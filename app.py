from flask import Flask, request, jsonify
import hashlib
import hmac
import base64
import time
import requests
import os
import random
import re
import json
import logging
from datetime import date, timedelta
from urllib.parse import quote
from concurrent.futures import ThreadPoolExecutor, TimeoutError as FuturesTimeoutError
import functools

app = Flask(__name__)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

#############################################
# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
#############################################
NAVER_API_KEY = os.environ.get('NAVER_API_KEY', '')
NAVER_SECRET_KEY = os.environ.get('NAVER_SECRET_KEY', '')
NAVER_CUSTOMER_ID = os.environ.get('NAVER_CUSTOMER_ID', '')
NAVER_CLIENT_ID = os.environ.get('NAVER_CLIENT_ID', '')
NAVER_CLIENT_SECRET = os.environ.get('NAVER_CLIENT_SECRET', '')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY', '')
DATA_GO_KR_API_KEY = os.environ.get('DATA_GO_KR_API_KEY', '')

# ì¹´ì¹´ì˜¤ ìŠ¤í‚¬ íƒ€ì„ì•„ì›ƒ ëŒ€ì‘ ì„¤ì •
API_TIMEOUT = 2.5  # ê°œë³„ API íƒ€ì„ì•„ì›ƒ (ì´ˆ)
SKILL_TIMEOUT = 4.5  # ì „ì²´ ìŠ¤í‚¬ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
API_RETRY = 1  # ì¬ì‹œë„ íšŸìˆ˜

# ìŠ¤ë ˆë“œí’€ (ë³‘ë ¬ ì²˜ë¦¬ìš©)
executor = ThreadPoolExecutor(max_workers=5)

#############################################
# í™˜ê²½ë³€ìˆ˜ ê²€ì¦
#############################################
def validate_required_keys():
    required = {
        'NAVER_API_KEY': NAVER_API_KEY,
        'NAVER_SECRET_KEY': NAVER_SECRET_KEY,
        'NAVER_CUSTOMER_ID': NAVER_CUSTOMER_ID
    }
    missing = [k for k, v in required.items() if not v]
    if missing:
        logger.warning(f"âš ï¸ Missing: {', '.join(missing)}")
        return False
    return True

#############################################
# íƒ€ì„ì•„ì›ƒ ë°ì½”ë ˆì´í„°
#############################################
def with_timeout(timeout_seconds):
    """í•¨ìˆ˜ ì‹¤í–‰ì— íƒ€ì„ì•„ì›ƒ ì ìš©"""
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            future = executor.submit(func, *args, **kwargs)
            try:
                return future.result(timeout=timeout_seconds)
            except FuturesTimeoutError:
                logger.warning(f"Timeout: {func.__name__}")
                return None
        return wrapper
    return decorator

#############################################
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
#############################################
def format_number(num):
    if isinstance(num, int):
        return "{:,}".format(num)
    return str(num)

def parse_count(value):
    if value is None:
        return 0
    if isinstance(value, int):
        return value
    if isinstance(value, str):
        if value == "< 10":
            return 5
        try:
            return int(str(value).replace(",", ""))
        except:
            return 0
    return 0

def format_won(value):
    if value >= 100000000:
        return f"{value / 100000000:.1f}ì–µì›"
    elif value >= 10000:
        return f"{value / 10000:.1f}ë§Œì›"
    else:
        return f"{format_number(int(value))}ì›"

def clean_keyword(keyword):
    return keyword.replace(" ", "")

def get_comp_text(comp):
    if comp == "ë†’ìŒ":
        return "[ë†’ìŒ]"
    elif comp == "ì¤‘ê°„":
        return "[ì¤‘ê°„]"
    else:
        return "[ë‚®ìŒ]"

def is_guide_message(text):
    guide_indicators = ["ì‚¬ìš© ê°€ì´ë“œ", "í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰", "ì—°ê´€ ê²€ìƒ‰ì–´", "CPC ê´‘ê³ ", "ìë™ì™„ì„±ì–´", "ëŒ€í‘œí‚¤ì›Œë“œ", "ì¬ë¯¸ ê¸°ëŠ¥"]
    count = sum(1 for indicator in guide_indicators if indicator in text)
    return count >= 4

#############################################
# ì§€ì—­ë³„ ìƒê¶Œ íŠ¹ì„± ë°ì´í„°
#############################################
REGION_DATA = {
    "ë¶€í‰": {
        "code": "2832000000",
        "name": "ì¸ì²œ ë¶€í‰êµ¬",
        "population": "45ë§Œëª…",
        "sales": {"min": 2000, "max": 3000},
        "price": {"min": 18000, "max": 22000},
        "weekday_ratio": 70,
        "peak_lunch": 40,
        "peak_dinner": 35,
        "peak_time": "ì ì‹¬ 11:30~13:00",
        "age_group": "20~30",
        "characteristics": "ì§ì¥ì¸ ë°€ì§‘, ì£¼ê±° ë³µí•©",
        "avg_size": {"min": 25, "max": 35}
    },
    "ê³„ì–‘": {
        "code": "2824500000",
        "name": "ì¸ì²œ ê³„ì–‘êµ¬",
        "population": "23ë§Œëª…",
        "sales": {"min": 1500, "max": 2500},
        "price": {"min": 15000, "max": 20000},
        "weekday_ratio": 65,
        "peak_lunch": 30,
        "peak_dinner": 45,
        "peak_time": "ì €ë… 18:00~20:00",
        "age_group": "30~40",
        "characteristics": "ì£¼ê±° ì¤‘ì‹¬, ê°€ì¡± ë‹¨ìœ„",
        "avg_size": {"min": 30, "max": 40}
    },
    "ì†¡ë„": {
        "code": "2826000000",
        "name": "ì¸ì²œ ì—°ìˆ˜êµ¬",
        "population": "34ë§Œëª…",
        "sales": {"min": 2500, "max": 4000},
        "price": {"min": 20000, "max": 28000},
        "weekday_ratio": 60,
        "peak_lunch": 30,
        "peak_dinner": 45,
        "peak_time": "ì €ë… 18:30~20:30",
        "age_group": "20~30",
        "characteristics": "ì‹ ë„ì‹œ, ì Šì€ ê°€ì¡±, ê³ ì†Œë“",
        "avg_size": {"min": 30, "max": 45}
    },
    "ê°•ë‚¨": {
        "code": "1168000000",
        "name": "ì„œìš¸ ê°•ë‚¨êµ¬",
        "population": "8~10ë§Œëª…",
        "sales": {"min": 4000, "max": 7000},
        "price": {"min": 25000, "max": 40000},
        "weekday_ratio": 55,
        "peak_lunch": 35,
        "peak_dinner": 40,
        "peak_time": "ì ì‹¬/ì €ë… ê· ë“±",
        "age_group": "20~40",
        "characteristics": "ê³ ì†Œë“, ì§ì¥ì¸, ìœ í¥",
        "avg_size": {"min": 35, "max": 50}
    },
    "í™ëŒ€": {
        "code": "1144000000",
        "name": "ì„œìš¸ ë§ˆí¬êµ¬",
        "population": "7~9ë§Œëª…",
        "sales": {"min": 3000, "max": 5000},
        "price": {"min": 15000, "max": 25000},
        "weekday_ratio": 45,
        "peak_lunch": 25,
        "peak_dinner": 50,
        "peak_time": "ì €ë…/ì•¼ê°„ 18:00~22:00",
        "age_group": "10~20",
        "characteristics": "ìœ í¥, íŠ¸ë Œë“œ, ì™¸êµ­ì¸",
        "avg_size": {"min": 20, "max": 35}
    },
    "ì„œì´ˆ": {
        "code": "1165000000",
        "name": "ì„œìš¸ ì„œì´ˆêµ¬",
        "population": "6~8ë§Œëª…",
        "sales": {"min": 3500, "max": 6000},
        "price": {"min": 22000, "max": 35000},
        "weekday_ratio": 60,
        "peak_lunch": 45,
        "peak_dinner": 35,
        "peak_time": "ì ì‹¬ 11:30~13:30",
        "age_group": "30~40",
        "characteristics": "ê³ ì†Œë“, ê°€ì¡±, ë²•ì¡°íƒ€ìš´",
        "avg_size": {"min": 35, "max": 50}
    },
    "ì ì‹¤": {
        "code": "1171000000",
        "name": "ì„œìš¸ ì†¡íŒŒêµ¬",
        "population": "7~9ë§Œëª…",
        "sales": {"min": 3000, "max": 5000},
        "price": {"min": 20000, "max": 30000},
        "weekday_ratio": 50,
        "peak_lunch": 30,
        "peak_dinner": 45,
        "peak_time": "ì €ë…/ì£¼ë§ 17:00~20:00",
        "age_group": "30~40",
        "characteristics": "ê°€ì¡±, ì‡¼í•‘, ë¡¯ë°ì›”ë“œ",
        "avg_size": {"min": 30, "max": 45}
    },
    "í•´ìš´ëŒ€": {
        "code": "2626000000",
        "name": "ë¶€ì‚° í•´ìš´ëŒ€êµ¬",
        "population": "5~7ë§Œëª…",
        "sales": {"min": 3000, "max": 5000},
        "price": {"min": 22000, "max": 35000},
        "weekday_ratio": 40,
        "peak_lunch": 25,
        "peak_dinner": 50,
        "peak_time": "ì €ë…/ì£¼ë§ 18:00~21:00",
        "age_group": "ì „ì—°ë ¹",
        "characteristics": "ê´€ê´‘, ê³ ê¸‰, í•´ë³€",
        "avg_size": {"min": 35, "max": 55}
    },
    "ì„œë©´": {
        "code": "2617000000",
        "name": "ë¶€ì‚° ë¶€ì‚°ì§„êµ¬",
        "population": "6~8ë§Œëª…",
        "sales": {"min": 2500, "max": 4000},
        "price": {"min": 18000, "max": 25000},
        "weekday_ratio": 55,
        "peak_lunch": 35,
        "peak_dinner": 40,
        "peak_time": "ì ì‹¬/ì €ë… ê· ë“±",
        "age_group": "20~30",
        "characteristics": "ë¶€ì‚° ì¤‘ì‹¬, ìœ í¥, ì‡¼í•‘",
        "avg_size": {"min": 25, "max": 40}
    },
    "ë¶„ë‹¹": {
        "code": "4113500000",
        "name": "ê²½ê¸° ì„±ë‚¨ì‹œ",
        "population": "5~6ë§Œëª…",
        "sales": {"min": 3000, "max": 5000},
        "price": {"min": 22000, "max": 32000},
        "weekday_ratio": 60,
        "peak_lunch": 35,
        "peak_dinner": 40,
        "peak_time": "ì €ë… 18:00~20:00",
        "age_group": "30~50",
        "characteristics": "ê³ ì†Œë“, ê°€ì¡±, ITê¸°ì—…",
        "avg_size": {"min": 35, "max": 50}
    },
    "ì¼ì‚°": {
        "code": "4128700000",
        "name": "ê²½ê¸° ê³ ì–‘ì‹œ",
        "population": "4~5ë§Œëª…",
        "sales": {"min": 2000, "max": 3500},
        "price": {"min": 18000, "max": 25000},
        "weekday_ratio": 55,
        "peak_lunch": 30,
        "peak_dinner": 45,
        "peak_time": "ì €ë…/ì£¼ë§ 17:30~20:00",
        "age_group": "30~40",
        "characteristics": "ë² ë“œíƒ€ìš´, ê°€ì¡±, í˜¸ìˆ˜ê³µì›",
        "avg_size": {"min": 30, "max": 45}
    },
    "ìˆ˜ì›": {
        "code": "4111100000",
        "name": "ê²½ê¸° ìˆ˜ì›ì‹œ",
        "population": "5~6ë§Œëª…",
        "sales": {"min": 2500, "max": 4000},
        "price": {"min": 18000, "max": 25000},
        "weekday_ratio": 60,
        "peak_lunch": 35,
        "peak_dinner": 40,
        "peak_time": "ì ì‹¬/ì €ë… ê· ë“±",
        "age_group": "20~40",
        "characteristics": "ì‚¼ì„±, ì§ì¥ì¸, ì—­ì‚¬",
        "avg_size": {"min": 25, "max": 40}
    },
}

DEFAULT_REGION_DATA = {
    "name": "ì „êµ­",
    "population": "ë°ì´í„° ì—†ìŒ",
    "sales": {"min": 2000, "max": 3500},
    "price": {"min": 18000, "max": 25000},
    "weekday_ratio": 60,
    "peak_lunch": 35,
    "peak_dinner": 40,
    "peak_time": "ì ì‹¬/ì €ë…",
    "age_group": "ì „ì—°ë ¹",
    "characteristics": "ì§€ì—­ íŠ¹ì„± ë¯¸ìƒ",
    "avg_size": {"min": 25, "max": 40}
}

REGION_KEYWORDS = list(REGION_DATA.keys())

#############################################
# ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API (ë¹ ë¥¸ ë²„ì „)
#############################################
def get_naver_api_headers(method="GET", uri="/keywordstool"):
    timestamp = str(int(time.time() * 1000))
    message = f"{timestamp}.{method}.{uri}"
    signature = hmac.new(NAVER_SECRET_KEY.encode('utf-8'), message.encode('utf-8'), hashlib.sha256).digest()
    signature_base64 = base64.b64encode(signature).decode('utf-8')
    return {
        "Content-Type": "application/json; charset=UTF-8",
        "X-Timestamp": timestamp,
        "X-API-KEY": NAVER_API_KEY,
        "X-Customer": str(NAVER_CUSTOMER_ID),
        "X-Signature": signature_base64
    }

def get_keyword_data_fast(keyword):
    """í‚¤ì›Œë“œ ë°ì´í„° ì¡°íšŒ (ë¹ ë¥¸ ë²„ì „ - ì¬ì‹œë„ ìµœì†Œí™”)"""
    if not validate_required_keys():
        return {"success": False, "error": "API í‚¤ ë¯¸ì„¤ì •"}

    base_url = "https://api.searchad.naver.com"
    uri = "/keywordstool"
    params = {"hintKeywords": keyword, "showDetail": "1"}

    try:
        headers = get_naver_api_headers("GET", uri)
        response = requests.get(base_url + uri, headers=headers, params=params, timeout=API_TIMEOUT)
        
        if response.status_code == 200:
            data = response.json()
            keyword_list = data.get("keywordList", [])
            if keyword_list:
                return {"success": True, "data": keyword_list}
            return {"success": False, "error": "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"}
        
        return {"success": False, "error": f"API ì˜¤ë¥˜ ({response.status_code})"}
        
    except requests.Timeout:
        return {"success": False, "error": "íƒ€ì„ì•„ì›ƒ"}
    except Exception as e:
        return {"success": False, "error": str(e)}

def get_performance_estimate_fast(keyword, bids, device='MOBILE'):
    """ì„±ê³¼ ì˜ˆì¸¡ API (ë¹ ë¥¸ ë²„ì „)"""
    uri = '/estimate/performance/keyword'
    url = f'https://api.searchad.naver.com{uri}'
    payload = {
        "device": device,
        "keywordplus": False,
        "key": keyword,
        "bids": bids if isinstance(bids, list) else [bids]
    }

    try:
        headers = get_naver_api_headers('POST', uri)
        response = requests.post(url, headers=headers, json=payload, timeout=API_TIMEOUT)
        
        if response.status_code == 200:
            return {"success": True, "data": response.json()}
        return {"success": False, "error": response.text}
        
    except requests.Timeout:
        return {"success": False, "error": "íƒ€ì„ì•„ì›ƒ"}
    except Exception as e:
        return {"success": False, "error": str(e)}

def get_datalab_trend_fast(keyword):
    """íŠ¸ë Œë“œ ë°ì´í„° (ë¹ ë¥¸ ë²„ì „)"""
    if not NAVER_CLIENT_ID or not NAVER_CLIENT_SECRET:
        return {"success": False, "error": "API í‚¤ ë¯¸ì„¤ì •"}

    url = "https://openapi.naver.com/v1/datalab/search"
    end_date = date.today() - timedelta(days=1)
    start_date = end_date - timedelta(days=365)

    payload = {
        "startDate": start_date.strftime("%Y-%m-%d"),
        "endDate": end_date.strftime("%Y-%m-%d"),
        "timeUnit": "month",
        "keywordGroups": [{"groupName": keyword, "keywords": [keyword]}]
    }
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
        "Content-Type": "application/json"
    }

    try:
        response = requests.post(url, headers=headers, json=payload, timeout=API_TIMEOUT)
        
        if response.status_code == 200:
            data = response.json()
            results = data.get("results", [])
            if results and results[0].get("data"):
                return {"success": True, "data": results[0]["data"]}
        return {"success": False, "error": "ë°ì´í„° ì—†ìŒ"}
        
    except requests.Timeout:
        return {"success": False, "error": "íƒ€ì„ì•„ì›ƒ"}
    except Exception as e:
        return {"success": False, "error": str(e)}

#############################################
# ì—…ì²´ ìˆ˜ / ë¦¬ë·° ì¶”ì • (API í˜¸ì¶œ ì—†ì´)
#############################################
def estimate_business_count(search_volume, comp_idx, region=None):
    COMP_RATIO = {'ë†’ìŒ': 0.08, 'ì¤‘ê°„': 0.05, 'ë‚®ìŒ': 0.03}
    base_ratio = COMP_RATIO.get(comp_idx, 0.05)
    estimated = int(search_volume * base_ratio)

    REGION_MULTIPLIER = {
        'ê°•ë‚¨': 1.3, 'í™ëŒ€': 1.3, 'ì ì‹¤': 1.3, 'í•´ìš´ëŒ€': 1.3,
        'ê³„ì–‘': 0.7, 'ì¼ì‚°': 0.7
    }

    if region and region in REGION_MULTIPLIER:
        estimated = int(estimated * REGION_MULTIPLIER[region])

    min_count = max(estimated - int(estimated * 0.2), 100)
    max_count = estimated + int(estimated * 0.2)

    return {"min": min_count, "max": max_count, "estimated": estimated}

def estimate_reviews(search_volume, comp_idx):
    if search_volume >= 100000:
        avg_review = random.randint(280, 350)
        avg_blog = random.randint(90, 130)
    elif search_volume >= 50000:
        avg_review = random.randint(180, 250)
        avg_blog = random.randint(60, 90)
    elif search_volume >= 20000:
        avg_review = random.randint(100, 180)
        avg_blog = random.randint(35, 60)
    elif search_volume >= 10000:
        avg_review = random.randint(60, 120)
        avg_blog = random.randint(20, 40)
    else:
        avg_review = random.randint(30, 70)
        avg_blog = random.randint(10, 25)

    COMP_MULTIPLIER = {'ë†’ìŒ': 1.2, 'ë‚®ìŒ': 0.8}
    multiplier = COMP_MULTIPLIER.get(comp_idx, 1.0)

    return {
        "avg_review": int(avg_review * multiplier),
        "avg_blog": int(avg_blog * multiplier)
    }

def extract_region(keyword):
    for region in REGION_KEYWORDS:
        if region in keyword:
            return region, REGION_DATA[region]
    return None, DEFAULT_REGION_DATA

def calculate_competition_level(search_volume, avg_review):
    if search_volume >= 100000:
        volume_score = 2
    elif search_volume >= 50000:
        volume_score = 1.5
    elif search_volume >= 20000:
        volume_score = 1
    else:
        volume_score = 0.5

    if avg_review >= 300:
        review_score = 2
    elif avg_review >= 200:
        review_score = 1.5
    elif avg_review >= 100:
        review_score = 1
    else:
        review_score = 0.5

    total = volume_score + review_score
    if total >= 3.5:
        return 4
    elif total >= 2.5:
        return 3
    elif total >= 1.5:
        return 2
    else:
        return 1

def generate_ad_strategy(analysis):
    search_volume = 0
    avg_review = 0

    if analysis.get("search_data"):
        search_volume = analysis["search_data"]["total"]

    if analysis.get("review_data"):
        avg_review = analysis["review_data"]["avg_review"]

    level = calculate_competition_level(search_volume, avg_review)

    strategies = {
        1: {"blog": {"min": 2, "rec": 4}, "insta": {"min": 2, "rec": 4}, "local": {"min": 1, "rec": 2}, "desc": "ê²½ìŸ ë‚®ìŒ"},
        2: {"blog": {"min": 4, "rec": 6}, "insta": {"min": 4, "rec": 6}, "local": {"min": 2, "rec": 4}, "desc": "ê²½ìŸ ì¤‘ê°„"},
        3: {"blog": {"min": 6, "rec": 8}, "insta": {"min": 6, "rec": 10}, "local": {"min": 3, "rec": 5}, "desc": "ê²½ìŸ ë†’ìŒ"},
        4: {"blog": {"min": 8, "rec": 12}, "insta": {"min": 8, "rec": 12}, "local": {"min": 4, "rec": 6}, "desc": "ê²½ìŸ ë§¤ìš° ë†’ìŒ"}
    }

    strategy = strategies[level]

    lines = []
    lines.append(f"â–¶ ê´‘ê³  ì „ëµ ({strategy['desc']})")
    lines.append("â€¢ í”Œë ˆì´ìŠ¤ê´‘ê³ : ìƒì‹œ ìš´ì˜")
    lines.append("â€¢ íŒŒì›Œë§í¬: ìƒì‹œ ìš´ì˜")
    lines.append(f"â€¢ ë¸”ë¡œê·¸ì²´í—˜ë‹¨: ìµœì†Œ ì›”{strategy['blog']['min']}íšŒ / ê¶Œì¥ ì›”{strategy['blog']['rec']}íšŒ")
    lines.append(f"â€¢ ì¸ìŠ¤íƒ€/ë©”íƒ€: ìµœì†Œ ì›”{strategy['insta']['min']}íšŒ / ê¶Œì¥ ì›”{strategy['insta']['rec']}íšŒ")
    lines.append(f"â€¢ ì§€ì—­ê´‘ê³ : ìµœì†Œ ì›”{strategy['local']['min']}íšŒ / ê¶Œì¥ ì›”{strategy['local']['rec']}íšŒ")

    return "\n".join(lines), level

#############################################
# ìƒê¶Œë¶„ì„ (ë³‘ë ¬ ì²˜ë¦¬ + íƒ€ì„ì•„ì›ƒ)
#############################################
def get_commercial_analysis_fast(keyword):
    """ìƒê¶Œë¶„ì„ - ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì†ë„ ìµœì í™”"""
    region, region_data = extract_region(keyword)

    result = {
        "keyword": keyword,
        "region": region,
        "region_data": region_data,
        "search_data": None,
        "trend_data": None,
        "review_data": None,
        "business_count": None
    }

    # í•„ìˆ˜: ê²€ìƒ‰ ë°ì´í„° (ë™ê¸° í˜¸ì¶œ)
    search_result = get_keyword_data_fast(keyword)
    if search_result["success"]:
        kw = search_result["data"][0]
        pc = parse_count(kw.get("monthlyPcQcCnt"))
        mobile = parse_count(kw.get("monthlyMobileQcCnt"))
        total = pc + mobile
        comp_idx = kw.get("compIdx", "ì¤‘ê°„")
        
        result["search_data"] = {
            "total": total,
            "mobile": mobile,
            "pc": pc,
            "mobile_ratio": (mobile * 100 // total) if total > 0 else 0,
            "comp_idx": comp_idx
        }
        
        result["business_count"] = estimate_business_count(total, comp_idx, region)
        
        # ë¦¬ë·° ì¶”ì • (API í˜¸ì¶œ ì—†ì´)
        estimated = estimate_reviews(total, comp_idx)
        result["review_data"] = {
            "success": True,
            "avg_review": estimated["avg_review"],
            "avg_blog": estimated["avg_blog"],
            "estimated": True
        }

    # ì„ íƒ: íŠ¸ë Œë“œ (ë¹„ë™ê¸° - ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ)
    try:
        future = executor.submit(get_datalab_trend_fast, keyword)
        trend_result = future.result(timeout=1.5)
        if trend_result["success"]:
            series = trend_result["data"]
            change = 0
            if len(series) >= 6:
                last3 = sum(p.get("ratio", 0) for p in series[-3:]) / 3
                prev3 = sum(p.get("ratio", 0) for p in series[-6:-3]) / 3
                change = ((last3 - prev3) / prev3) * 100 if prev3 > 0 else 0
            result["trend_data"] = {"series": series, "change": change}
    except:
        pass

    return result

def format_commercial_analysis(analysis):
    """ìƒê¶Œë¶„ì„ ê²°ê³¼ í¬ë§·íŒ… (ê°„ì†Œí™”)"""

    keyword = analysis["keyword"]
    region = analysis["region"]
    region_data = analysis["region_data"]

    lines = [f"[ìƒê¶Œë¶„ì„] {keyword}", ""]

    lines.append("â–¶ ê²€ìƒ‰ ë°ì´í„°")
    if analysis["search_data"]:
        sd = analysis["search_data"]
        lines.append(f"ì›” ê²€ìƒ‰ëŸ‰: {format_number(sd['total'])}íšŒ")
        lines.append(f"ëª¨ë°”ì¼ {sd['mobile_ratio']}% / PC {100-sd['mobile_ratio']}%")
        
        if analysis["trend_data"]:
            change = analysis["trend_data"]["change"]
            if change >= 10:
                trend = f"ìƒìŠ¹ (+{change:.0f}%)"
            elif change <= -10:
                trend = f"í•˜ë½ ({change:.0f}%)"
            else:
                trend = f"ìœ ì§€ ({change:+.0f}%)"
            lines.append(f"íŠ¸ë Œë“œ: {trend}")
    else:
        lines.append("ë°ì´í„° ì—†ìŒ")
    lines.append("")

    lines.append("â–¶ ì§€ì—­ ìƒê¶Œ")
    if region:
        lines.append(f"ì§€ì—­: {region} ({region_data['name']})")
        lines.append(f"íŠ¹ì„±: {region_data['characteristics']}")
    else:
        lines.append("ì§€ì—­: ì „êµ­")

    if analysis["business_count"]:
        bc = analysis["business_count"]
        lines.append(f"ì¶”ì • ì—…ì²´: ì•½ {format_number(bc['min'])}~{format_number(bc['max'])}ê°œ")
    lines.append("")

    lines.append("â–¶ ê²½ìŸ ë¶„ì„ (ìƒìœ„ 20ê°œ í‰ê· )")
    if analysis["review_data"]:
        rd = analysis["review_data"]
        lines.append(f"í‰ê·  ë¦¬ë·°: {rd['avg_review']}ê°œ")
        lines.append(f"í‰ê·  ë¸”ë¡œê·¸: {rd['avg_blog']}ê°œ")
        target_review = int(rd['avg_review'] * 1.1)
        lines.append(f"â†’ ëª©í‘œ: ë¦¬ë·° {target_review}ê°œ ì´ìƒ")
    lines.append("")

    lines.append("â–¶ ë§¤ì¶œ ë¶„ì„")
    sales = region_data["sales"]
    price = region_data["price"]
    lines.append(f"í‰ê· ë§¤ì¶œ: ì›” {sales['min']:,}~{sales['max']:,}ë§Œì›")
    lines.append(f"ê°ë‹¨ê°€: {price['min']:,}~{price['max']:,}ì›")
    lines.append("")

    lines.append("â–¶ ê²°ì œ ì‹œê°„ëŒ€")
    weekday = region_data["weekday_ratio"]
    peak_lunch = region_data.get("peak_lunch", 35)
    peak_dinner = region_data.get("peak_dinner", 40)
    lines.append(f"ì ì‹¬ ({peak_lunch}%) / ì €ë… ({peak_dinner}%)")
    lines.append(f"ì£¼ì¤‘ {weekday}% / ì£¼ë§ {100-weekday}%")
    lines.append("")

    ad_strategy, comp_level = generate_ad_strategy(analysis)
    lines.append(ad_strategy)
    lines.append("")

    lines.append("â–¶ ì¸ì‚¬ì´íŠ¸")
    insights = generate_insights_fast(analysis, region_data, comp_level)
    lines.extend(insights)

    return "\n".join(lines)

def generate_insights_fast(analysis, region_data, comp_level=2):
    """ë¹ ë¥¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    insights = []

    peak_lunch = region_data.get("peak_lunch", 35)
    peak_dinner = region_data.get("peak_dinner", 40)

    if peak_lunch >= 40:
        insights.append("â€¢ ì ì‹¬ í”¼í¬ â†’ 11ì‹œ ì „ ìƒìœ„ë…¸ì¶œ ì„¸íŒ…")
    elif peak_dinner >= 45:
        insights.append("â€¢ ì €ë… í”¼í¬ â†’ 17ì‹œ ê´‘ê³  ì§‘ì¤‘")
    else:
        insights.append("â€¢ ì ì‹¬/ì €ë… ê· ë“± â†’ í•˜ë£¨ 2íšŒ í‘¸ì‹œ")

    char = region_data.get("characteristics", "")
    if "ì§ì¥ì¸" in char:
        insights.append("â€¢ ì§ì¥ì¸ â†’ ëŸ°ì¹˜ì„¸íŠ¸ êµ¬ì„±")
    elif "ê°€ì¡±" in char:
        insights.append("â€¢ ê°€ì¡± íƒ€ê²Ÿ â†’ í‚¤ì¦ˆë©”ë‰´ ê°•ì¡°")

    if comp_level >= 3:
        insights.append("â€¢ ê²½ìŸ ì¹˜ì—´ â†’ ì°¨ë³„í™” í•„ìˆ˜")
    else:
        insights.append("â€¢ ê²½ìŸ ë‚®ìŒ â†’ ì„ ì  íš¨ê³¼ ìœ ë¦¬")

    return insights[:3]

#############################################
# ê¸°ëŠ¥ 1: ê²€ìƒ‰ëŸ‰ ì¡°íšŒ
#############################################
def get_search_volume(keyword):
    if "," in keyword:
        keywords = [k.strip() for k in keyword.split(",")]
        if len(keywords) > 5:
            return "ìµœëŒ€ 5ê°œ í‚¤ì›Œë“œê¹Œì§€ë§Œ ì¡°íšŒ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        return get_multi_search_volume(keywords[:5])

    result = get_keyword_data_fast(keyword)
    if not result["success"]:
        return f"ì¡°íšŒ ì‹¤íŒ¨: {result['error']}"

    kw = result["data"][0]
    pc = parse_count(kw.get("monthlyPcQcCnt"))
    mobile = parse_count(kw.get("monthlyMobileQcCnt"))
    total = pc + mobile

    return f"""[ê²€ìƒ‰ëŸ‰] {kw.get('relKeyword', keyword)}
ì›”ê°„ ì´ {format_number(total)}íšŒ
ã„´ ëª¨ë°”ì¼: {format_number(mobile)}íšŒ
ã„´ PC: {format_number(pc)}íšŒ

â€» ë„ì›€ë§: "ë„ì›€ë§" ì…ë ¥"""

def get_multi_search_volume(keywords):
    """ë‹¤ì¤‘ í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰ (ë³‘ë ¬ ì²˜ë¦¬)"""
    lines = ["[ê²€ìƒ‰ëŸ‰ ë¹„êµ]", ""]
    
    def fetch_one(kw):
        kw = kw.replace(" ", "")
        result = get_keyword_data_fast(kw)
        if result["success"]:
            data = result["data"][0]
            pc = parse_count(data.get("monthlyPcQcCnt"))
            mobile = parse_count(data.get("monthlyMobileQcCnt"))
            total = pc + mobile
            mobile_ratio = (mobile * 100 // total) if total > 0 else 0
            return f"â–¸ {data.get('relKeyword', kw)}\n  {format_number(total)}íšŒ (ëª¨ë°”ì¼ {mobile_ratio}%)"
        return f"â–¸ {kw}\n  ì¡°íšŒ ì‹¤íŒ¨"
    
    # ë³‘ë ¬ ì²˜ë¦¬
    futures = [executor.submit(fetch_one, kw) for kw in keywords]
    
    for future in futures:
        try:
            result = future.result(timeout=3)
            lines.append(result)
            lines.append("")
        except:
            lines.append("â–¸ ì¡°íšŒ ì‹¤íŒ¨")
            lines.append("")

    return "\n".join(lines).strip()

#############################################
# ê¸°ëŠ¥ 2: ì—°ê´€ í‚¤ì›Œë“œ
#############################################
def get_related_keywords(keyword):
    try:
        url = f"https://search.naver.com/search.naver?where=nexearch&query={requests.utils.quote(keyword)}"
        headers = {"User-Agent": "Mozilla/5.0", "Accept-Language": "ko-KR,ko;q=0.9"}
        response = requests.get(url, headers=headers, timeout=API_TIMEOUT)

        if response.status_code == 200:
            pattern = re.findall(r'<div class="tit">([^<]+)</div>', response.text)
            seen = set()
            related = []
            for kw in pattern:
                kw = kw.strip()
                if kw and kw != keyword and kw not in seen and len(kw) > 1:
                    seen.add(kw)
                    related.append(kw)
                    if len(related) >= 10:
                        break
            
            if related:
                result = f"[ì—°ê´€ê²€ìƒ‰ì–´] {keyword}\n\n"
                for i, kw in enumerate(related, 1):
                    result += f"{i}. {kw}\n"
                return result.strip()
    except:
        pass
    
    return get_related_keywords_api(keyword)

def get_related_keywords_api(keyword):
    result = get_keyword_data_fast(keyword)
    if not result["success"]:
        return f"ì¡°íšŒ ì‹¤íŒ¨: {result['error']}"

    keyword_list = result["data"][:10]
    response = f"[ì—°ê´€í‚¤ì›Œë“œ] {keyword}\n\n"

    for i, kw in enumerate(keyword_list, 1):
        name = kw.get("relKeyword", "")
        total = parse_count(kw.get("monthlyPcQcCnt")) + parse_count(kw.get("monthlyMobileQcCnt"))
        comp = get_comp_text(kw.get("compIdx", ""))
        response += f"{i}. {name} ({format_number(total)}) {comp}\n"

    return response.strip()

#############################################
# ê¸°ëŠ¥ 3: ê´‘ê³  ë‹¨ê°€ (ê°„ì†Œí™” ë²„ì „)
#############################################
def get_ad_cost_fast(keyword):
    """ê´‘ê³  ë‹¨ê°€ ë¶„ì„ - ë¹ ë¥¸ ë²„ì „"""
    result = get_keyword_data_fast(keyword)
    if not result["success"]:
        return f"ì¡°íšŒ ì‹¤íŒ¨: {result['error']}"

    kw = result["data"][0]
    keyword_name = kw.get('relKeyword', keyword)
    pc_qc = parse_count(kw.get("monthlyPcQcCnt"))
    mobile_qc = parse_count(kw.get("monthlyMobileQcCnt"))
    total_qc = pc_qc + mobile_qc
    mobile_ratio = (mobile_qc * 100 // total_qc) if total_qc > 0 else 0
    comp_idx = kw.get("compIdx", "ì¤‘ê°„")

    comp_emoji = "ğŸ”´" if comp_idx == "ë†’ìŒ" else "ğŸŸ¡" if comp_idx == "ì¤‘ê°„" else "ğŸŸ¢"

    lines = [f"ğŸ’° \"{keyword_name}\" ê´‘ê³  ë¶„ì„", ""]

    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append("ğŸ“Š í‚¤ì›Œë“œ ì •ë³´")
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append("")
    lines.append(f"ê²½ìŸë„: {comp_idx} {comp_emoji}")
    lines.append(f"ì›”ê°„ ê²€ìƒ‰ëŸ‰: {format_number(total_qc)}íšŒ")
    lines.append(f"â”œ ëª¨ë°”ì¼: {format_number(mobile_qc)}íšŒ ({mobile_ratio}%)")
    lines.append(f"â”” PC: {format_number(pc_qc)}íšŒ ({100-mobile_ratio}%)")
    lines.append("")

    # ì…ì°°ê°€ í…ŒìŠ¤íŠ¸ (í•µì‹¬ë§Œ)
    test_bids = [200, 500, 1000, 2000, 3000, 5000]

    mobile_perf = get_performance_estimate_fast(keyword_name, test_bids, 'MOBILE')

    if mobile_perf.get("success"):
        mobile_estimates = mobile_perf["data"].get("estimate", [])
        valid_estimates = [e for e in mobile_estimates if e.get('clicks', 0) > 0]
        
        if valid_estimates:
            lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            lines.append("ğŸ“± ëª¨ë°”ì¼ ì„±ê³¼")
            lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            lines.append("")
            
            for est in valid_estimates[:5]:
                bid = est.get('bid', 0)
                clicks = est.get('clicks', 0)
                cost = est.get('cost', 0) or int(clicks * bid * 0.8)
                lines.append(f"{format_number(bid)}ì› â†’ ì›” {clicks}íšŒ | {format_won(cost)}")
            
            lines.append("")
            
            # ì¶”ì²œ ì…ì°°ê°€ (í´ë¦­ìˆ˜ ìµœëŒ€)
            best = max(valid_estimates, key=lambda x: x.get('clicks', 0))
            lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            lines.append("ğŸ¯ ì¶”ì²œ")
            lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            lines.append("")
            lines.append(f"ì…ì°°ê°€: {format_number(best.get('bid', 0))}ì›")
            lines.append(f"ì˜ˆìƒ í´ë¦­: ì›” {best.get('clicks', 0)}íšŒ")
            cost = best.get('cost', 0) or int(best.get('clicks', 0) * best.get('bid', 0) * 0.8)
            lines.append(f"ì˜ˆìƒ ë¹„ìš©: ì›” {format_won(cost)}")
    else:
        lines.append("ì„±ê³¼ ì˜ˆì¸¡ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    return "\n".join(lines)

#############################################
# ê¸°ëŠ¥ 5: ìš´ì„¸
#############################################
def get_fortune(birthdate=None):
    if not GEMINI_API_KEY:
        return get_fortune_fallback(birthdate)

    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}"

    if birthdate:
        if len(birthdate) == 6:
            year = f"19{birthdate[:2]}" if int(birthdate[:2]) > 30 else f"20{birthdate[:2]}"
            month, day = birthdate[2:4], birthdate[4:6]
        elif len(birthdate) == 8:
            year, month, day = birthdate[:4], birthdate[4:6], birthdate[6:8]
        else:
            return get_fortune()
        
        prompt = f"""ìƒë…„ì›”ì¼ {year}ë…„ {month}ì›” {day}ì¼ìƒì˜ ì˜¤ëŠ˜ ìš´ì„¸ë¥¼ ì•Œë ¤ì¤˜.
í˜•ì‹:
[ìš´ì„¸] {year}ë…„ {month}ì›” {day}ì¼ìƒ

ì´ìš´: (2ì¤„)
ì• ì •ìš´: (1ì¤„)
ê¸ˆì „ìš´: (1ì¤„)
ì§ì¥ìš´: (1ì¤„)

í–‰ìš´ì˜ ìˆ«ì: (1-45 ìˆ«ì 3ê°œ)
í–‰ìš´ì˜ ìƒ‰: (1ê°œ)

ì˜¤ëŠ˜ì˜ ì¡°ì–¸: "(í•œë§ˆë””)"

ì¬ë¯¸ìˆê³  ê¸ì •ì ìœ¼ë¡œ. ì´ëª¨í‹°ì½˜ ì—†ì´."""
    else:
        prompt = """ì˜¤ëŠ˜ì˜ ìš´ì„¸ë¥¼ ì•Œë ¤ì¤˜.
í˜•ì‹:
[ì˜¤ëŠ˜ì˜ ìš´ì„¸]

ì´ìš´: (2ì¤„)
ì• ì •ìš´: (1ì¤„)
ê¸ˆì „ìš´: (1ì¤„)
ì§ì¥ìš´: (1ì¤„)

í–‰ìš´ì˜ ìˆ«ì: (1-45 ìˆ«ì 3ê°œ)
í–‰ìš´ì˜ ìƒ‰: (1ê°œ)

ì˜¤ëŠ˜ì˜ í•œë§ˆë””: "(ê²©ì–¸)"

ì¬ë¯¸ìˆê³  ê¸ì •ì ìœ¼ë¡œ. ì´ëª¨í‹°ì½˜ ì—†ì´."""

    try:
        response = requests.post(url, json={
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": {"temperature": 0.9, "maxOutputTokens": 400}
        }, timeout=3)
        if response.status_code == 200:
            return response.json()["candidates"][0]["content"]["parts"][0]["text"]
    except:
        pass
    return get_fortune_fallback(birthdate)

def get_fortune_fallback(birthdate=None):
    fortunes = ["ì˜¤ëŠ˜ì€ ìƒˆë¡œìš´ ê¸°íšŒê°€ ì°¾ì•„ì˜¤ëŠ” ë‚ !", "ì¢‹ì€ ì†Œì‹ì´ ë“¤ë ¤ì˜¬ ì˜ˆì •ì´ì—ìš”.", "ì‘ì€ í–‰ìš´ì´ ë‹¹ì‹ ì„ ë”°ë¼ë‹¤ë…€ìš”."]
    love = ["ì„¤ë ˆëŠ” ë§Œë‚¨ì´ ìˆì„ ìˆ˜ ìˆì–´ìš”", "ì†Œì¤‘í•œ ì‚¬ëŒê³¼ ëŒ€í™”ë¥¼ ë‚˜ëˆ ë³´ì„¸ìš”"]
    money = ["ì‘ì€ íš¡ì¬ìˆ˜ê°€ ìˆì–´ìš”", "ì ˆì•½ì´ ë¯¸ë•ì¸ ë‚ "]
    work = ["ì§‘ì¤‘ë ¥ì´ ë†’ì•„ì§€ëŠ” ì‹œê°„", "ìƒˆ í”„ë¡œì íŠ¸ì— ë„ì „í•´ë³´ì„¸ìš”"]
    lucky_numbers = sorted(random.sample(range(1, 46), 3))
    colors = ["ë¹¨ê°„ìƒ‰", "íŒŒë€ìƒ‰", "ë…¸ë€ìƒ‰", "ì´ˆë¡ìƒ‰", "ë³´ë¼ìƒ‰"]

    if birthdate and len(birthdate) in [6, 8]:
        if len(birthdate) == 6:
            year = f"19{birthdate[:2]}" if int(birthdate[:2]) > 30 else f"20{birthdate[:2]}"
            month, day = birthdate[2:4], birthdate[4:6]
        else:
            year, month, day = birthdate[:4], birthdate[4:6], birthdate[6:8]
        
        return f"""[ìš´ì„¸] {year}ë…„ {month}ì›” {day}ì¼ìƒ
ì´ìš´: {random.choice(fortunes)}
ì• ì •ìš´: {random.choice(love)}
ê¸ˆì „ìš´: {random.choice(money)}
ì§ì¥ìš´: {random.choice(work)}

í–‰ìš´ì˜ ìˆ«ì: {lucky_numbers[0]}, {lucky_numbers[1]}, {lucky_numbers[2]}
í–‰ìš´ì˜ ìƒ‰: {random.choice(colors)}"""

    return f"""[ì˜¤ëŠ˜ì˜ ìš´ì„¸]
ì´ìš´: {random.choice(fortunes)}
ì• ì •ìš´: {random.choice(love)}
ê¸ˆì „ìš´: {random.choice(money)}
ì§ì¥ìš´: {random.choice(work)}

í–‰ìš´ì˜ ìˆ«ì: {lucky_numbers[0]}, {lucky_numbers[1]}, {lucky_numbers[2]}
í–‰ìš´ì˜ ìƒ‰: {random.choice(colors)}"""

#############################################
# ê¸°ëŠ¥ 6: ë¡œë˜
#############################################
def get_lotto():
    result = "[ë¡œë˜ ë²ˆí˜¸ ì¶”ì²œ]\n\n"
    for i in range(1, 6):
        numbers = sorted(random.sample(range(1, 46), 6))
        result += f"{i}) {', '.join(str(n).zfill(2) for n in numbers)}\n"
    result += "\ní–‰ìš´ì„ ë¹•ë‹ˆë‹¤!\nâ€» ì¬ë¯¸ë¡œë§Œ ì¦ê¸°ì„¸ìš”!"
    return result

#############################################
# ê¸°ëŠ¥ 7: ëŒ€í‘œí‚¤ì›Œë“œ
#############################################
def extract_place_id_from_url(url_or_id):
    url_or_id = url_or_id.strip()
    if url_or_id.isdigit():
        return url_or_id

    patterns = [r'/restaurant/(\d+)', r'/place/(\d+)', r'/cafe/(\d+)', r'/hospital/(\d+)', r'/beauty/(\d+)', r'place/(\d+)', r'=(\d{10,})']
    for pattern in patterns:
        match = re.search(pattern, url_or_id)
        if match and len(match.group(1)) >= 7:
            return match.group(1)

    match = re.search(r'\d{7,}', url_or_id)
    return match.group(0) if match else None

def get_place_keywords(place_id):
    headers = {"User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X)", "Accept-Language": "ko-KR,ko;q=0.9"}

    for category in ['restaurant', 'place', 'cafe']:
        try:
            url = f"https://m.place.naver.com/{category}/{place_id}/home"
            response = requests.get(url, headers=headers, timeout=API_TIMEOUT)
            if response.status_code == 200:
                html = response.content.decode('utf-8', errors='ignore')
                match = re.search(r'"keywordList"\s*:\s*\[((?:"[^"]*",?\s*)*)\]', html)
                if match:
                    keywords = json.loads("[" + match.group(1) + "]")
                    if keywords:
                        return {"success": True, "keywords": keywords}
        except:
            pass

    return {"success": False, "error": "ëŒ€í‘œí‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

def format_place_keywords(input_str):
    place_id = extract_place_id_from_url(input_str.strip())

    if not place_id:
        return f"""[ëŒ€í‘œí‚¤ì›Œë“œ] ì¡°íšŒ ì‹¤íŒ¨
í”Œë ˆì´ìŠ¤ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ì‚¬ìš©ë²•:
ëŒ€í‘œ 1529801174
ëŒ€í‘œ place.naver.com/restaurant/1529801174"""

    result = get_place_keywords(place_id)

    if not result["success"]:
        return f"""[ëŒ€í‘œí‚¤ì›Œë“œ] ì¡°íšŒ ì‹¤íŒ¨
í”Œë ˆì´ìŠ¤ ID: {place_id}
{result['error']}"""

    keywords = result["keywords"]
    response = f"[ëŒ€í‘œí‚¤ì›Œë“œ] {place_id}\n\n"
    for i, kw in enumerate(keywords, 1):
        response += f"{i}. {kw}\n"
    response += f"\në³µì‚¬ìš©: {', '.join(keywords)}"

    return response

#############################################
# ê¸°ëŠ¥ 8: ë„¤ì´ë²„ ìë™ì™„ì„±
#############################################
def get_autocomplete(keyword):
    try:
        params = {"q": keyword, "con": "1", "frm": "nv", "ans": "2", "r_format": "json", "r_enc": "UTF-8", "r_unicode": "0", "t_koreng": "1", "run": "2", "rev": "4", "q_enc": "UTF-8", "st": "100"}
        headers = {"User-Agent": "Mozilla/5.0", "Referer": "https://www.naver.com/"}
        response = requests.get("https://ac.search.naver.com/nx/ac", params=params, headers=headers, timeout=API_TIMEOUT)

        if response.status_code == 200:
            suggestions = []
            for item_group in response.json().get("items", []):
                if isinstance(item_group, list):
                    for item in item_group:
                        if isinstance(item, list) and item:
                            kw = item[0][0] if isinstance(item[0], list) else item[0]
                            if kw and kw != keyword and kw not in suggestions:
                                suggestions.append(kw)
                                if len(suggestions) >= 10:
                                    break
            
            if suggestions:
                result = f"[ìë™ì™„ì„±] {keyword}\n\n"
                for i, s in enumerate(suggestions, 1):
                    result += f"{i}. {s}\n"
                return result
    except:
        pass

    return f"[ìë™ì™„ì„±] {keyword}\n\nê²°ê³¼ ì—†ìŒ"

#############################################
# ê¸°ëŠ¥ 9: ìœ íŠœë¸Œ ìë™ì™„ì„±ì–´
#############################################
def get_youtube_autocomplete(keyword):
    try:
        url = "https://suggestqueries.google.com/complete/search"
        params = {"client": "youtube", "ds": "yt", "q": keyword, "hl": "ko", "gl": "kr"}
        headers = {"User-Agent": "Mozilla/5.0"}

        response = requests.get(url, params=params, headers=headers, timeout=API_TIMEOUT)
        
        if response.status_code == 200:
            text = response.text
            start_idx = text.find('(')
            end_idx = text.rfind(')')
            if start_idx != -1 and end_idx != -1:
                json_str = text[start_idx + 1:end_idx]
                data = json.loads(json_str)
                
                suggestions = []
                if len(data) > 1 and isinstance(data[1], list):
                    for item in data[1]:
                        if isinstance(item, list) and len(item) > 0:
                            suggestion = item[0]
                            if suggestion and suggestion != keyword:
                                suggestions.append(suggestion)
                
                if suggestions:
                    result = f"[ìœ íŠœë¸Œ ìë™ì™„ì„±] {keyword}\n\n"
                    for i, s in enumerate(suggestions[:15], 1):
                        result += f"{i}. {s}\n"
                    return result
        
        return f"[ìœ íŠœë¸Œ ìë™ì™„ì„±] {keyword}\n\nê²°ê³¼ ì—†ìŒ"
        
    except Exception as e:
        return f"[ìœ íŠœë¸Œ ìë™ì™„ì„±] {keyword}\n\nì¡°íšŒ ì‹¤íŒ¨"

#############################################
# ë„ì›€ë§
#############################################
def get_help():
    return """[ì‚¬ìš© ê°€ì´ë“œ]

â–¶ í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰ (ìµœëŒ€ 5ê°œ)
ì˜ˆ) ì¸ì²œë§›ì§‘,ê°•ë‚¨ë§›ì§‘,ì„œìš¸ë§›ì§‘

â–¶ ìƒê¶Œë¶„ì„
ì˜ˆ) ìƒê¶Œ ê°•ë‚¨ë§›ì§‘

â–¶ ì—°ê´€ ê²€ìƒ‰ì–´
ì˜ˆ) ì—°ê´€ ì¸ì²œë§›ì§‘

â–¶ ìë™ì™„ì„±ì–´(ë„¤ì´ë²„)
ì˜ˆ) ìë™ ì¸ì²œë§›ì§‘

â–¶ ìë™ì™„ì„±ì–´(ìœ íŠœë¸Œ)
ì˜ˆ) ìœ íŠœë¸Œ ì¸ì²œë§›ì§‘

â–¶ CPC ê´‘ê³  ë‹¨ê°€
ì˜ˆ) ê´‘ê³  ì¸ì²œë§›ì§‘

â–¶ ëŒ€í‘œ í‚¤ì›Œë“œ
ì˜ˆ) ëŒ€í‘œ 12345678

â–¶ ì¬ë¯¸ ê¸°ëŠ¥
ìš´ì„¸ â†’ ìš´ì„¸ 870114
ë¡œë˜ â†’ ë¡œë˜"""

#############################################
# í…ŒìŠ¤íŠ¸ ë¼ìš°íŠ¸
#############################################
@app.route('/')
def home():
    return "ì„œë²„ ì •ìƒ ì‘ë™ ì¤‘"

@app.route('/test-commercial')
def test_commercial():
    keyword = request.args.get('q', 'ë¶€í‰ë§›ì§‘')
    start = time.time()
    analysis = get_commercial_analysis_fast(keyword)
    result = format_commercial_analysis(analysis)
    elapsed = time.time() - start

    html = f"""<!DOCTYPE html>
<html><head><meta charset="UTF-8"><title>ìƒê¶Œë¶„ì„ í…ŒìŠ¤íŠ¸</title></head>
<body>
<h2>í‚¤ì›Œë“œ: {keyword}</h2>
<h3>ì²˜ë¦¬ ì‹œê°„: {elapsed:.2f}ì´ˆ</h3>
<h3>ê¸€ì ìˆ˜: {len(result)}ì</h3>
<pre style="background:#f5f5f5; padding:20px; white-space:pre-wrap;">{result}</pre>
</body></html>"""
    return html, 200, {'Content-Type': 'text/html; charset=utf-8'}

@app.route('/test-ad')
def test_ad():
    keyword = request.args.get('q', 'ë¶€í‰ë§›ì§‘')
    start = time.time()
    result = get_ad_cost_fast(keyword)
    elapsed = time.time() - start

    html = f"""<!DOCTYPE html>
<html><head><meta charset="UTF-8"><title>ê´‘ê³ ë¶„ì„ í…ŒìŠ¤íŠ¸</title></head>
<body>
<h2>í‚¤ì›Œë“œ: {keyword}</h2>
<h3>ì²˜ë¦¬ ì‹œê°„: {elapsed:.2f}ì´ˆ</h3>
<pre style="background:#f5f5f5; padding:20px; white-space:pre-wrap;">{result}</pre>
</body></html>"""
    return html, 200, {'Content-Type': 'text/html; charset=utf-8'}

#############################################
# ì¹´ì¹´ì˜¤ ìŠ¤í‚¬ (íƒ€ì„ì•„ì›ƒ ë°©ì–´)
#############################################
@app.route('/skill', methods=['POST'])
def kakao_skill():
    start_time = time.time()
    
    try:
        request_data = request.get_json()
        if request_data is None:
            return create_kakao_response("ìš”ì²­ ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        user_utterance = request_data.get("userRequest", {}).get("utterance", "").strip()
        if not user_utterance:
            return create_kakao_response("ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        
        if is_guide_message(user_utterance):
            return create_kakao_response("ê°€ì´ë“œë¥¼ ì°¸ê³ í•´ì„œ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        
        lower_input = user_utterance.lower()
        
        # ë¹ ë¥¸ ì‘ë‹µ (API í˜¸ì¶œ ì—†ìŒ)
        if lower_input in ["ë„ì›€ë§", "ë„ì›€", "ì‚¬ìš©ë²•", "help", "?", "ë©”ë‰´"]:
            return create_kakao_response(get_help())
        
        if lower_input in ["ë¡œë˜", "ë¡œë˜ë²ˆí˜¸", "lotto"]:
            return create_kakao_response(get_lotto())
        
        # ìš´ì„¸
        if lower_input.startswith("ìš´ì„¸ "):
            birthdate = ''.join(filter(str.isdigit, user_utterance))
            if birthdate and len(birthdate) in [6, 8]:
                return create_kakao_response(get_fortune(birthdate))
            return create_kakao_response("ìƒë…„ì›”ì¼ 6ìë¦¬/8ìë¦¬ ì…ë ¥\nì˜ˆ) ìš´ì„¸ 870114")
        
        if lower_input in ["ìš´ì„¸", "ì˜¤ëŠ˜ì˜ìš´ì„¸", "ì˜¤ëŠ˜ìš´ì„¸"]:
            return create_kakao_response(get_fortune())
        
        # íƒ€ì„ì•„ì›ƒ ì²´í¬ í•¨ìˆ˜
        def check_timeout():
            if time.time() - start_time > SKILL_TIMEOUT:
                raise TimeoutError("ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼")
        
        # ìƒê¶Œë¶„ì„ (ìµœì í™” ë²„ì „)
        if any(lower_input.startswith(cmd) for cmd in ["ìƒê¶Œ ", "ìƒì„¸ ", "ì¸ì‚¬ì´íŠ¸ ", "íŠ¸ë Œë“œ "]):
            keyword = user_utterance.split(" ", 1)[1].strip() if " " in user_utterance else ""
            keyword = clean_keyword(keyword)
            if keyword:
                check_timeout()
                analysis = get_commercial_analysis_fast(keyword)
                check_timeout()
                return create_kakao_response(format_commercial_analysis(analysis))
            return create_kakao_response("ì˜ˆ) ìƒê¶Œ ë¶€í‰ë§›ì§‘")
        
        # ìœ íŠœë¸Œ ìë™ì™„ì„±
        if lower_input.startswith("ìœ íŠœë¸Œ ") or lower_input.startswith("yt "):
            keyword = user_utterance.split(" ", 1)[1].strip() if " " in user_utterance else ""
            if keyword:
                return create_kakao_response(get_youtube_autocomplete(keyword))
            return create_kakao_response("ì˜ˆ) ìœ íŠœë¸Œ ë¶€í‰ë§›ì§‘")
        
        # ë„¤ì´ë²„ ìë™ì™„ì„±
        if lower_input.startswith("ìë™ ") or lower_input.startswith("ìë™ì™„ì„± "):
            keyword = user_utterance.split(" ", 1)[1].strip() if " " in user_utterance else ""
            if keyword:
                return create_kakao_response(get_autocomplete(keyword))
            return create_kakao_response("ì˜ˆ) ìë™ ë¶€í‰ë§›ì§‘")
        
        # ëŒ€í‘œí‚¤ì›Œë“œ
        if lower_input.startswith("ëŒ€í‘œ ") or lower_input.startswith("ëŒ€í‘œí‚¤ì›Œë“œ "):
            input_text = user_utterance.split(" ", 1)[1].strip() if " " in user_utterance else ""
            if input_text:
                return create_kakao_response(format_place_keywords(input_text))
            return create_kakao_response("ì˜ˆ) ëŒ€í‘œ 37838432")
        
        # ì—°ê´€ í‚¤ì›Œë“œ
        if lower_input.startswith("ì—°ê´€ "):
            keyword = user_utterance.split(" ", 1)[1].strip() if " " in user_utterance else ""
            keyword = clean_keyword(keyword)
            if keyword:
                return create_kakao_response(get_related_keywords(keyword))
            return create_kakao_response("ì˜ˆ) ì—°ê´€ ë§›ì§‘")
        
        # ê´‘ê³  ë‹¨ê°€ (ìµœì í™” ë²„ì „)
        if lower_input.startswith("ê´‘ê³  "):
            keyword = user_utterance.split(" ", 1)[1].strip() if " " in user_utterance else ""
            keyword = clean_keyword(keyword)
            if keyword:
                check_timeout()
                return create_kakao_response(get_ad_cost_fast(keyword))
            return create_kakao_response("ì˜ˆ) ê´‘ê³  ë§›ì§‘")
        
        # ê¸°ë³¸: ê²€ìƒ‰ëŸ‰ ì¡°íšŒ
        keyword = user_utterance.strip()
        if "," in keyword:
            return create_kakao_response(get_search_volume(keyword))
        else:
            return create_kakao_response(get_search_volume(clean_keyword(keyword)))

    except TimeoutError:
        return create_kakao_response("ì²˜ë¦¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        logger.error(f"ìŠ¤í‚¬ ì˜¤ë¥˜: {str(e)}")
        return create_kakao_response(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

def create_kakao_response(text):
    if len(text) > 1000:
        text = text[:997] + "..."
    return jsonify({"version": "2.0", "template": {"outputs": [{"simpleText": {"text": text}}]}})

#############################################
# ì„œë²„ ì‹¤í–‰
#############################################
if __name__ == '__main__':
    print("=== í™˜ê²½ë³€ìˆ˜ í™•ì¸ ===")
    print(f"ê²€ìƒ‰ê´‘ê³  API: {'âœ…' if NAVER_API_KEY else 'âŒ'}")
    print(f"DataLab API: {'âœ…' if NAVER_CLIENT_ID else 'âŒ'}")
    print(f"Gemini API: {'âœ…' if GEMINI_API_KEY else 'âŒ'}")
    print("====================")

    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)