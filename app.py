from flask import Flask, request, jsonify
import hashlib
import hmac
import base64
import time
import requests
import os
import random
import re
import json
import logging
from datetime import date, timedelta
from urllib.parse import quote

app = Flask(__name__)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

#############################################
# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
#############################################
NAVER_API_KEY = os.environ.get('NAVER_API_KEY', '')
NAVER_SECRET_KEY = os.environ.get('NAVER_SECRET_KEY', '')
NAVER_CUSTOMER_ID = os.environ.get('NAVER_CUSTOMER_ID', '')
NAVER_CLIENT_ID = os.environ.get('NAVER_CLIENT_ID', '')
NAVER_CLIENT_SECRET = os.environ.get('NAVER_CLIENT_SECRET', '')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY', '')
DATA_GO_KR_API_KEY = os.environ.get('DATA_GO_KR_API_KEY', '')


#############################################
# í™˜ê²½ë³€ìˆ˜ ê²€ì¦
#############################################
def validate_required_keys():
    """í•„ìˆ˜ API í‚¤ ê²€ì¦"""
    required = {
        'NAVER_API_KEY': NAVER_API_KEY,
        'NAVER_SECRET_KEY': NAVER_SECRET_KEY,
        'NAVER_CUSTOMER_ID': NAVER_CUSTOMER_ID
    }
    missing = [k for k, v in required.items() if not v]
    if missing:
        logger.warning(f"âš ï¸  Missing required keys: {', '.join(missing)}")
        return False
    return True


#############################################
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
#############################################
def format_number(num):
    if isinstance(num, int):
        return "{:,}".format(num)
    return str(num)

def parse_count(value):
    if value is None:
        return 0
    if isinstance(value, int):
        return value
    if isinstance(value, str):
        if value == "< 10":
            return 5
        try:
            return int(str(value).replace(",", ""))
        except:
            return 0
    return 0

def format_won(value):
    if value >= 100000000:
        return f"{value / 100000000:.1f}ì–µì›"
    elif value >= 10000:
        return f"{value / 10000:.1f}ë§Œì›"
    else:
        return f"{format_number(int(value))}ì›"

def clean_keyword(keyword):
    return keyword.replace(" ", "")

def get_comp_text(comp):
    if comp == "ë†’ìŒ":
        return "[ë†’ìŒ]"
    elif comp == "ì¤‘ê°„":
        return "[ì¤‘ê°„]"
    else:
        return "[ë‚®ìŒ]"

def is_guide_message(text):
    guide_indicators = ["ì‚¬ìš© ê°€ì´ë“œ", "í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰", "ì—°ê´€ ê²€ìƒ‰ì–´", "CPC ê´‘ê³ ", "ìë™ì™„ì„±ì–´", "ëŒ€í‘œí‚¤ì›Œë“œ", "ì¬ë¯¸ ê¸°ëŠ¥"]
    count = sum(1 for indicator in guide_indicators if indicator in text)
    return count >= 4


#############################################
# ì§€ì—­ë³„ ìƒê¶Œ íŠ¹ì„± ë°ì´í„°
#############################################
REGION_DATA = {
    "ë¶€í‰": {
        "code": "2832000000",
        "name": "ì¸ì²œ ë¶€í‰êµ¬",
        "population": "4~5ë§Œëª…",
        "sales": {"min": 2000, "max": 3000},
        "price": {"min": 18000, "max": 22000},
        "weekday_ratio": 70,
        "peak_lunch": 40,
        "peak_dinner": 35,
        "peak_time": "ì ì‹¬ 11:30~13:00",
        "age_group": "2030",
        "characteristics": "ì§ì¥ì¸ ë°€ì§‘, ì£¼ê±° ë³µí•©",
        "avg_size": {"min": 25, "max": 35}
    },
    "ê³„ì–‘": {
        "code": "2824500000",
        "name": "ì¸ì²œ ê³„ì–‘êµ¬",
        "population": "2~3ë§Œëª…",
        "sales": {"min": 1500, "max": 2500},
        "price": {"min": 15000, "max": 20000},
        "weekday_ratio": 65,
        "peak_lunch": 30,
        "peak_dinner": 45,
        "peak_time": "ì €ë… 18:00~20:00",
        "age_group": "3040",
        "characteristics": "ì£¼ê±° ì¤‘ì‹¬, ê°€ì¡± ë‹¨ìœ„",
        "avg_size": {"min": 30, "max": 40}
    },
    "ì†¡ë„": {
        "code": "2826000000",
        "name": "ì¸ì²œ ì—°ìˆ˜êµ¬",
        "population": "3~4ë§Œëª…",
        "sales": {"min": 2500, "max": 4000},
        "price": {"min": 20000, "max": 28000},
        "weekday_ratio": 60,
        "peak_lunch": 30,
        "peak_dinner": 45,
        "peak_time": "ì €ë… 18:30~20:30",
        "age_group": "2030",
        "characteristics": "ì‹ ë„ì‹œ, ì Šì€ ê°€ì¡±, ê³ ì†Œë“",
        "avg_size": {"min": 30, "max": 45}
    },
    "ê°•ë‚¨": {
        "code": "1168000000",
        "name": "ì„œìš¸ ê°•ë‚¨êµ¬",
        "population": "8~10ë§Œëª…",
        "sales": {"min": 4000, "max": 7000},
        "price": {"min": 25000, "max": 40000},
        "weekday_ratio": 55,
        "peak_lunch": 35,
        "peak_dinner": 40,
        "peak_time": "ì ì‹¬/ì €ë… ê· ë“±",
        "age_group": "2040",
        "characteristics": "ê³ ì†Œë“, ì§ì¥ì¸, ìœ í¥",
        "avg_size": {"min": 35, "max": 50}
    },
    "í™ëŒ€": {
        "code": "1144000000",
        "name": "ì„œìš¸ ë§ˆí¬êµ¬",
        "population": "7~9ë§Œëª…",
        "sales": {"min": 3000, "max": 5000},
        "price": {"min": 15000, "max": 25000},
        "weekday_ratio": 45,
        "peak_lunch": 25,
        "peak_dinner": 50,
        "peak_time": "ì €ë…/ì•¼ê°„ 18:00~22:00",
        "age_group": "1020",
        "characteristics": "ìœ í¥, íŠ¸ë Œë“œ, ì™¸êµ­ì¸",
        "avg_size": {"min": 20, "max": 35}
    },
    "ì„œì´ˆ": {
        "code": "1165000000",
        "name": "ì„œìš¸ ì„œì´ˆêµ¬",
        "population": "6~8ë§Œëª…",
        "sales": {"min": 3500, "max": 6000},
        "price": {"min": 22000, "max": 35000},
        "weekday_ratio": 60,
        "peak_lunch": 45,
        "peak_dinner": 35,
        "peak_time": "ì ì‹¬ 11:30~13:30",
        "age_group": "3040",
        "characteristics": "ê³ ì†Œë“, ê°€ì¡±, ë²•ì¡°íƒ€ìš´",
        "avg_size": {"min": 35, "max": 50}
    },
    "ì ì‹¤": {
        "code": "1171000000",
        "name": "ì„œìš¸ ì†¡íŒŒêµ¬",
        "population": "7~9ë§Œëª…",
        "sales": {"min": 3000, "max": 5000},
        "price": {"min": 20000, "max": 30000},
        "weekday_ratio": 50,
        "peak_lunch": 30,
        "peak_dinner": 45,
        "peak_time": "ì €ë…/ì£¼ë§ 17:00~20:00",
        "age_group": "3040",
        "characteristics": "ê°€ì¡±, ì‡¼í•‘, ë¡¯ë°ì›”ë“œ",
        "avg_size": {"min": 30, "max": 45}
    },
    "í•´ìš´ëŒ€": {
        "code": "2626000000",
        "name": "ë¶€ì‚° í•´ìš´ëŒ€êµ¬",
        "population": "5~7ë§Œëª…",
        "sales": {"min": 3000, "max": 5000},
        "price": {"min": 22000, "max": 35000},
        "weekday_ratio": 40,
        "peak_lunch": 25,
        "peak_dinner": 50,
        "peak_time": "ì €ë…/ì£¼ë§ 18:00~21:00",
        "age_group": "ì „ì—°ë ¹",
        "characteristics": "ê´€ê´‘, ê³ ê¸‰, í•´ë³€",
        "avg_size": {"min": 35, "max": 55}
    },
    "ì„œë©´": {
        "code": "2617000000",
        "name": "ë¶€ì‚° ë¶€ì‚°ì§„êµ¬",
        "population": "6~8ë§Œëª…",
        "sales": {"min": 2500, "max": 4000},
        "price": {"min": 18000, "max": 25000},
        "weekday_ratio": 55,
        "peak_lunch": 35,
        "peak_dinner": 40,
        "peak_time": "ì ì‹¬/ì €ë… ê· ë“±",
        "age_group": "2030",
        "characteristics": "ë¶€ì‚° ì¤‘ì‹¬, ìœ í¥, ì‡¼í•‘",
        "avg_size": {"min": 25, "max": 40}
    },
    "ë¶„ë‹¹": {
        "code": "4113500000",
        "name": "ê²½ê¸° ì„±ë‚¨ì‹œ",
        "population": "5~6ë§Œëª…",
        "sales": {"min": 3000, "max": 5000},
        "price": {"min": 22000, "max": 32000},
        "weekday_ratio": 60,
        "peak_lunch": 35,
        "peak_dinner": 40,
        "peak_time": "ì €ë… 18:00~20:00",
        "age_group": "3050",
        "characteristics": "ê³ ì†Œë“, ê°€ì¡±, ITê¸°ì—…",
        "avg_size": {"min": 35, "max": 50}
    },
    "ì¼ì‚°": {
        "code": "4128700000",
        "name": "ê²½ê¸° ê³ ì–‘ì‹œ",
        "population": "4~5ë§Œëª…",
        "sales": {"min": 2000, "max": 3500},
        "price": {"min": 18000, "max": 25000},
        "weekday_ratio": 55,
        "peak_lunch": 30,
        "peak_dinner": 45,
        "peak_time": "ì €ë…/ì£¼ë§ 17:30~20:00",
        "age_group": "3040",
        "characteristics": "ë² ë“œíƒ€ìš´, ê°€ì¡±, í˜¸ìˆ˜ê³µì›",
        "avg_size": {"min": 30, "max": 45}
    },
    "ìˆ˜ì›": {
        "code": "4111100000",
        "name": "ê²½ê¸° ìˆ˜ì›ì‹œ",
        "population": "5~6ë§Œëª…",
        "sales": {"min": 2500, "max": 4000},
        "price": {"min": 18000, "max": 25000},
        "weekday_ratio": 60,
        "peak_lunch": 35,
        "peak_dinner": 40,
        "peak_time": "ì ì‹¬/ì €ë… ê· ë“±",
        "age_group": "2040",
        "characteristics": "ì‚¼ì„±, ì§ì¥ì¸, ì—­ì‚¬",
        "avg_size": {"min": 25, "max": 40}
    },
}

DEFAULT_REGION_DATA = {
    "name": "ì „êµ­",
    "population": "ë°ì´í„° ì—†ìŒ",
    "sales": {"min": 2000, "max": 3500},
    "price": {"min": 18000, "max": 25000},
    "weekday_ratio": 60,
    "peak_lunch": 35,
    "peak_dinner": 40,
    "peak_time": "ì ì‹¬/ì €ë…",
    "age_group": "ì „ì—°ë ¹",
    "characteristics": "ì§€ì—­ íŠ¹ì„± ë¯¸ìƒ",
    "avg_size": {"min": 25, "max": 40}
}

REGION_KEYWORDS = list(REGION_DATA.keys())


#############################################
# ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API
#############################################
def get_naver_api_headers(method="GET", uri="/keywordstool"):
    timestamp = str(int(time.time() * 1000))
    message = f"{timestamp}.{method}.{uri}"
    signature = hmac.new(NAVER_SECRET_KEY.encode('utf-8'), message.encode('utf-8'), hashlib.sha256).digest()
    signature_base64 = base64.b64encode(signature).decode('utf-8')
    return {
        "Content-Type": "application/json; charset=UTF-8",
        "X-Timestamp": timestamp,
        "X-API-KEY": NAVER_API_KEY,
        "X-Customer": str(NAVER_CUSTOMER_ID),
        "X-Signature": signature_base64
    }

def get_keyword_data(keyword, retry=2):
    """í‚¤ì›Œë“œ ë°ì´í„° ì¡°íšŒ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    if not validate_required_keys():
        return {"success": False, "error": "API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
    
    base_url = "https://api.searchad.naver.com"
    uri = "/keywordstool"
    params = {"hintKeywords": keyword, "showDetail": "1"}
    
    for attempt in range(retry + 1):
        try:
            headers = get_naver_api_headers("GET", uri)
            response = requests.get(base_url + uri, headers=headers, params=params, timeout=5)
            
            if response.status_code == 200:
                data = response.json()
                keyword_list = data.get("keywordList", [])
                if keyword_list:
                    return {"success": True, "data": keyword_list}
                return {"success": False, "error": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."}
            
            if attempt < retry:
                logger.debug(f"ì¬ì‹œë„ {attempt + 1}/{retry}: {keyword}")
                time.sleep(0.5)
                continue
            
            return {"success": False, "error": f"API ì˜¤ë¥˜ ({response.status_code})"}
            
        except requests.Timeout:
            if attempt < retry:
                logger.debug(f"íƒ€ì„ì•„ì›ƒ ì¬ì‹œë„ {attempt + 1}/{retry}")
                time.sleep(0.5)
                continue
            return {"success": False, "error": "ìš”ì²­ ì‹œê°„ ì´ˆê³¼"}
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            if attempt < retry:
                time.sleep(0.5)
                continue
            return {"success": False, "error": str(e)}


#############################################
# CPC API
#############################################
def get_performance_estimate(keyword, bids, device='MOBILE', retry=2):
    """ì„±ê³¼ ì˜ˆì¸¡ API (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    uri = '/estimate/performance/keyword'
    url = f'https://api.searchad.naver.com{uri}'
    payload = {
        "device": device,
        "keywordplus": False,
        "key": keyword,
        "bids": bids if isinstance(bids, list) else [bids]
    }
    
    for attempt in range(retry + 1):
        try:
            headers = get_naver_api_headers('POST', uri)
            response = requests.post(url, headers=headers, json=payload, timeout=10)
            
            if response.status_code == 200:
                return {"success": True, "data": response.json()}
            
            if attempt < retry:
                logger.debug(f"ì„±ê³¼ ì˜ˆì¸¡ ì¬ì‹œë„ {attempt + 1}/{retry}")
                time.sleep(0.5)
                continue
            
            return {"success": False, "error": response.text}
            
        except requests.Timeout:
            if attempt < retry:
                logger.debug(f"íƒ€ì„ì•„ì›ƒ ì¬ì‹œë„ {attempt + 1}/{retry}")
                time.sleep(0.5)
                continue
            return {"success": False, "error": "ìš”ì²­ ì‹œê°„ ì´ˆê³¼"}
        except Exception as e:
            logger.error(f"ì„±ê³¼ ì˜ˆì¸¡ ì˜¤ë¥˜: {str(e)}")
            if attempt < retry:
                time.sleep(0.5)
                continue
            return {"success": False, "error": str(e)}


#############################################
# DataLab íŠ¸ë Œë“œ API
#############################################
def get_datalab_trend(keyword, retry=2):
    """íŠ¸ë Œë“œ ë°ì´í„° ì¡°íšŒ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    if not NAVER_CLIENT_ID or not NAVER_CLIENT_SECRET:
        return {"success": False, "error": "DataLab API í‚¤ ë¯¸ì„¤ì •"}
    
    url = "https://openapi.naver.com/v1/datalab/search"
    end_date = date.today() - timedelta(days=1)
    start_date = end_date - timedelta(days=365)
    
    payload = {
        "startDate": start_date.strftime("%Y-%m-%d"),
        "endDate": end_date.strftime("%Y-%m-%d"),
        "timeUnit": "month",
        "keywordGroups": [{"groupName": keyword, "keywords": [keyword]}]
    }
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
        "Content-Type": "application/json"
    }
    
    for attempt in range(retry + 1):
        try:
            response = requests.post(url, headers=headers, json=payload, timeout=5)
            
            if response.status_code == 200:
                data = response.json()
                results = data.get("results", [])
                if results and results[0].get("data"):
                    return {"success": True, "data": results[0]["data"]}
            
            if attempt < retry:
                logger.debug(f"íŠ¸ë Œë“œ ì¬ì‹œë„ {attempt + 1}/{retry}")
                time.sleep(0.5)
                continue
            
            return {"success": False, "error": "íŠ¸ë Œë“œ ë°ì´í„° ì—†ìŒ"}
            
        except requests.Timeout:
            if attempt < retry:
                time.sleep(0.5)
                continue
            return {"success": False, "error": "ìš”ì²­ ì‹œê°„ ì´ˆê³¼"}
        except Exception as e:
            logger.error(f"íŠ¸ë Œë“œ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            if attempt < retry:
                time.sleep(0.5)
                continue
            return {"success": False, "error": str(e)}


#############################################
# ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ë¦¬ë·° ìˆ˜ì§‘
#############################################
def get_place_reviews(keyword, max_count=20):
    """ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ì—ì„œ ìƒìœ„ ì—…ì²´ ë¦¬ë·° ìˆ˜ ìˆ˜ì§‘"""
    
    headers = {
        "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15",
        "Accept": "application/json, text/plain, */*",
        "Accept-Language": "ko-KR,ko;q=0.9",
        "Referer": "https://m.place.naver.com/"
    }
    
    try:
        url = f"https://m.search.naver.com/search.naver?query={quote(keyword)}&where=m_local"
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code != 200:
            return {"success": False, "error": "ê²€ìƒ‰ ì‹¤íŒ¨"}
        
        html = response.text
        
        reviews = []
        blog_reviews = []
        
        review_pattern = r'ë°©ë¬¸ìë¦¬ë·°\s*(\d[\d,]*)'
        review_matches = re.findall(review_pattern, html)
        for match in review_matches[:max_count]:
            try:
                reviews.append(int(match.replace(',', '')))
            except:
                pass
        
        blog_pattern = r'ë¸”ë¡œê·¸ë¦¬ë·°\s*(\d[\d,]*)'
        blog_matches = re.findall(blog_pattern, html)
        for match in blog_matches[:max_count]:
            try:
                blog_reviews.append(int(match.replace(',', '')))
            except:
                pass
        
        if len(reviews) < 5:
            json_pattern = r'"visitorReviewCount"\s*:\s*(\d+)'
            json_matches = re.findall(json_pattern, html)
            for match in json_matches[:max_count]:
                try:
                    reviews.append(int(match))
                except:
                    pass
        
        if len(blog_reviews) < 5:
            json_blog_pattern = r'"blogReviewCount"\s*:\s*(\d+)'
            json_blog_matches = re.findall(json_blog_pattern, html)
            for match in json_blog_matches[:max_count]:
                try:
                    blog_reviews.append(int(match))
                except:
                    pass
        
        if reviews or blog_reviews:
            avg_review = sum(reviews) / len(reviews) if reviews else 0
            avg_blog = sum(blog_reviews) / len(blog_reviews) if blog_reviews else 0
            
            return {
                "success": True,
                "avg_review": int(avg_review),
                "avg_blog": int(avg_blog),
                "review_count": len(reviews),
                "blog_count": len(blog_reviews),
                "reviews": reviews[:20],
                "blog_reviews": blog_reviews[:20]
            }
        
        return {"success": False, "error": "ë¦¬ë·° ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨"}
        
    except Exception as e:
        logger.error(f"ë¦¬ë·° ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)}")
        return {"success": False, "error": str(e)}


#############################################
# ì—…ì²´ ìˆ˜ ì¶”ì •
#############################################
def estimate_business_count(search_volume, comp_idx, region=None):
    """ê²€ìƒ‰ëŸ‰ê³¼ ê²½ìŸë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì—…ì²´ ìˆ˜ ì¶”ì •"""
    
    COMP_RATIO = {
        'ë†’ìŒ': 0.08,
        'ì¤‘ê°„': 0.05,
        'ë‚®ìŒ': 0.03
    }
    
    base_ratio = COMP_RATIO.get(comp_idx, 0.05)
    estimated = int(search_volume * base_ratio)
    
    REGION_MULTIPLIER = {
        'ê°•ë‚¨': 1.3, 'í™ëŒ€': 1.3, 'ì ì‹¤': 1.3, 'í•´ìš´ëŒ€': 1.3,
        'ê³„ì–‘': 0.7, 'ì¼ì‚°': 0.7
    }
    
    if region and region in REGION_MULTIPLIER:
        estimated = int(estimated * REGION_MULTIPLIER[region])
    
    min_count = max(estimated - int(estimated * 0.2), 100)
    max_count = estimated + int(estimated * 0.2)
    
    return {"min": min_count, "max": max_count, "estimated": estimated}


def estimate_reviews(search_volume, comp_idx):
    """ê²€ìƒ‰ëŸ‰ ê¸°ë°˜ í‰ê·  ë¦¬ë·° ìˆ˜ ì¶”ì •"""
    
    if search_volume >= 100000:
        avg_review = random.randint(280, 350)
        avg_blog = random.randint(90, 130)
    elif search_volume >= 50000:
        avg_review = random.randint(180, 250)
        avg_blog = random.randint(60, 90)
    elif search_volume >= 20000:
        avg_review = random.randint(100, 180)
        avg_blog = random.randint(35, 60)
    elif search_volume >= 10000:
        avg_review = random.randint(60, 120)
        avg_blog = random.randint(20, 40)
    else:
        avg_review = random.randint(30, 70)
        avg_blog = random.randint(10, 25)
    
    COMP_MULTIPLIER = {'ë†’ìŒ': 1.2, 'ë‚®ìŒ': 0.8}
    multiplier = COMP_MULTIPLIER.get(comp_idx, 1.0)
    
    avg_review = int(avg_review * multiplier)
    avg_blog = int(avg_blog * multiplier)
    
    return {"avg_review": avg_review, "avg_blog": avg_blog}


def extract_region(keyword):
    """í‚¤ì›Œë“œì—ì„œ ì§€ì—­ëª… ì¶”ì¶œ"""
    for region in REGION_KEYWORDS:
        if region in keyword:
            return region, REGION_DATA[region]
    return None, DEFAULT_REGION_DATA


def calculate_competition_level(search_volume, avg_review):
    """ê²€ìƒ‰ëŸ‰ê³¼ ë¦¬ë·° ìˆ˜ ê¸°ë°˜ ê²½ìŸ ê°•ë„ ê³„ì‚° (1~4)"""
    
    if search_volume >= 100000:
        volume_score = 2
    elif search_volume >= 50000:
        volume_score = 1.5
    elif search_volume >= 20000:
        volume_score = 1
    else:
        volume_score = 0.5
    
    if avg_review >= 300:
        review_score = 2
    elif avg_review >= 200:
        review_score = 1.5
    elif avg_review >= 100:
        review_score = 1
    else:
        review_score = 0.5
    
    total = volume_score + review_score
    if total >= 3.5:
        return 4
    elif total >= 2.5:
        return 3
    elif total >= 1.5:
        return 2
    else:
        return 1


def generate_ad_strategy(analysis):
    """ê²½ìŸ ê°•ë„ ê¸°ë°˜ ë™ì  ê´‘ê³  ì „ëµ ìƒì„±"""
    
    search_volume = 0
    avg_review = 0
    
    if analysis.get("search_data"):
        search_volume = analysis["search_data"]["total"]
    
    if analysis.get("review_data"):
        avg_review = analysis["review_data"]["avg_review"]
    
    level = calculate_competition_level(search_volume, avg_review)
    
    strategies = {
        1: {"blog": {"min": 2, "rec": 4}, "insta": {"min": 2, "rec": 4}, "local": {"min": 1, "rec": 2}, "desc": "ê²½ìŸ ë‚®ìŒ"},
        2: {"blog": {"min": 4, "rec": 6}, "insta": {"min": 4, "rec": 6}, "local": {"min": 2, "rec": 4}, "desc": "ê²½ìŸ ì¤‘ê°„"},
        3: {"blog": {"min": 6, "rec": 8}, "insta": {"min": 6, "rec": 10}, "local": {"min": 3, "rec": 5}, "desc": "ê²½ìŸ ë†’ìŒ"},
        4: {"blog": {"min": 8, "rec": 12}, "insta": {"min": 8, "rec": 12}, "local": {"min": 4, "rec": 6}, "desc": "ê²½ìŸ ë§¤ìš° ë†’ìŒ"}
    }
    
    strategy = strategies[level]
    
    lines = []
    lines.append(f"â–¶ ê´‘ê³  ì „ëµ ({strategy['desc']})")
    lines.append("â€¢ í”Œë ˆì´ìŠ¤ê´‘ê³ : ìƒì‹œ ìš´ì˜")
    lines.append("â€¢ íŒŒì›Œë§í¬: ìƒì‹œ ìš´ì˜")
    lines.append(f"â€¢ ë¸”ë¡œê·¸ì²´í—˜ë‹¨: ìµœì†Œ ì›”{strategy['blog']['min']}íšŒ / ê¶Œì¥ ì›”{strategy['blog']['rec']}íšŒ")
    lines.append(f"â€¢ ì¸ìŠ¤íƒ€/ë©”íƒ€: ìµœì†Œ ì›”{strategy['insta']['min']}íšŒ / ê¶Œì¥ ì›”{strategy['insta']['rec']}íšŒ")
    lines.append(f"â€¢ ì§€ì—­ê´‘ê³ (ë‹¹ê·¼,MY): ìµœì†Œ ì›”{strategy['local']['min']}íšŒ / ê¶Œì¥ ì›”{strategy['local']['rec']}íšŒ")
    
    return "\n".join(lines), level


def get_commercial_analysis(keyword):
    """í‚¤ì›Œë“œ ê¸°ë°˜ ìƒê¶Œ ë¶„ì„"""
    
    region, region_data = extract_region(keyword)
    
    result = {
        "keyword": keyword,
        "region": region,
        "region_data": region_data,
        "search_data": None,
        "trend_data": None,
        "review_data": None,
        "business_count": None
    }
    
    search_result = get_keyword_data(keyword)
    if search_result["success"]:
        kw = search_result["data"][0]
        pc = parse_count(kw.get("monthlyPcQcCnt"))
        mobile = parse_count(kw.get("monthlyMobileQcCnt"))
        total = pc + mobile
        comp_idx = kw.get("compIdx", "ì¤‘ê°„")
        
        result["search_data"] = {
            "total": total,
            "mobile": mobile,
            "pc": pc,
            "mobile_ratio": (mobile * 100 // total) if total > 0 else 0,
            "comp_idx": comp_idx
        }
        
        result["business_count"] = estimate_business_count(total, comp_idx, region)
    
    trend_result = get_datalab_trend(keyword)
    if trend_result["success"]:
        series = trend_result["data"]
        change = 0
        if len(series) >= 6:
            last3 = sum(p.get("ratio", 0) for p in series[-3:]) / 3
            prev3 = sum(p.get("ratio", 0) for p in series[-6:-3]) / 3
            change = ((last3 - prev3) / prev3) * 100 if prev3 > 0 else 0
        result["trend_data"] = {"series": series, "change": change}
    
    review_result = get_place_reviews(keyword)
    if review_result["success"]:
        result["review_data"] = review_result
    else:
        if result["search_data"]:
            estimated = estimate_reviews(
                result["search_data"]["total"],
                result["search_data"]["comp_idx"]
            )
            result["review_data"] = {
                "success": True,
                "avg_review": estimated["avg_review"],
                "avg_blog": estimated["avg_blog"],
                "estimated": True
            }
    
    return result


def format_commercial_analysis(analysis):
    """ìƒê¶Œë¶„ì„ ê²°ê³¼ í¬ë§·íŒ…"""
    
    keyword = analysis["keyword"]
    region = analysis["region"]
    region_data = analysis["region_data"]
    
    lines = [f"[ìƒê¶Œë¶„ì„] {keyword}", ""]
    
    lines.append("â–¶ ê²€ìƒ‰ ë°ì´í„°")
    if analysis["search_data"]:
        sd = analysis["search_data"]
        lines.append(f"ì›” ê²€ìƒ‰ëŸ‰: {format_number(sd['total'])}íšŒ")
        lines.append(f"ëª¨ë°”ì¼ {sd['mobile_ratio']}% / PC {100-sd['mobile_ratio']}%")
        
        if analysis["trend_data"]:
            change = analysis["trend_data"]["change"]
            if change >= 10:
                trend = f"ìƒìŠ¹ (+{change:.0f}%)"
            elif change <= -10:
                trend = f"í•˜ë½ ({change:.0f}%)"
            else:
                trend = f"ìœ ì§€ ({change:+.0f}%)"
            lines.append(f"íŠ¸ë Œë“œ: {trend}")
    else:
        lines.append("ë°ì´í„° ì—†ìŒ")
    lines.append("")
    
    lines.append("â–¶ ì§€ì—­ ìƒê¶Œ")
    if region:
        lines.append(f"ì§€ì—­: {region} ({region_data['name']})")
        lines.append(f"íŠ¹ì„±: {region_data['characteristics']}")
    else:
        lines.append("ì§€ì—­: ì „êµ­")
    
    if analysis["business_count"]:
        bc = analysis["business_count"]
        lines.append(f"ì¶”ì • ì—…ì²´: ì•½ {format_number(bc['min'])}~{format_number(bc['max'])}ê°œ")
    lines.append("")
    
    lines.append("â–¶ ê²½ìŸ ë¶„ì„ (ìƒìœ„ 20ê°œ í‰ê· )")
    if analysis["review_data"]:
        rd = analysis["review_data"]
        lines.append(f"í‰ê·  ë¦¬ë·°: {rd['avg_review']}ê°œ")
        lines.append(f"í‰ê·  ë¸”ë¡œê·¸: {rd['avg_blog']}ê°œ")
        target_review = int(rd['avg_review'] * 1.1)
        lines.append(f"â†’ ëª©í‘œ: ë¦¬ë·° {target_review}ê°œ ì´ìƒ")
    else:
        lines.append("ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
    lines.append("")
    
    lines.append("â–¶ ë§¤ì¶œ ë¶„ì„")
    sales = region_data["sales"]
    price = region_data["price"]
    avg_size = region_data.get("avg_size", {"min": 25, "max": 40})
    
    pyeong_sales_min = int(sales["min"] * 10000 / avg_size["max"] / 10000)
    pyeong_sales_max = int(sales["max"] * 10000 / avg_size["min"] / 10000)
    
    lines.append(f"í‰ê· ë§¤ì¶œ: ì›” {sales['min']:,}~{sales['max']:,}ë§Œì›")
    lines.append(f"ê°ë‹¨ê°€: {price['min']:,}~{price['max']:,}ì›")
    lines.append(f"í‰ë‹¹ë§¤ì¶œ: ì•½ {pyeong_sales_min}~{pyeong_sales_max}ë§Œì› ({avg_size['min']}~{avg_size['max']}í‰ ê¸°ì¤€)")
    lines.append("")
    
    lines.append("â–¶ ê²°ì œ ì‹œê°„ëŒ€")
    weekday = region_data["weekday_ratio"]
    peak_lunch = region_data.get("peak_lunch", 35)
    peak_dinner = region_data.get("peak_dinner", 40)
    other = 100 - peak_lunch - peak_dinner
    
    lines.append(f"ì ì‹¬ 11:30~13:00 ({peak_lunch}%)")
    lines.append(f"ì €ë… 18:00~20:00 ({peak_dinner}%)")
    lines.append(f"ê¸°íƒ€ ì‹œê°„ëŒ€ ({other}%)")
    lines.append(f"ì£¼ì¤‘ {weekday}% / ì£¼ë§ {100-weekday}%")
    lines.append("")
    
    lines.append("â–¶ ì˜ˆìƒ í´ë¦­ë¥  (ì—…ì¢… í‰ê· )")
    lines.append("ëª¨ë°”ì¼: ì•½ 2.3%")
    lines.append("PC: ì•½ 1.1%")
    lines.append("")
    
    ad_strategy, comp_level = generate_ad_strategy(analysis)
    lines.append(ad_strategy)
    lines.append("")
    
    lines.append("â–¶ ì¸ì‚¬ì´íŠ¸")
    insights = generate_insights_v2(analysis, region_data, comp_level)
    lines.extend(insights)
    
    return "\n".join(lines)


def generate_insights_v2(analysis, region_data, comp_level=2):
    """ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ v2"""
    insights = []
    
    peak_lunch = region_data.get("peak_lunch", 35)
    peak_dinner = region_data.get("peak_dinner", 40)
    
    if peak_lunch >= 40:
        insights.append("â€¢ ì ì‹¬ í”¼í¬ â†’ 11ì‹œ ì „ ìƒìœ„ë…¸ì¶œ ì„¸íŒ… í•„ìˆ˜")
    elif peak_dinner >= 45:
        insights.append("â€¢ ì €ë… í”¼í¬ â†’ 17ì‹œ ê´‘ê³  ì§‘ì¤‘, ì›¨ì´íŒ… ê´€ë¦¬")
    else:
        insights.append("â€¢ ì ì‹¬/ì €ë… ê· ë“± â†’ í•˜ë£¨ 2íšŒ í‘¸ì‹œ ì•Œë¦¼ íš¨ê³¼ì ")
    
    char = region_data.get("characteristics", "")
    if "ì§ì¥ì¸" in char:
        insights.append("â€¢ ì§ì¥ì¸ íƒ€ê²Ÿ â†’ ëŸ°ì¹˜ì„¸íŠ¸ 12,000ì›ëŒ€ êµ¬ì„±")
    elif "ê°€ì¡±" in char:
        insights.append("â€¢ ê°€ì¡± íƒ€ê²Ÿ â†’ í‚¤ì¦ˆë©”ë‰´/ë†€ì´ê³µê°„ ê°•ì¡°")
    elif "ìœ í¥" in char or "ë°ì´íŠ¸" in char:
        insights.append("â€¢ ë°ì´íŠ¸ íƒ€ê²Ÿ â†’ ë¶„ìœ„ê¸°/ì¸í…Œë¦¬ì–´ ì‚¬ì§„ í•„ìˆ˜")
    elif "ê´€ê´‘" in char:
        insights.append("â€¢ ê´€ê´‘ê° íƒ€ê²Ÿ â†’ ì™¸êµ­ì–´ ë©”ë‰´/ë„¤ì´ë²„ ì˜ˆì•½ í•„ìˆ˜")
    
    if analysis["review_data"]:
        avg_review = analysis["review_data"]["avg_review"]
        if comp_level >= 3:
            insights.append(f"â€¢ ë¦¬ë·° {avg_review}ê°œ ì´ìƒ í•„ìˆ˜, ì‚¬ì§„ ë¦¬ë·° ìœ ë„")
        else:
            insights.append(f"â€¢ ë¦¬ë·° {avg_review}ê°œ ëª©í‘œ, ê¾¸ì¤€íˆ í™•ë³´")
    
    if analysis["trend_data"]:
        change = analysis["trend_data"]["change"]
        if change <= -15:
            insights.append("â€¢ ê²€ìƒ‰ í•˜ë½ ì¤‘ â†’ SNS ë°”ì´ëŸ´ë¡œ ë°˜ì „ í•„ìš”")
        elif change >= 15:
            insights.append("â€¢ ê²€ìƒ‰ ìƒìŠ¹ ì¤‘ â†’ ì§€ê¸ˆì´ ë§ˆì¼€íŒ… ì ê¸°!")
        else:
            insights.append("â€¢ ê²€ìƒ‰ ìœ ì§€ ì¤‘ â†’ ê¾¸ì¤€í•œ ë¦¬ë·° ê´€ë¦¬ í•„ìˆ˜")
    
    if comp_level == 4:
        insights.append("â€¢ ì´ˆê²½ìŸ â†’ ì°¨ë³„í™” ì»¨ì…‰/ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´ í•„ìˆ˜")
    elif comp_level == 1:
        insights.append("â€¢ ê²½ìŸ ë‚®ìŒ â†’ ì„ ì  íš¨ê³¼, ë¹ ë¥¸ ë¦¬ë·° í™•ë³´ ìœ ë¦¬")
    
    return insights[:5]

#############################################
# ê¸°ëŠ¥ 1: ê²€ìƒ‰ëŸ‰ ì¡°íšŒ
#############################################
def get_search_volume(keyword):
    if "," in keyword:
        keywords = [k.strip() for k in keyword.split(",")]
        if len(keywords) > 5:
            return "ìµœëŒ€ 5ê°œ í‚¤ì›Œë“œê¹Œì§€ë§Œ ì¡°íšŒ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        return get_multi_search_volume(keywords[:5])
    
    result = get_keyword_data(keyword)
    if not result["success"]:
        return f"ì¡°íšŒ ì‹¤íŒ¨: {result['error']}"
    
    kw = result["data"][0]
    pc = parse_count(kw.get("monthlyPcQcCnt"))
    mobile = parse_count(kw.get("monthlyMobileQcCnt"))
    total = pc + mobile
    
    return f"""[ê²€ìƒ‰ëŸ‰] {kw.get('relKeyword', keyword)}

ì›”ê°„ ì´ {format_number(total)}íšŒ
ã„´ ëª¨ë°”ì¼: {format_number(mobile)}íšŒ
ã„´ PC: {format_number(pc)}íšŒ

â€» ë„ì›€ë§: "ë„ì›€ë§" ì…ë ¥"""


def get_multi_search_volume(keywords):
    """ë‹¤ì¤‘ í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰"""
    lines = ["[ê²€ìƒ‰ëŸ‰ ë¹„êµ]", ""]
    
    for keyword in keywords:
        keyword = keyword.replace(" ", "")
        result = get_keyword_data(keyword)
        
        if result["success"]:
            kw = result["data"][0]
            pc = parse_count(kw.get("monthlyPcQcCnt"))
            mobile = parse_count(kw.get("monthlyMobileQcCnt"))
            total = pc + mobile
            mobile_ratio = (mobile * 100 // total) if total > 0 else 0
            
            lines.append(f"â–¸ {kw.get('relKeyword', keyword)}")
            lines.append(f"  {format_number(total)}íšŒ (ëª¨ë°”ì¼ {mobile_ratio}%)")
        else:
            lines.append(f"â–¸ {keyword}")
            lines.append(f"  ì¡°íšŒ ì‹¤íŒ¨")
        lines.append("")
    
    return "\n".join(lines).strip()


#############################################
# ê¸°ëŠ¥ 2: ì—°ê´€ í‚¤ì›Œë“œ
#############################################
def get_related_keywords(keyword):
    try:
        url = f"https://search.naver.com/search.naver?where=nexearch&query={requests.utils.quote(keyword)}"
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36", "Accept-Language": "ko-KR,ko;q=0.9"}
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            pattern = re.findall(r'<div class="tit">([^<]+)</div>', response.text)
            seen = set()
            related = []
            for kw in pattern:
                kw = kw.strip()
                if kw and kw != keyword and kw not in seen and len(kw) > 1:
                    seen.add(kw)
                    related.append(kw)
                    if len(related) >= 10:
                        break
            
            if related:
                result = f"[ì—°ê´€ê²€ìƒ‰ì–´] {keyword}\n\n"
                for i, kw in enumerate(related, 1):
                    result += f"{i}. {kw}\n"
                return result.strip()
        
        return get_related_keywords_api(keyword)
    except:
        return get_related_keywords_api(keyword)


def get_related_keywords_api(keyword):
    result = get_keyword_data(keyword)
    if not result["success"]:
        return f"ì¡°íšŒ ì‹¤íŒ¨: {result['error']}"
    
    keyword_list = result["data"][:10]
    response = f"[ì—°ê´€í‚¤ì›Œë“œ] {keyword}\n\n"
    
    for i, kw in enumerate(keyword_list, 1):
        name = kw.get("relKeyword", "")
        total = parse_count(kw.get("monthlyPcQcCnt")) + parse_count(kw.get("monthlyMobileQcCnt"))
        comp = get_comp_text(kw.get("compIdx", ""))
        response += f"{i}. {name} ({format_number(total)}) {comp}\n"
    
    return response.strip()


#############################################
# ê¸°ëŠ¥ 3: ê´‘ê³  ë‹¨ê°€
#############################################
def get_ad_cost(keyword):
    result = get_keyword_data(keyword)
    if not result["success"]:
        return f"ì¡°íšŒ ì‹¤íŒ¨: {result['error']}"
    
    kw = result["data"][0]
    keyword_name = kw.get('relKeyword', keyword)
    pc_qc = parse_count(kw.get("monthlyPcQcCnt"))
    mobile_qc = parse_count(kw.get("monthlyMobileQcCnt"))
    total_qc = pc_qc + mobile_qc
    mobile_ratio = (mobile_qc * 100 // total_qc) if total_qc > 0 else 0
    comp_idx = kw.get("compIdx", "ì¤‘ê°„")
    
    comp_emoji = "ğŸ”´" if comp_idx == "ë†’ìŒ" else "ğŸŸ¡" if comp_idx == "ì¤‘ê°„" else "ğŸŸ¢"
    
    lines = [f"ğŸ’° \"{keyword_name}\" ê´‘ê³  ë¶„ì„", ""]
    
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append("ğŸ“Š í‚¤ì›Œë“œ ì •ë³´")
    lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    lines.append("")
    lines.append(f"ê²½ìŸë„: {comp_idx} {comp_emoji}")
    lines.append(f"ì›”ê°„ ê²€ìƒ‰ëŸ‰: {format_number(total_qc)}íšŒ")
    lines.append(f"â”œ ëª¨ë°”ì¼: {format_number(mobile_qc)}íšŒ ({mobile_ratio}%)")
    lines.append(f"â”” PC: {format_number(pc_qc)}íšŒ ({100-mobile_ratio}%)")
    lines.append("")
    
    test_bids = [
        100, 200, 300, 400, 500, 600, 700, 800, 900, 1000,
        1200, 1500, 1800, 2000, 2200, 2500, 3000, 3500, 4000, 5000,
        6000, 7000, 8000, 10000, 15000
    ]
    
    mobile_perf = get_performance_estimate(keyword_name, test_bids, 'MOBILE')
    
    efficient_bid = None
    efficient_clicks = 0
    efficient_cost = 0
    daily_budget = 10000
    unique_selected = []
    
    if mobile_perf.get("success"):
        mobile_estimates = mobile_perf["data"].get("estimate", [])
        valid_estimates = [e for e in mobile_estimates if e.get('clicks', 0) > 0]
        
        if valid_estimates:
            lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            lines.append("ğŸ“± ëª¨ë°”ì¼ ì„±ê³¼ ë¶„ì„")
            lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            lines.append("")
            lines.append("ì…ì°°ê°€ë³„ ì˜ˆìƒ ì„±ê³¼")
            lines.append("")
            
            max_clicks = max(e.get('clicks', 0) for e in valid_estimates)
            
            first_max_bid = None
            for e in sorted(valid_estimates, key=lambda x: x.get('bid', 0)):
                if e.get('clicks', 0) == max_clicks:
                    first_max_bid = e.get('bid', 0)
                    break
            
            target_ratios = [0.2, 0.4, 0.6, 0.8, 1.0]
            selected_bids = []

            for i, ratio in enumerate(target_ratios):
                target_clicks = int(max_clicks * ratio)
                closest = min(valid_estimates, 
                            key=lambda x: abs(x.get('clicks', 0) - target_clicks))
                selected_bids.append(closest)

            seen_bids = set()
            unique_selected = []
            for e in selected_bids:
                bid = e.get('bid', 0)
                if bid not in seen_bids:
                    seen_bids.add(bid)
                    unique_selected.append(e)

            max_clicks_in_selected = max(e.get('clicks', 0) for e in unique_selected) if unique_selected else 0

            attempt_count = 0
            while len(unique_selected) < 5 and attempt_count < len(valid_estimates):
                for e in sorted(valid_estimates, key=lambda x: x.get('bid', 0)):
                    bid = e.get('bid', 0)
                    clicks = e.get('clicks', 0)
                    
                    if bid in seen_bids:
                        continue
                    
                    if clicks == max_clicks_in_selected:
                        continue
                    
                    if any(e2.get('clicks', 0) == clicks for e2 in unique_selected):
                        continue
                    
                    unique_selected.append(e)
                    seen_bids.add(bid)
                    break
                else:
                    break
                attempt_count += 1

            first_max_bid_in_selected = None
            for e in sorted(unique_selected, key=lambda x: x.get('bid', 0)):
                if e.get('clicks', 0) == max_clicks_in_selected:
                    first_max_bid_in_selected = e.get('bid', 0)
                    break

            if first_max_bid_in_selected:
                candidates = [e for e in valid_estimates 
                            if e.get('clicks', 0) == max_clicks_in_selected
                            and e.get('bid', 0) > first_max_bid_in_selected]
                if candidates:
                    next_bid = min(candidates, key=lambda x: x.get('bid', 0))
                    if next_bid.get('bid', 0) not in seen_bids:
                        unique_selected.append(next_bid)

            unique_selected.sort(key=lambda x: x.get('bid', 0))
            
            efficient_est = None
            if len(unique_selected) >= 5:
                efficient_est = unique_selected[4]
            elif len(unique_selected) >= 3:
                efficient_est = unique_selected[-1]
            elif len(unique_selected) > 0:
                efficient_est = unique_selected[0]
            
            if efficient_est:
                efficient_bid = efficient_est.get('bid', 0)
                efficient_clicks = efficient_est.get('clicks', 0)
                efficient_cost = efficient_est.get('cost', 0)
                
                if efficient_cost == 0:
                    efficient_cost = int(efficient_clicks * efficient_bid * 0.8)
            
            for est in unique_selected:
                bid = est.get('bid', 0)
                clicks = est.get('clicks', 0)
                cost = est.get('cost', 0)
                
                if cost == 0:
                    cost = int(clicks * bid * 0.8)
                
                lines.append(f"{format_number(bid)}ì› â†’ ì›” {clicks}íšŒ í´ë¦­ | {format_won(cost)}")
            
            if first_max_bid_in_selected:
                lines.append(f"  â†‘ {format_number(first_max_bid_in_selected)}ì› ì´ìƒì€ íš¨ê³¼ ë™ì¼")
            
            if len(unique_selected) < 5:
                lines.append("")
                lines.append("â€» ì…ì°°ê°€ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì¼ë¶€ë§Œ í‘œì‹œ")
            
            lines.append("")
    
    if efficient_bid:
        lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        lines.append("ğŸ¯ ì¶”ì²œ ì…ì°°ê°€")
        lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        lines.append("")
        lines.append(f"âœ… ì¶”ì²œ: {format_number(efficient_bid)}ì›")
        lines.append(f"â”œ ì˜ˆìƒ í´ë¦­: ì›” {efficient_clicks}íšŒ")
        lines.append(f"â”œ ì˜ˆìƒ ë¹„ìš©: ì›” {format_won(efficient_cost)}")
        
        cpc = int(efficient_cost / efficient_clicks) if efficient_clicks > 0 else 0
        lines.append(f"â”œ í´ë¦­ë‹¹ ë¹„ìš©: ì•½ {format_number(cpc)}ì›")
        
        daily_budget = max(efficient_cost / 30, 10000)
        lines.append(f"â”” ì¼ ì˜ˆì‚°: ì•½ {format_won(daily_budget)}")
        lines.append("")
        
        if len(unique_selected) >= 4:
            lower_est = unique_selected[max(0, len(unique_selected) - 3)]
            lower_bid = lower_est.get('bid', 0)
            lower_clicks = lower_est.get('clicks', 0)
            lower_cost = lower_est.get('cost', 0)
            
            if lower_cost == 0:
                lower_cost = int(lower_clicks * lower_bid * 0.8)
            
            if lower_bid < efficient_bid:
                lines.append(f"â€» ì˜ˆì‚° ì ìœ¼ë©´ {format_number(lower_bid)}ì›ë„ ê°€ëŠ¥ (ì›” {lower_clicks}íšŒ/{format_won(lower_cost)})")
        
        lines.append("")
    
    pc_perf = get_performance_estimate(keyword_name, test_bids, 'PC')
    
    if pc_perf.get("success"):
        pc_estimates = pc_perf["data"].get("estimate", [])
        valid_pc = [e for e in pc_estimates if e.get('clicks', 0) > 0]
        
        if valid_pc:
            best_pc = max(valid_pc, key=lambda x: x.get('clicks', 0))
            pc_bid = best_pc.get('bid', 0)
            pc_clicks = best_pc.get('clicks', 0)
            pc_cost = best_pc.get('cost', 0)
            
            if pc_cost == 0:
                pc_cost = int(pc_clicks * pc_bid * 0.8)
            
            lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            lines.append("ğŸ’» PC ì˜ˆìƒ ì„±ê³¼")
            lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            lines.append("")
            lines.append(f"ì¶”ì²œ: {format_number(pc_bid)}ì›")
            lines.append(f"â”œ ì˜ˆìƒ í´ë¦­: ì›” {pc_clicks}íšŒ")
            lines.append(f"â”” ì˜ˆìƒ ë¹„ìš©: ì›” {format_won(pc_cost)}")
            lines.append("")
    
    if efficient_bid:
        lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        lines.append("ğŸ“‹ ìš´ì˜ ê°€ì´ë“œ")
        lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        lines.append("")
        lines.append("ì‹œì‘ ì„¤ì •")
        lines.append(f"â€¢ ì…ì°°ê°€: {format_number(efficient_bid)}ì›")
        lines.append(f"â€¢ ì¼ ì˜ˆì‚°: {format_won(daily_budget)}")
        lines.append(f"â€¢ ì›” ì˜ˆì‚°: ì•½ {format_won(efficient_cost)}")
        lines.append("")
        lines.append("ìš´ì˜ íŒ")
        lines.append("â€¢ 1ì£¼ì¼ í›„ CTR í™•ì¸ (1.5% ì´ìƒ ëª©í‘œ)")
        lines.append("â€¢ ì „í™˜ ë°œìƒ ì‹œ ì˜ˆì‚° ì¦ì•¡ ê²€í† ")
        lines.append("â€¢ í’ˆì§ˆì ìˆ˜ ê´€ë¦¬ë¡œ CPC ì ˆê° ê°€ëŠ¥")
        lines.append("")
        lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    
    return "\n".join(lines)


#############################################
# ê¸°ëŠ¥ 5: ìš´ì„¸
#############################################
def get_fortune(birthdate=None):
    if not GEMINI_API_KEY:
        return get_fortune_fallback(birthdate)
    
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}"
    
    if birthdate:
        if len(birthdate) == 6:
            year = f"19{birthdate[:2]}" if int(birthdate[:2]) > 30 else f"20{birthdate[:2]}"
            month, day = birthdate[2:4], birthdate[4:6]
        elif len(birthdate) == 8:
            year, month, day = birthdate[:4], birthdate[4:6], birthdate[6:8]
        else:
            return get_fortune()
        
        prompt = f"""ìƒë…„ì›”ì¼ {year}ë…„ {month}ì›” {day}ì¼ìƒì˜ ì˜¤ëŠ˜ ìš´ì„¸ë¥¼ ì•Œë ¤ì¤˜.
í˜•ì‹:
[ìš´ì„¸] {year}ë…„ {month}ì›” {day}ì¼ìƒ

ì´ìš´: (2ì¤„)
ì• ì •ìš´: (1ì¤„)
ê¸ˆì „ìš´: (1ì¤„)
ì§ì¥ìš´: (1ì¤„)

í–‰ìš´ì˜ ìˆ«ì: (1-45 ìˆ«ì 3ê°œ)
í–‰ìš´ì˜ ìƒ‰: (1ê°œ)

ì˜¤ëŠ˜ì˜ ì¡°ì–¸: "(í•œë§ˆë””)"

ì¬ë¯¸ìˆê³  ê¸ì •ì ìœ¼ë¡œ. ì´ëª¨í‹°ì½˜ ì—†ì´."""
    else:
        prompt = """ì˜¤ëŠ˜ì˜ ìš´ì„¸ë¥¼ ì•Œë ¤ì¤˜.
í˜•ì‹:
[ì˜¤ëŠ˜ì˜ ìš´ì„¸]

ì´ìš´: (2ì¤„)
ì• ì •ìš´: (1ì¤„)
ê¸ˆì „ìš´: (1ì¤„)
ì§ì¥ìš´: (1ì¤„)

í–‰ìš´ì˜ ìˆ«ì: (1-45 ìˆ«ì 3ê°œ)
í–‰ìš´ì˜ ìƒ‰: (1ê°œ)

ì˜¤ëŠ˜ì˜ í•œë§ˆë””: "(ê²©ì–¸)"

ì¬ë¯¸ìˆê³  ê¸ì •ì ìœ¼ë¡œ. ì´ëª¨í‹°ì½˜ ì—†ì´."""
    
    try:
        response = requests.post(url, json={"contents": [{"parts": [{"text": prompt}]}], "generationConfig": {"temperature": 0.9, "maxOutputTokens": 500}}, timeout=4)
        if response.status_code == 200:
            return response.json()["candidates"][0]["content"]["parts"][0]["text"]
    except:
        pass
    return get_fortune_fallback(birthdate)


def get_fortune_fallback(birthdate=None):
    fortunes = ["ì˜¤ëŠ˜ì€ ìƒˆë¡œìš´ ê¸°íšŒê°€ ì°¾ì•„ì˜¤ëŠ” ë‚ !", "ì¢‹ì€ ì†Œì‹ì´ ë“¤ë ¤ì˜¬ ì˜ˆì •ì´ì—ìš”.", "ì‘ì€ í–‰ìš´ì´ ë‹¹ì‹ ì„ ë”°ë¼ë‹¤ë…€ìš”."]
    love = ["ì„¤ë ˆëŠ” ë§Œë‚¨ì´ ìˆì„ ìˆ˜ ìˆì–´ìš”", "ì†Œì¤‘í•œ ì‚¬ëŒê³¼ ëŒ€í™”ë¥¼ ë‚˜ëˆ ë³´ì„¸ìš”"]
    money = ["ì‘ì€ íš¡ì¬ìˆ˜ê°€ ìˆì–´ìš”", "ì ˆì•½ì´ ë¯¸ë•ì¸ ë‚ "]
    work = ["ì§‘ì¤‘ë ¥ì´ ë†’ì•„ì§€ëŠ” ì‹œê°„", "ìƒˆ í”„ë¡œì íŠ¸ì— ë„ì „í•´ë³´ì„¸ìš”"]
    lucky_numbers = sorted(random.sample(range(1, 46), 3))
    colors = ["ë¹¨ê°„ìƒ‰", "íŒŒë€ìƒ‰", "ë…¸ë€ìƒ‰", "ì´ˆë¡ìƒ‰", "ë³´ë¼ìƒ‰"]
    
    if birthdate and len(birthdate) in [6, 8]:
        if len(birthdate) == 6:
            year = f"19{birthdate[:2]}" if int(birthdate[:2]) > 30 else f"20{birthdate[:2]}"
            month, day = birthdate[2:4], birthdate[4:6]
        else:
            year, month, day = birthdate[:4], birthdate[4:6], birthdate[6:8]
        
        return f"""[ìš´ì„¸] {year}ë…„ {month}ì›” {day}ì¼ìƒ

ì´ìš´: {random.choice(fortunes)}
ì• ì •ìš´: {random.choice(love)}
ê¸ˆì „ìš´: {random.choice(money)}
ì§ì¥ìš´: {random.choice(work)}

í–‰ìš´ì˜ ìˆ«ì: {lucky_numbers[0]}, {lucky_numbers[1]}, {lucky_numbers[2]}
í–‰ìš´ì˜ ìƒ‰: {random.choice(colors)}"""
    
    return f"""[ì˜¤ëŠ˜ì˜ ìš´ì„¸]

ì´ìš´: {random.choice(fortunes)}
ì• ì •ìš´: {random.choice(love)}
ê¸ˆì „ìš´: {random.choice(money)}
ì§ì¥ìš´: {random.choice(work)}

í–‰ìš´ì˜ ìˆ«ì: {lucky_numbers[0]}, {lucky_numbers[1]}, {lucky_numbers[2]}
í–‰ìš´ì˜ ìƒ‰: {random.choice(colors)}"""


#############################################
# ê¸°ëŠ¥ 6: ë¡œë˜
#############################################
def get_lotto():
    if not GEMINI_API_KEY:
        return get_lotto_fallback()
    
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}"
    prompt = """ë¡œë˜ ë²ˆí˜¸ 5ì„¸íŠ¸ ì¶”ì²œ. 1~45, ê° 6ê°œ, ì˜¤ë¦„ì°¨ìˆœ.
í˜•ì‹:
[ë¡œë˜ ë²ˆí˜¸ ì¶”ì²œ]

1) 00, 00, 00, 00, 00, 00
2) 00, 00, 00, 00, 00, 00
3) 00, 00, 00, 00, 00, 00
4) 00, 00, 00, 00, 00, 00
5) 00, 00, 00, 00, 00, 00

í–‰ìš´ì„ ë¹•ë‹ˆë‹¤!
â€» ì¬ë¯¸ë¡œë§Œ ì¦ê¸°ì„¸ìš”!"""
    
    try:
        response = requests.post(url, json={"contents": [{"parts": [{"text": prompt}]}], "generationConfig": {"temperature": 1.0, "maxOutputTokens": 400}}, timeout=4)
        if response.status_code == 200:
            return response.json()["candidates"][0]["content"]["parts"][0]["text"]
    except:
        pass
    return get_lotto_fallback()


def get_lotto_fallback():
    result = "[ë¡œë˜ ë²ˆí˜¸ ì¶”ì²œ]\n\n"
    for i in range(1, 6):
        numbers = sorted(random.sample(range(1, 46), 6))
        result += f"{i}) {', '.join(str(n).zfill(2) for n in numbers)}\n"
    result += "\ní–‰ìš´ì„ ë¹•ë‹ˆë‹¤!\nâ€» ì¬ë¯¸ë¡œë§Œ ì¦ê¸°ì„¸ìš”!"
    return result


#############################################
# ê¸°ëŠ¥ 7: ëŒ€í‘œí‚¤ì›Œë“œ
#############################################
def extract_place_id_from_url(url_or_id):
    url_or_id = url_or_id.strip()
    if url_or_id.isdigit():
        return url_or_id
    
    patterns = [r'/restaurant/(\d+)', r'/place/(\d+)', r'/cafe/(\d+)', r'/hospital/(\d+)', r'/beauty/(\d+)', r'place/(\d+)', r'=(\d{10,})']
    for pattern in patterns:
        match = re.search(pattern, url_or_id)
        if match and len(match.group(1)) >= 7:
            return match.group(1)
    
    match = re.search(r'\d{7,}', url_or_id)
    return match.group(0) if match else None


def get_place_keywords(place_id):
    headers = {"User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X)", "Accept-Language": "ko-KR,ko;q=0.9"}
    
    for category in ['restaurant', 'place', 'cafe', 'hospital', 'beauty']:
        try:
            url = f"https://m.place.naver.com/{category}/{place_id}/home"
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                html = response.content.decode('utf-8', errors='ignore')
                match = re.search(r'"keywordList"\s*:\s*\[((?:"[^"]*",?\s*)*)\]', html)
                if match:
                    keywords = json.loads("[" + match.group(1) + "]")
                    if keywords:
                        return {"success": True, "keywords": keywords}
        except:
            pass
    
    return {"success": False, "error": "ëŒ€í‘œí‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}


def format_place_keywords(input_str):
    place_id = extract_place_id_from_url(input_str.strip())
    
    if not place_id:
        return f"""[ëŒ€í‘œí‚¤ì›Œë“œ] ì¡°íšŒ ì‹¤íŒ¨

í”Œë ˆì´ìŠ¤ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ì‚¬ìš©ë²•:
ëŒ€í‘œ 1529801174
ëŒ€í‘œ place.naver.com/restaurant/1529801174"""
    
    result = get_place_keywords(place_id)
    
    if not result["success"]:
        return f"""[ëŒ€í‘œí‚¤ì›Œë“œ] ì¡°íšŒ ì‹¤íŒ¨

í”Œë ˆì´ìŠ¤ ID: {place_id}
{result['error']}"""
    
    keywords = result["keywords"]
    response = f"[ëŒ€í‘œí‚¤ì›Œë“œ] {place_id}\n\n"
    for i, kw in enumerate(keywords, 1):
        response += f"{i}. {kw}\n"
    response += f"\në³µì‚¬ìš©: {', '.join(keywords)}"
    
    return response


#############################################
# ê¸°ëŠ¥ 8: ë„¤ì´ë²„ ìë™ì™„ì„±
#############################################
def get_autocomplete(keyword):
    try:
        params = {"q": keyword, "con": "1", "frm": "nv", "ans": "2", "r_format": "json", "r_enc": "UTF-8", "r_unicode": "0", "t_koreng": "1", "run": "2", "rev": "4", "q_enc": "UTF-8", "st": "100"}
        headers = {"User-Agent": "Mozilla/5.0", "Referer": "https://www.naver.com/"}
        response = requests.get("https://ac.search.naver.com/nx/ac", params=params, headers=headers, timeout=5)
        
        if response.status_code == 200:
            suggestions = []
            for item_group in response.json().get("items", []):
                if isinstance(item_group, list):
                    for item in item_group:
                        if isinstance(item, list) and item:
                            kw = item[0][0] if isinstance(item[0], list) else item[0]
                            if kw and kw != keyword and kw not in suggestions:
                                suggestions.append(kw)
                                if len(suggestions) >= 10:
                                    break
            
            if suggestions:
                result = f"[ìë™ì™„ì„±] {keyword}\n\n"
                for i, s in enumerate(suggestions, 1):
                    result += f"{i}. {s}\n"
                result += f"\nâ€» ë„ì–´ì“°ê¸°ì— ë”°ë¼ ê²°ê³¼ ë‹¤ë¦„"
                return result
    except:
        pass
    
    return f"[ìë™ì™„ì„±] {keyword}\n\nê²°ê³¼ ì—†ìŒ"


#############################################
# ê¸°ëŠ¥ 9: ìœ íŠœë¸Œ ìë™ì™„ì„±ì–´ (ì‹ ê·œ)
#############################################
def get_youtube_autocomplete(keyword):
    """ìœ íŠœë¸Œ ìë™ì™„ì„± í‚¤ì›Œë“œ ìˆ˜ì§‘"""
    try:
        url = "https://suggestqueries.google.com/complete/search"
        params = {
            "client": "youtube",
            "ds": "yt",
            "q": keyword,
            "hl": "ko",
            "gl": "kr"
        }
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        
        response = requests.get(url, params=params, headers=headers, timeout=5)
        
        if response.status_code == 200:
            text = response.text
            
            start_idx = text.find('(')
            end_idx = text.rfind(')')
            if start_idx != -1 and end_idx != -1:
                json_str = text[start_idx + 1:end_idx]
                data = json.loads(json_str)
                
                suggestions = []
                if len(data) > 1 and isinstance(data[1], list):
                    for item in data[1]:
                        if isinstance(item, list) and len(item) > 0:
                            suggestion = item[0]
                            if suggestion and suggestion != keyword:
                                suggestions.append(suggestion)
                
                if suggestions:
                    result = f"[ìœ íŠœë¸Œ ìë™ì™„ì„±] {keyword}\n\n"
                    for i, s in enumerate(suggestions[:15], 1):
                        result += f"{i}. {s}\n"
                    result += f"\nì´ {len(suggestions[:15])}ê°œ"
                    return result
        
        return f"[ìœ íŠœë¸Œ ìë™ì™„ì„±] {keyword}\n\nê²°ê³¼ ì—†ìŒ"
        
    except Exception as e:
        logger.error(f"ìœ íŠœë¸Œ ìë™ì™„ì„± ì˜¤ë¥˜: {str(e)}")
        return f"[ìœ íŠœë¸Œ ìë™ì™„ì„±] {keyword}\n\nì¡°íšŒ ì‹¤íŒ¨: {str(e)}"


#############################################
# ê¸°ëŠ¥ 10: í”Œë ˆì´ìŠ¤ ìˆœìœ„ ì¡°íšŒ (ì‹ ê·œ)
#############################################
def get_place_ranking(keyword, place_id):
    """ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ì—ì„œ íŠ¹ì • ì—…ì²´ì˜ ìˆœìœ„ ì¡°íšŒ"""
    
    headers = {
        "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15",
        "Accept": "application/json, text/plain, */*",
        "Accept-Language": "ko-KR,ko;q=0.9",
        "Referer": "https://m.place.naver.com/"
    }
    
    try:
        search_url = f"https://map.naver.com/v5/api/search?caller=pcweb&query={quote(keyword)}&type=all&page=1&displayCount=100"
        
        response = requests.get(search_url, headers=headers, timeout=10)
        
        place_ids = []
        place_names = {}
        
        if response.status_code == 200:
            try:
                data = response.json()
                
                if "result" in data and "place" in data["result"]:
                    place_list = data["result"]["place"].get("list", [])
                    for item in place_list:
                        pid = str(item.get("id", ""))
                        name = item.get("name", "")
                        if pid:
                            place_ids.append(pid)
                            place_names[pid] = name
            except:
                pass
        
        if len(place_ids) < 10:
            mobile_url = f"https://m.search.naver.com/search.naver?where=m_local&query={quote(keyword)}"
            response2 = requests.get(mobile_url, headers=headers, timeout=10)
            
            if response2.status_code == 200:
                html = response2.text
                
                patterns = [
                    r'place/(\d{7,})',
                    r'restaurant/(\d{7,})',
                    r'cafe/(\d{7,})',
                    r'"id"\s*:\s*"?(\d{7,})"?',
                    r'data-id="(\d{7,})"'
                ]
                
                for pattern in patterns:
                    matches = re.findall(pattern, html)
                    for match in matches:
                        if match not in place_ids:
                            place_ids.append(match)
        
        seen = set()
        unique_ids = []
        for pid in place_ids:
            if pid not in seen:
                seen.add(pid)
                unique_ids.append(pid)
        
        place_ids = unique_ids[:100]
        
        target_id = str(place_id).strip()
        
        if target_id in place_ids:
            rank = place_ids.index(target_id) + 1
            place_name = place_names.get(target_id, "")
            
            if rank == 1:
                rank_emoji = "ğŸ¥‡"
            elif rank == 2:
                rank_emoji = "ğŸ¥ˆ"
            elif rank == 3:
                rank_emoji = "ğŸ¥‰"
            elif rank <= 5:
                rank_emoji = "â­"
            elif rank <= 10:
                rank_emoji = "âœ…"
            elif rank <= 20:
                rank_emoji = "ğŸ“"
            else:
                rank_emoji = "ğŸ“Œ"
            
            result = f"[í”Œë ˆì´ìŠ¤ ìˆœìœ„] {keyword}\n\n"
            result += f"{rank_emoji} í˜„ì¬ ìˆœìœ„: {rank}ìœ„\n\n"
            result += f"í”Œë ˆì´ìŠ¤ ID: {target_id}\n"
            if place_name:
                result += f"ì—…ì²´ëª…: {place_name}\n"
            result += f"\nì´ ê²€ìƒ‰ ì—…ì²´: {len(place_ids)}ê°œ\n"
            
            if rank > 1:
                result += f"\nâ–¸ ìƒìœ„ ì—…ì²´\n"
                start = max(0, rank - 4)
                for i in range(start, rank - 1):
                    pid = place_ids[i]
                    name = place_names.get(pid, pid)
                    result += f"  {i+1}ìœ„: {name[:15]}\n"
            
            result += f"\nâ–¸ ë‚´ ì—…ì²´\n"
            result += f"  â¤ {rank}ìœ„: {place_name if place_name else target_id}\n"
            
            if rank < len(place_ids):
                result += f"\nâ–¸ í•˜ìœ„ ì—…ì²´\n"
                end = min(len(place_ids), rank + 3)
                for i in range(rank, end):
                    pid = place_ids[i]
                    name = place_names.get(pid, pid)
                    result += f"  {i+1}ìœ„: {name[:15]}\n"
            
            result += "\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            if rank <= 3:
                result += "ğŸ’¡ ìƒìœ„ê¶Œ ìœ ì§€ ì¤‘! ë¦¬ë·° ê´€ë¦¬ í•„ìˆ˜"
            elif rank <= 10:
                result += "ğŸ’¡ 10ìœ„ê¶Œ! ë¦¬ë·° 10ê°œ ì¶”ê°€ë¡œ ìˆœìœ„ ìƒìŠ¹ ê°€ëŠ¥"
            elif rank <= 20:
                result += "ğŸ’¡ 20ìœ„ê¶Œ, ë¸”ë¡œê·¸+ë¦¬ë·° ë³‘í–‰ í•„ìš”"
            else:
                result += "ğŸ’¡ ì§‘ì¤‘ ë§ˆì¼€íŒ… í•„ìš” (ë¦¬ë·°/ë¸”ë¡œê·¸/ê´‘ê³ )"
            
            return result
        
        else:
            result = f"[í”Œë ˆì´ìŠ¤ ìˆœìœ„] {keyword}\n\n"
            result += f"âŒ ìˆœìœ„ê¶Œ ì™¸ (100ìœ„ ë°–)\n\n"
            result += f"í”Œë ˆì´ìŠ¤ ID: {target_id}\n"
            result += f"ê²€ìƒ‰ëœ ì—…ì²´ ìˆ˜: {len(place_ids)}ê°œ\n"
            result += "\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            result += "ğŸ’¡ 100ìœ„ ë°–ì€ ë…¸ì¶œ íš¨ê³¼ ê±°ì˜ ì—†ìŒ\n"
            result += "ğŸ’¡ í”Œë ˆì´ìŠ¤ ê´‘ê³  ë˜ëŠ” ë¦¬ë·° í™•ë³´ í•„ìš”"
            
            if place_ids[:5]:
                result += "\n\nâ–¸ í˜„ì¬ ìƒìœ„ 5ê°œ ì—…ì²´\n"
                for i, pid in enumerate(place_ids[:5], 1):
                    name = place_names.get(pid, pid)
                    result += f"  {i}ìœ„: {name[:20]}\n"
            
            return result
    
    except Exception as e:
        logger.error(f"ìˆœìœ„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return f"[í”Œë ˆì´ìŠ¤ ìˆœìœ„] ì¡°íšŒ ì‹¤íŒ¨\n\nì˜¤ë¥˜: {str(e)}"


def parse_ranking_input(user_input):
    """ìˆœìœ„ ì¡°íšŒ ì…ë ¥ íŒŒì‹±: 'ìˆœìœ„ í‚¤ì›Œë“œ í”Œë ˆì´ìŠ¤ID'"""
    
    text = user_input.strip()
    if text.startswith("ìˆœìœ„ "):
        text = text[3:].strip()
    elif text.startswith("ìˆœìœ„"):
        text = text[2:].strip()
    
    words = text.split()
    
    place_id = None
    keyword_parts = []
    
    for i, word in enumerate(reversed(words)):
        extracted = extract_place_id_from_url(word)
        if extracted:
            place_id = extracted
            keyword_parts = words[:len(words) - i - 1]
            break
        elif word.isdigit() and len(word) >= 7:
            place_id = word
            keyword_parts = words[:len(words) - i - 1]
            break
    
    keyword = " ".join(keyword_parts).strip()
    
    return keyword, place_id


#############################################
# ë„ì›€ë§
#############################################
def get_help():
    return """[ì‚¬ìš© ê°€ì´ë“œ]

â–¶ í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰ (ìµœëŒ€ 5ê°œ)
ì˜ˆ) ì¸ì²œë§›ì§‘,ê°•ë‚¨ë§›ì§‘,ì„œìš¸ë§›ì§‘

â–¶ ìƒê¶Œë¶„ì„ (íŠ¸ë Œë“œ+ë§¤ì¶œ+ê³ ê°)
ì˜ˆ) ìƒê¶Œ ê°•ë‚¨ë§›ì§‘

â–¶ ì—°ê´€ ê²€ìƒ‰ì–´
ì˜ˆ) ì—°ê´€ ì¸ì²œë§›ì§‘

â–¶ ìë™ì™„ì„±ì–´ (ë„¤ì´ë²„)
ì˜ˆ) ìë™ ì¸ì²œë§›ì§‘

â–¶ ìœ íŠœë¸Œ ìë™ì™„ì„±ì–´
ì˜ˆ) ìœ íŠœë¸Œ ì¸ì²œë§›ì§‘

â–¶ CPC ê´‘ê³  ë‹¨ê°€
ì˜ˆ) ê´‘ê³  ì¸ì²œë§›ì§‘

â–¶ ëŒ€í‘œ í‚¤ì›Œë“œ
ì˜ˆ) ëŒ€í‘œ 12345678

â–¶ í”Œë ˆì´ìŠ¤ ìˆœìœ„ ì¡°íšŒ
ì˜ˆ) ìˆœìœ„ ë¶€í‰ë§›ì§‘ 12345678

â–¶ ì¬ë¯¸ ê¸°ëŠ¥
ì˜ˆ) ìš´ì„¸ 870114
ì˜ˆ) ë¡œë˜"""


#############################################
# í…ŒìŠ¤íŠ¸ ë¼ìš°íŠ¸
#############################################
@app.route('/')
def home():
    return "ì„œë²„ ì •ìƒ ì‘ë™ ì¤‘"


@app.route('/test-review')
def test_review():
    keyword = request.args.get('q', 'ë¶€í‰ë§›ì§‘')
    result = get_place_reviews(keyword)
    
    html = f"""<!DOCTYPE html>
<html><head><meta charset="UTF-8"><title>ë¦¬ë·° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸</title></head>
<body>
<h2>í‚¤ì›Œë“œ: {keyword}</h2>
<p><b>ì„±ê³µ:</b> {result.get('success')}</p>
<p><b>í‰ê·  ë¦¬ë·°:</b> {result.get('avg_review', 'N/A')}</p>
<p><b>í‰ê·  ë¸”ë¡œê·¸:</b> {result.get('avg_blog', 'N/A')}</p>
<p><b>ìˆ˜ì§‘ ê°œìˆ˜:</b> ë¦¬ë·° {result.get('review_count', 0)}ê°œ / ë¸”ë¡œê·¸ {result.get('blog_count', 0)}ê°œ</p>
"""
    if result.get('reviews'):
        html += f"<p><b>ë¦¬ë·° ë¦¬ìŠ¤íŠ¸:</b> {result['reviews']}</p>"
    if result.get('error'):
        html += f"<p style='color:red'>ì˜¤ë¥˜: {result['error']}</p>"
    html += "</body></html>"
    return html, 200, {'Content-Type': 'text/html; charset=utf-8'}


@app.route('/test-commercial')
def test_commercial():
    keyword = request.args.get('q', 'ë¶€í‰ë§›ì§‘')
    analysis = get_commercial_analysis(keyword)
    result = format_commercial_analysis(analysis)
    
    html = f"""<!DOCTYPE html>
<html><head><meta charset="UTF-8"><title>ìƒê¶Œë¶„ì„ í…ŒìŠ¤íŠ¸</title></head>
<body>
<h2>í‚¤ì›Œë“œ: {keyword}</h2>
<h3>ê¸€ì ìˆ˜: {len(result)}ì</h3>
<pre style="background:#f5f5f5; padding:20px; white-space:pre-wrap;">{result}</pre>
</body></html>"""
    return html, 200, {'Content-Type': 'text/html; charset=utf-8'}


@app.route('/test-place')
def test_place():
    place_id = request.args.get('id', '37838432')
    result = get_place_keywords(place_id)
    
    html = f"<h2>ID: {place_id}</h2><h3>{'ì„±ê³µ' if result['success'] else 'ì‹¤íŒ¨'}</h3>"
    if result['success']:
        html += "<ul>" + "".join(f"<li>{kw}</li>" for kw in result['keywords']) + "</ul>"
    else:
        html += f"<p>{result.get('error')}</p>"
    
    return html, 200, {'Content-Type': 'text/html; charset=utf-8'}


@app.route('/test-ad')
def test_ad():
    keyword = request.args.get('q', 'ë¶€í‰ë§›ì§‘')
    result = get_ad_cost(keyword)
    
    html = f"""<!DOCTYPE html>
<html><head><meta charset="UTF-8"><title>ê´‘ê³ ë¶„ì„ í…ŒìŠ¤íŠ¸</title></head>
<body>
<h2>í‚¤ì›Œë“œ: {keyword}</h2>
<h3>ê¸€ì ìˆ˜: {len(result)}ì</h3>
<pre style="background:#f5f5f5; padding:20px; white-space:pre-wrap;">{result}</pre>
</body></html>"""
    return html, 200, {'Content-Type': 'text/html; charset=utf-8'}


@app.route('/test-youtube')
def test_youtube():
    keyword = request.args.get('q', 'ë¶€í‰ë§›ì§‘')
    result = get_youtube_autocomplete(keyword)
    
    html = f"""<!DOCTYPE html>
<html><head><meta charset="UTF-8"><title>ìœ íŠœë¸Œ ìë™ì™„ì„± í…ŒìŠ¤íŠ¸</title></head>
<body>
<h2>í‚¤ì›Œë“œ: {keyword}</h2>
<pre style="background:#f5f5f5; padding:20px; white-space:pre-wrap;">{result}</pre>
</body></html>"""
    return html, 200, {'Content-Type': 'text/html; charset=utf-8'}


@app.route('/test-ranking')
def test_ranking():
    keyword = request.args.get('q', 'ë¶€í‰ë§›ì§‘')
    place_id = request.args.get('id', '1234567890')
    result = get_place_ranking(keyword, place_id)
    
    html = f"""<!DOCTYPE html>
<html><head><meta charset="UTF-8"><title>í”Œë ˆì´ìŠ¤ ìˆœìœ„ í…ŒìŠ¤íŠ¸</title></head>
<body>
<h2>í‚¤ì›Œë“œ: {keyword}</h2>
<h3>í”Œë ˆì´ìŠ¤ ID: {place_id}</h3>
<pre style="background:#f5f5f5; padding:20px; white-space:pre-wrap;">{result}</pre>
</body></html>"""
    return html, 200, {'Content-Type': 'text/html; charset=utf-8'}


#############################################
# ì¹´ì¹´ì˜¤ ìŠ¤í‚¬
#############################################
@app.route('/skill', methods=['POST'])
def kakao_skill():
    try:
        request_data = request.get_json()
        if request_data is None:
            return create_kakao_response("ìš”ì²­ ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
        user_utterance = request_data.get("userRequest", {}).get("utterance", "").strip()
        if not user_utterance:
            return create_kakao_response("ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        
        if is_guide_message(user_utterance):
            return create_kakao_response("ê°€ì´ë“œë¥¼ ì°¸ê³ í•´ì„œ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        
        lower_input = user_utterance.lower()
        
        # ë„ì›€ë§
        if lower_input in ["ë„ì›€ë§", "ë„ì›€", "ì‚¬ìš©ë²•", "help", "?", "ë©”ë‰´"]:
            return create_kakao_response(get_help())
        
        # ìš´ì„¸
        if lower_input.startswith("ìš´ì„¸ "):
            birthdate = ''.join(filter(str.isdigit, user_utterance))
            if birthdate and len(birthdate) in [6, 8]:
                return create_kakao_response(get_fortune(birthdate))
            return create_kakao_response("ìƒë…„ì›”ì¼ 6ìë¦¬/8ìë¦¬ ì…ë ¥\nì˜ˆ) ìš´ì„¸ 870114")
        
        if lower_input in ["ìš´ì„¸", "ì˜¤ëŠ˜ì˜ìš´ì„¸", "ì˜¤ëŠ˜ìš´ì„¸"]:
            return create_kakao_response(get_fortune())
        
        # ë¡œë˜
        if lower_input in ["ë¡œë˜", "ë¡œë˜ë²ˆí˜¸", "lotto"]:
            return create_kakao_response(get_lotto())
        
        # ìƒê¶Œë¶„ì„
        if any(lower_input.startswith(cmd) for cmd in ["ìƒê¶Œ ", "ìƒì„¸ ", "ì¸ì‚¬ì´íŠ¸ ", "íŠ¸ë Œë“œ "]):
            keyword = user_utterance.split(" ", 1)[1].strip() if " " in user_utterance else ""
            keyword = clean_keyword(keyword)
            if keyword:
                analysis = get_commercial_analysis(keyword)
                return create_kakao_response(format_commercial_analysis(analysis))
            return create_kakao_response("ì˜ˆ) ìƒê¶Œ ë¶€í‰ë§›ì§‘")
        
        # ìœ íŠœë¸Œ ìë™ì™„ì„± (ì‹ ê·œ)
        if lower_input.startswith("ìœ íŠœë¸Œ ") or lower_input.startswith("yt "):
            keyword = user_utterance.split(" ", 1)[1].strip() if " " in user_utterance else ""
            if keyword:
                return create_kakao_response(get_youtube_autocomplete(keyword))
            return create_kakao_response("ì˜ˆ) ìœ íŠœë¸Œ ë¶€í‰ë§›ì§‘")
        
        # ë„¤ì´ë²„ ìë™ì™„ì„±
        if lower_input.startswith("ìë™ ") or lower_input.startswith("ìë™ì™„ì„± "):
            keyword = user_utterance.split(" ", 1)[1].strip() if " " in user_utterance else ""
            if keyword:
                return create_kakao_response(get_autocomplete(keyword))
            return create_kakao_response("ì˜ˆ) ìë™ ë¶€í‰ë§›ì§‘")
        
        # í”Œë ˆì´ìŠ¤ ìˆœìœ„ ì¡°íšŒ (ì‹ ê·œ)
        if lower_input.startswith("ìˆœìœ„ "):
            keyword, place_id = parse_ranking_input(user_utterance)
            if keyword and place_id:
                return create_kakao_response(get_place_ranking(keyword, place_id))
            return create_kakao_response("ì˜ˆ) ìˆœìœ„ ë¶€í‰ë§›ì§‘ 1234567890\nì˜ˆ) ìˆœìœ„ ê°•ë‚¨ë§›ì§‘ place.naver.com/restaurant/12345")
        
        # ëŒ€í‘œí‚¤ì›Œë“œ
        if lower_input.startswith("ëŒ€í‘œ ") or lower_input.startswith("ëŒ€í‘œí‚¤ì›Œë“œ "):
            input_text = user_utterance.split(" ", 1)[1].strip() if " " in user_utterance else ""
            if input_text:
                return create_kakao_response(format_place_keywords(input_text))
            return create_kakao_response("ì˜ˆ) ëŒ€í‘œ 37838432")
        
        # ì—°ê´€ í‚¤ì›Œë“œ
        if lower_input.startswith("ì—°ê´€ "):
            keyword = user_utterance.split(" ", 1)[1].strip() if " " in user_utterance else ""
            keyword = clean_keyword(keyword)
            if keyword:
                return create_kakao_response(get_related_keywords(keyword))
            return create_kakao_response("ì˜ˆ) ì—°ê´€ ë§›ì§‘")
        
        # ê´‘ê³  ë‹¨ê°€
        if lower_input.startswith("ê´‘ê³  "):
            keyword = user_utterance.split(" ", 1)[1].strip() if " " in user_utterance else ""
            keyword = clean_keyword(keyword)
            if keyword:
                return create_kakao_response(get_ad_cost(keyword))
            return create_kakao_response("ì˜ˆ) ê´‘ê³  ë§›ì§‘")
        
        # ê¸°ë³¸: ê²€ìƒ‰ëŸ‰ ì¡°íšŒ
        keyword = user_utterance.strip()
        if "," in keyword:
            return create_kakao_response(get_search_volume(keyword))
        else:
            return create_kakao_response(get_search_volume(clean_keyword(keyword)))
    
    except Exception as e:
        logger.error(f"ìŠ¤í‚¬ ì˜¤ë¥˜: {str(e)}")
        return create_kakao_response(f"ì˜¤ë¥˜: {str(e)}")


def create_kakao_response(text):
    if len(text) > 1000:
        text = text[:997] + "..."
    return jsonify({"version": "2.0", "template": {"outputs": [{"simpleText": {"text": text}}]}})


#############################################
# ì„œë²„ ì‹¤í–‰
#############################################
if __name__ == '__main__':
    print("=== í™˜ê²½ë³€ìˆ˜ í™•ì¸ ===")
    print(f"ê²€ìƒ‰ê´‘ê³  API: {'âœ…' if NAVER_API_KEY else 'âŒ'}")
    print(f"DataLab API: {'âœ…' if NAVER_CLIENT_ID else 'âŒ'}")
    print(f"Gemini API: {'âœ…' if GEMINI_API_KEY else 'âŒ'}")
    print(f"ê³µê³µë°ì´í„° API: {'âœ…' if DATA_GO_KR_API_KEY else 'âŒ'}")
    
    if validate_required_keys():
        print("âœ… í•„ìˆ˜ API í‚¤ í™•ì¸ ì™„ë£Œ")
    else:
        print("âš ï¸  ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    
    print("====================")
    
    if os.environ.get('PRODUCTION') == 'true':
        logging.basicConfig(level=logging.WARNING)
        logger.setLevel(logging.WARNING)
        print("ìš´ì˜ ëª¨ë“œ: WARNING ë ˆë²¨ ë¡œê·¸")
    else:
        print("ê°œë°œ ëª¨ë“œ: INFO ë ˆë²¨ ë¡œê·¸")
    
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)

