from flask import Flask, request, jsonify
import hashlib
import hmac
import base64
import time
import requests
import os
import random
import re
import json
import logging
from datetime import date, timedelta
from urllib.parse import quote

app = Flask(__name__)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

#############################################
# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
#############################################

# ê²€ìƒ‰ê´‘ê³  API í™˜ê²½ë³€ìˆ˜
NAVER_API_KEY = os.environ.get('NAVER_API_KEY', '')
NAVER_SECRET_KEY = os.environ.get('NAVER_SECRET_KEY', '')
NAVER_CUSTOMER_ID = os.environ.get('NAVER_CUSTOMER_ID', '')

# ë„¤ì´ë²„ DataLab API í™˜ê²½ë³€ìˆ˜ (ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ/ì¸ì‚¬ì´íŠ¸ìš©)
NAVER_CLIENT_ID = os.environ.get('NAVER_CLIENT_ID', '')
NAVER_CLIENT_SECRET = os.environ.get('NAVER_CLIENT_SECRET', '')

# Gemini API í™˜ê²½ë³€ìˆ˜ (ìš´ì„¸/ë¡œë˜ìš©)
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY', '')


#############################################
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
#############################################
def format_number(num):
    if isinstance(num, int):
        return "{:,}".format(num)
    return str(num)


def parse_count(value):
    if value is None:
        return 0
    if isinstance(value, int):
        return value
    if isinstance(value, str):
        if value == "< 10":
            return 5
        try:
            return int(str(value).replace(",", ""))
        except:
            return 0
    return 0


def format_won(value):
    if value >= 100000000:
        return f"{value / 100000000:.1f}ì–µì›"
    elif value >= 10000:
        return f"{value / 10000:.1f}ë§Œì›"
    else:
        return f"{format_number(int(value))}ì›"


def clean_keyword(keyword):
    return keyword.replace(" ", "")


def get_comp_text(comp):
    """ê²½ìŸë„ í…ìŠ¤íŠ¸ ë°˜í™˜"""
    if comp == "ë†’ìŒ":
        return "[ë†’ìŒ]"
    elif comp == "ì¤‘ê°„":
        return "[ì¤‘ê°„]"
    else:
        return "[ë‚®ìŒ]"


def is_guide_message(text):
    """ì‚¬ìš© ê°€ì´ë“œ ë©”ì‹œì§€ì¸ì§€ í™•ì¸"""
    guide_indicators = [
        "ì‚¬ìš© ê°€ì´ë“œ", "ì‚¬ìš©ê°€ì´ë“œ",
        "í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰", "ì—°ê´€ ê²€ìƒ‰ì–´", "CPC ê´‘ê³ ",
        "ë¸”ë¡œê·¸ ìƒìœ„ê¸€", "ìë™ì™„ì„±ì–´", "ëŒ€í‘œí‚¤ì›Œë“œ",
        "ì¬ë¯¸ ê¸°ëŠ¥", "ê²½ìŸë„:"
    ]

    count = sum(1 for indicator in guide_indicators if indicator in text)
    if count >= 4:
        return True
    return False


#############################################
# ì§€ì—­ í‚¤ì›Œë“œ ëª©ë¡ (í™•ì¥)
#############################################
REGION_KEYWORDS = [
    # ê´‘ì—­ì‹œ/íŠ¹ë³„ì‹œ
    "ì„œìš¸", "ì¸ì²œ", "ë¶€ì‚°", "ëŒ€êµ¬", "ëŒ€ì „", "ê´‘ì£¼", "ìš¸ì‚°", "ì„¸ì¢…",
    # ë„
    "ê²½ê¸°", "ê°•ì›", "ì¶©ë¶", "ì¶©ë‚¨", "ì „ë¶", "ì „ë‚¨", "ê²½ë¶", "ê²½ë‚¨", "ì œì£¼",
    # ì„œìš¸ ì£¼ìš” ì§€ì—­
    "ê°•ë‚¨", "ê°•ë¶", "ê°•ì„œ", "ê°•ë™", "ì†¡íŒŒ", "ì„œì´ˆ", "ë§ˆí¬", "ì˜ë“±í¬", "ìš©ì‚°",
    "ì¢…ë¡œ", "ì¤‘êµ¬", "ì„±ë™", "ê´‘ì§„", "ë™ëŒ€ë¬¸", "ì¤‘ë‘", "ì„±ë¶", "ë„ë´‰", "ë…¸ì›",
    "ì€í‰", "ì„œëŒ€ë¬¸", "ì–‘ì²œ", "êµ¬ë¡œ", "ê¸ˆì²œ", "ê´€ì•…", "ë™ì‘", "í™ëŒ€", "í•©ì •",
    "ì—°ë‚¨", "ì´íƒœì›", "í•œë‚¨", "ì••êµ¬ì •", "ì²­ë‹´", "ì‚¼ì„±", "ì ì‹¤", "ê±´ëŒ€", "ì™•ì‹­ë¦¬",
    # ê²½ê¸° ì£¼ìš” ì§€ì—­
    "ìˆ˜ì›", "ì„±ë‚¨", "ë¶„ë‹¹", "ê³ ì–‘", "ì¼ì‚°", "ìš©ì¸", "ë¶€ì²œ", "ì•ˆì‚°", "ì•ˆì–‘",
    "ë‚¨ì–‘ì£¼", "í™”ì„±", "í‰íƒ", "ì˜ì •ë¶€", "ì‹œí¥", "íŒŒì£¼", "ê¹€í¬", "ê´‘ëª…", "êµ°í¬",
    "ì´ì²œ", "ì˜¤ì‚°", "í•˜ë‚¨", "ì–‘ì£¼", "êµ¬ë¦¬", "ì•ˆì„±", "í¬ì²œ", "ì˜ì™•", "ì—¬ì£¼", "ë™íƒ„",
    # ì¸ì²œ ì£¼ìš” ì§€ì—­
    "ë¶€í‰", "ê³„ì–‘", "ë‚¨ë™", "ì—°ìˆ˜", "ì†¡ë„", "ì²­ë¼", "ê²€ë‹¨", "ê°•í™”", "ì˜¹ì§„",
    # ë¶€ì‚° ì£¼ìš” ì§€ì—­
    "í•´ìš´ëŒ€", "ì„œë©´", "ê´‘ì•ˆë¦¬", "ë‚¨í¬ë™", "ì„¼í…€", "ì‚¬ìƒ", "ì‚¬í•˜", "ë™ë˜",
    "ê¸ˆì •", "ì—°ì‚°", "ë•ì²œ", "ê¸°ì¥",
    # ê¸°íƒ€ ì£¼ìš” ë„ì‹œ
    "ì²œì•ˆ", "ì²­ì£¼", "ì „ì£¼", "í¬í•­", "ì°½ì›", "ë§ˆì‚°", "ì§„í•´", "ì œì£¼ì‹œ", "ì„œê·€í¬",
    "ì¶˜ì²œ", "ì›ì£¼", "ê°•ë¦‰", "ì†ì´ˆ", "ì—¬ìˆ˜", "ìˆœì²œ", "ëª©í¬", "êµ°ì‚°", "ìµì‚°"
]


#############################################
# ì§€ì—­ ë¶„ì„ í•¨ìˆ˜
#############################################
def build_region_text(keyword):
    """í‚¤ì›Œë“œ ì•ˆì— í¬í•¨ëœ ì§€ì—­ëª… íƒì§€"""
    found = []
    for r in REGION_KEYWORDS:
        if r in keyword:
            found.append(r)

    if found:
        found.sort(key=len, reverse=True)
        primary_region = found[0]

        # ì§€ì—­ íŠ¹ì„± ë¶„ì„
        region_info = {
            "ê°•ë‚¨": ("ì„œìš¸ ê°•ë‚¨ê¶Œ", "ê³ ì†Œë“ì¸µ, 2030 ì§ì¥ì¸ ë°€ì§‘"),
            "ì„œì´ˆ": ("ì„œìš¸ ê°•ë‚¨ê¶Œ", "ê³ ì†Œë“ì¸µ, ê°€ì¡± ë‹¨ìœ„ ë§ìŒ"),
            "ì†¡íŒŒ": ("ì„œìš¸ ê°•ë‚¨ê¶Œ", "ì‹ í˜¼ë¶€ë¶€, ì Šì€ ê°€ì¡± ë§ìŒ"),
            "í™ëŒ€": ("ì„œìš¸ ë§ˆí¬ê¶Œ", "1020 ìœ ë™ì¸êµ¬, íŠ¸ë Œë“œ ë¯¼ê°"),
            "ë§ˆí¬": ("ì„œìš¸ ë§ˆí¬ê¶Œ", "2030 ì§ì¥ì¸, ë¬¸í™” ì†Œë¹„ì¸µ"),
            "í•©ì •": ("ì„œìš¸ ë§ˆí¬ê¶Œ", "2030 ì—¬ì„± ë¹„ìœ¨ ë†’ìŒ"),
            "ì´íƒœì›": ("ì„œìš¸ ìš©ì‚°ê¶Œ", "ì™¸êµ­ì¸, 2030 íŠ¸ë Œë“œì„¸í„°"),
            "í•´ìš´ëŒ€": ("ë¶€ì‚° í•´ìš´ëŒ€ê¶Œ", "ê´€ê´‘ê°, ê³ ì†Œë“ì¸µ í˜¼ì¬"),
            "ê´‘ì•ˆë¦¬": ("ë¶€ì‚° í•´ìš´ëŒ€ê¶Œ", "2030 ë°ì´íŠ¸ ëª…ì†Œ"),
            "ì„œë©´": ("ë¶€ì‚° ì¤‘ì‹¬ê¶Œ", "ì „ ì—°ë ¹ëŒ€ ìœ ë™ì¸êµ¬"),
            "ë¶€í‰": ("ì¸ì²œ ë¶€í‰ê¶Œ", "2040 ì§ì¥ì¸, ì£¼ê±° ë°€ì§‘"),
            "ì†¡ë„": ("ì¸ì²œ ì—°ìˆ˜ê¶Œ", "ê³ ì†Œë“ ì‹ ë„ì‹œ, ì Šì€ ê°€ì¡±"),
            "ë¶„ë‹¹": ("ê²½ê¸° ì„±ë‚¨", "ê³ ì†Œë“ì¸µ, 4050 ê°€ì¡±"),
            "ì¼ì‚°": ("ê²½ê¸° ê³ ì–‘", "3040 ê°€ì¡±, ì£¼ê±° ì¤‘ì‹¬"),
            "ë™íƒ„": ("ê²½ê¸° í™”ì„±", "ì‹ í˜¼ë¶€ë¶€, ì Šì€ ê°€ì¡±"),
        }

        if primary_region in region_info:
            area_name, area_desc = region_info[primary_region]
            area_type = f"{area_name} - {area_desc}"
        else:
            area_type = f"{primary_region} ì§€ì—­ íƒ€ê²Ÿ í‚¤ì›Œë“œ"

        return f"""ì§€ì—­: {', '.join(found)}
íŠ¹ì„±: {area_type}
ì „ëµ: í•´ë‹¹ ì§€ì—­ íƒ€ê²Ÿ ì½˜í…ì¸ /ê´‘ê³  ì§‘ì¤‘"""

    return """ì§€ì—­: ì „êµ­/ë¹„íŠ¹ì •
íŠ¹ì„±: ì§€ì—­ëª…ì´ ì—†ì–´ ì „êµ­ ëŒ€ìƒ í‚¤ì›Œë“œë¡œ ì¶”ì •
ì „ëµ: ì§€ì—­ ì„¸ë¶„í™” í‚¤ì›Œë“œ ì¶”ê°€ ê²€í†  ê¶Œì¥"""


#############################################
# íƒ€ê²Ÿ ì¶”ì • ë¡œì§ (ì—°ë ¹/ì„±ë³„)
#############################################
def estimate_target_demographic(keyword, total_qc, mobile_ratio):
    """í‚¤ì›Œë“œ íŠ¹ì„± ê¸°ë°˜ íƒ€ê²Ÿ ì¶”ì •"""

    # í‚¤ì›Œë“œ íŒ¨í„´ë³„ íƒ€ê²Ÿ ì¶”ì •
    patterns = {
        # ì—°ë ¹ëŒ€ ì¶”ì •
        "2030": ["ë§›ì§‘", "ì¹´í˜", "ë°ì´íŠ¸", "í•«í”Œ", "ì¸ìŠ¤íƒ€", "ë¸ŒëŸ°ì¹˜", "í", "í´ëŸ½", "ìˆ ì§‘", "ì´ìì¹´ì•¼"],
        "3040": ["í•™ì›", "í•™êµ", "êµìœ¡", "ì•„íŒŒíŠ¸", "ë¶€ë™ì‚°", "ì¸í…Œë¦¬ì–´", "ì´ì‚¬", "ìœ¡ì•„", "í‚¤ì¦ˆ"],
        "4050": ["ë³‘ì›", "í•œì˜ì›", "ê±´ê°•", "ë“±ì‚°", "ê³¨í”„", "ë‚šì‹œ", "ì—¬í–‰ì‚¬", "íŒ¨í‚¤ì§€"],
        "ì „ì—°ë ¹": ["ë§ˆíŠ¸", "ë°°ë‹¬", "íƒë°°", "ì€í–‰", "ê´€ê³µì„œ", "ì£¼ë¯¼ì„¼í„°"],

        # ì„±ë³„ ì¶”ì •
        "ì—¬ì„±": ["ë„¤ì¼", "ì†ëˆˆì¹", "í”¼ë¶€ê³¼", "ì„±í˜•", "ë‹¤ì´ì–´íŠ¸", "í•„ë¼í…ŒìŠ¤", "ìš”ê°€", "ë·°í‹°", "í™”ì¥í’ˆ", "í—¤ì–´"],
        "ë‚¨ì„±": ["í—¬ìŠ¤ì¥", "í”¼íŠ¸ë‹ˆìŠ¤", "ë‹¹êµ¬", "pcë°©", "ê²Œì„", "ì¶•êµ¬", "ì•¼êµ¬", "ë‚šì‹œ", "ì² ë¬¼ì "],
    }

    estimated_age = []
    estimated_gender = []

    keyword_lower = keyword.lower()

    for age_group, keywords in patterns.items():
        if age_group in ["2030", "3040", "4050", "ì „ì—°ë ¹"]:
            for kw in keywords:
                if kw in keyword_lower:
                    estimated_age.append(age_group)
                    break
        else:
            for kw in keywords:
                if kw in keyword_lower:
                    estimated_gender.append(age_group)
                    break

    # ê¸°ë³¸ê°’ ì„¤ì •
    if not estimated_age:
        if mobile_ratio >= 85:
            estimated_age = ["2030 ì¶”ì • (ëª¨ë°”ì¼ ë¹„ì¤‘ ë†’ìŒ)"]
        elif mobile_ratio <= 50:
            estimated_age = ["4050 ì¶”ì • (PC ë¹„ì¤‘ ë†’ìŒ)"]
        else:
            estimated_age = ["ì „ ì—°ë ¹ëŒ€"]

    if not estimated_gender:
        estimated_gender = ["ì„±ë³„ êµ¬ë¶„ ì–´ë ¤ì›€"]

    return {
        "age": estimated_age[0] if estimated_age else "ì „ ì—°ë ¹ëŒ€",
        "gender": estimated_gender[0] if estimated_gender else "ì„±ë³„ ë¬´ê´€"
    }


def analyze_keyword_type(keyword):
    """í‚¤ì›Œë“œ ìœ í˜• ë¶„ì„"""
    commercial = ["ë§›ì§‘", "ì¶”ì²œ", "ìˆœìœ„", "ë¹„êµ", "ê°€ê²©", "í• ì¸", "ì´ë²¤íŠ¸", "ì˜ˆì•½", "êµ¬ë§¤", "í›„ê¸°", "ë¦¬ë·°", "best", "TOP"]
    info = ["ë°©ë²•", "í•˜ëŠ”ë²•", "ëœ»", "ì›ì¸", "ì¦ìƒ", "íš¨ê³¼", "ì¢…ë¥˜", "ì°¨ì´", "ë¹„êµ", "ì¥ë‹¨ì "]
    local = ["ë§›ì§‘", "ë³‘ì›", "í•™ì›", "ì¹´í˜", "ë¯¸ìš©ì‹¤", "í—¬ìŠ¤ì¥", "ë¶€ë™ì‚°", "ìˆ™ì†Œ", "í˜¸í…”", "íœì…˜"]
    brand = ["ë‚˜ì´í‚¤", "ì•„ë””ë‹¤ìŠ¤", "ì‚¼ì„±", "ì• í”Œ", "LG", "í˜„ëŒ€", "ê¸°ì•„"]

    types = []
    keyword_lower = keyword.lower()

    if any(kw in keyword_lower for kw in local):
        types.append("ì§€ì—­ ì„œë¹„ìŠ¤")
    if any(kw in keyword_lower for kw in commercial):
        types.append("êµ¬ë§¤ ì˜ë„")
    if any(kw in keyword_lower for kw in info):
        types.append("ì •ë³´ íƒìƒ‰")
    if any(kw in keyword_lower for kw in brand):
        types.append("ë¸Œëœë“œ ê²€ìƒ‰")

    if not types:
        types.append("ì¼ë°˜ ê²€ìƒ‰")

    return " + ".join(types)


#############################################
# íƒ€ê²Ÿ ë¶„ì„ í†µí•©
#############################################
def build_target_text(total_qc, mobile_ratio, keyword):
    """íƒ€ê²Ÿ ë¶„ì„"""
    lines = []

    if total_qc <= 0:
        return "ê²€ìƒ‰ëŸ‰ì´ ì ì–´ íƒ€ê²Ÿ ë¶„ì„ì´ ì–´ë µìŠµë‹ˆë‹¤."

    # ê²€ìƒ‰ëŸ‰ ê·œëª¨ í‰ê°€
    if total_qc >= 100000:
        volume_grade = "ëŒ€í˜• í‚¤ì›Œë“œ"
        competition = "ë†’ìŒ (ìƒìœ„ ë…¸ì¶œ ì–´ë ¤ì›€)"
    elif total_qc >= 30000:
        volume_grade = "ì¤‘ëŒ€í˜• í‚¤ì›Œë“œ"
        competition = "ì¤‘ìƒ (ê²½ìŸ ìˆìœ¼ë‚˜ ê°€ëŠ¥)"
    elif total_qc >= 10000:
        volume_grade = "ì¤‘í˜• í‚¤ì›Œë“œ"
        competition = "ì¤‘ê°„ (ì ê·¹ ê³µëµ ì¶”ì²œ)"
    elif total_qc >= 3000:
        volume_grade = "ì¤‘ì†Œí˜• í‚¤ì›Œë“œ"
        competition = "ë‚®ìŒ (í‹ˆìƒˆ ê³µëµ ì í•©)"
    else:
        volume_grade = "ì†Œí˜•/ë¡±í…Œì¼ í‚¤ì›Œë“œ"
        competition = "ë§¤ìš° ë‚®ìŒ"

    lines.append(f"[ê·œëª¨] {volume_grade}")
    lines.append(f"[ê²½ìŸ] {competition}")
    lines.append("")

    # ë””ë°”ì´ìŠ¤ ë¶„ì„
    if mobile_ratio >= 85:
        device_text = "ëª¨ë°”ì¼ ì••ë„ì  (85%+)"
        device_advice = "â†’ ëª¨ë°”ì¼ ìµœì í™” í•„ìˆ˜"
    elif mobile_ratio >= 70:
        device_text = "ëª¨ë°”ì¼ ì¤‘ì‹¬ (70-85%)"
        device_advice = "â†’ ëª¨ë°”ì¼ ìš°ì„  ìµœì í™”"
    elif mobile_ratio >= 50:
        device_text = "ëª¨ë°”ì¼/PC ê· í˜•"
        device_advice = "â†’ ì–‘ìª½ ëª¨ë‘ ìµœì í™”"
    else:
        device_text = "PC ë¹„ì¤‘ ë†’ìŒ"
        device_advice = "â†’ PC ìƒì„¸ ì •ë³´ ì¤‘ìš”"

    lines.append(f"[ë””ë°”ì´ìŠ¤] {device_text}")
    lines.append(device_advice)
    lines.append("")

    # íƒ€ê²Ÿ ì¶”ì • (ì—°ë ¹/ì„±ë³„)
    target = estimate_target_demographic(keyword, total_qc, mobile_ratio)
    lines.append(f"[ì¶”ì • ì—°ë ¹] {target['age']}")
    lines.append(f"[ì¶”ì • ì„±ë³„] {target['gender']}")
    lines.append("")

    # í‚¤ì›Œë“œ ìœ í˜•
    keyword_type = analyze_keyword_type(keyword)
    lines.append(f"[í‚¤ì›Œë“œ ìœ í˜•] {keyword_type}")

    return "\n".join(lines)


#############################################
# ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API
#############################################
def get_naver_api_headers(method="GET", uri="/keywordstool"):
    timestamp = str(int(time.time() * 1000))
    message = f"{timestamp}.{method}.{uri}"
    signature = hmac.new(
        NAVER_SECRET_KEY.encode('utf-8'),
        message.encode('utf-8'),
        hashlib.sha256
    ).digest()
    signature_base64 = base64.b64encode(signature).decode('utf-8')

    return {
        "Content-Type": "application/json; charset=UTF-8",
        "X-Timestamp": timestamp,
        "X-API-KEY": NAVER_API_KEY,
        "X-Customer": str(NAVER_CUSTOMER_ID),
        "X-Signature": signature_base64
    }


def get_keyword_data(keyword):
    if not NAVER_API_KEY or not NAVER_SECRET_KEY or not NAVER_CUSTOMER_ID:
        return {"success": False, "error": "ê²€ìƒ‰ê´‘ê³  API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    base_url = "https://api.searchad.naver.com"
    uri = "/keywordstool"
    headers = get_naver_api_headers("GET", uri)
    params = {"hintKeywords": keyword, "showDetail": "1"}

    try:
        response = requests.get(base_url + uri, headers=headers, params=params, timeout=4)
        if response.status_code == 200:
            data = response.json()
            keyword_list = data.get("keywordList", [])
            if keyword_list:
                return {"success": True, "data": keyword_list}
            else:
                return {"success": False, "error": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."}
        else:
            return {"success": False, "error": f"API ì˜¤ë¥˜ ({response.status_code})"}
    except Exception as e:
        logger.error(f"ê²€ìƒ‰ê´‘ê³  API ì˜¤ë¥˜: {str(e)}")
        return {"success": False, "error": str(e)}


#############################################
# CPC API í•¨ìˆ˜ë“¤
#############################################
def get_performance_estimate(keyword, bids, device='MOBILE'):
    try:
        uri = '/estimate/performance/keyword'
        url = f'https://api.searchad.naver.com{uri}'
        headers = get_naver_api_headers('POST', uri)
        payload = {
            "device": device,
            "keywordplus": False,
            "key": keyword,
            "bids": bids if isinstance(bids, list) else [bids]
        }
        response = requests.post(url, headers=headers, json=payload, timeout=4)
        if response.status_code == 200:
            return {"success": True, "data": response.json()}
        return {"success": False, "status": response.status_code, "error": response.text}
    except Exception as e:
        logger.error(f"CPC API ì˜¤ë¥˜: {str(e)}")
        return {"success": False, "error": str(e)}


def get_optimal_bid_analysis(estimates):
    if not estimates:
        return None

    valid_estimates = [e for e in estimates if e.get('clicks', 0) > 0]
    if not valid_estimates:
        return None

    min_exposure = valid_estimates[0]
    efficiency_data = []

    for i in range(1, len(valid_estimates)):
        prev = valid_estimates[i - 1]
        curr = valid_estimates[i]
        click_increase = curr.get('clicks', 0) - prev.get('clicks', 0)
        cost_increase = curr.get('cost', 0) - prev.get('cost', 0)

        if cost_increase > 0 and click_increase > 0:
            efficiency_data.append({
                'index': i,
                'data': curr,
                'prev_data': prev,
                'click_increase': click_increase,
                'cost_increase': cost_increase,
                'cost_per_click': cost_increase / click_increase
            })

    best_efficiency = None
    for i, eff in enumerate(efficiency_data):
        if i + 1 < len(efficiency_data):
            next_eff = efficiency_data[i + 1]
            efficiency_drop = next_eff['cost_per_click'] / eff['cost_per_click'] if eff['cost_per_click'] > 0 else 999
            click_ratio = next_eff['click_increase'] / eff['click_increase'] if eff['click_increase'] > 0 else 0
            if efficiency_drop >= 2 or click_ratio < 0.1:
                best_efficiency = {'data': eff['data'], 'cost_per_click': eff['cost_per_click'], 'reason': 'efficiency_drop'}
                break
        else:
            best_efficiency = {'data': eff['data'], 'cost_per_click': eff['cost_per_click'], 'reason': 'last_efficient'}

    if not best_efficiency:
        if len(valid_estimates) >= 3:
            mid_idx = len(valid_estimates) // 2
            best_efficiency = {'data': valid_estimates[mid_idx], 'cost_per_click': None}
        elif valid_estimates:
            best_efficiency = {'data': valid_estimates[-1], 'cost_per_click': None}

    alternative = None
    if best_efficiency and len(valid_estimates) >= 2:
        best_clicks = best_efficiency['data'].get('clicks', 0)
        min_alternative_clicks = max(best_clicks * 0.15, 10)
        best_bid = best_efficiency['data'].get('bid', 0)
        for est in valid_estimates:
            if est.get('bid', 0) < best_bid and est.get('clicks', 0) >= min_alternative_clicks:
                alternative = est

    max_effective_bid = None
    if valid_estimates:
        max_clicks = valid_estimates[-1].get('clicks', 0)
        for est in valid_estimates:
            if est.get('clicks', 0) == max_clicks:
                max_effective_bid = est.get('bid', 0)
                break

    return {
        'min_exposure': min_exposure,
        'best_efficiency': best_efficiency,
        'alternative': alternative,
        'max_effective_bid': max_effective_bid,
        'all_estimates': valid_estimates
    }


#############################################
# DataLab ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ API
#############################################
def get_datalab_trend(keyword):
    if not NAVER_CLIENT_ID or not NAVER_CLIENT_SECRET:
        return {"success": False, "error": "DataLab API í‚¤ ë¯¸ì„¤ì •"}

    url = "https://openapi.naver.com/v1/datalab/search"
    end_date = date.today() - timedelta(days=1)
    start_date = end_date - timedelta(days=365)

    payload = {
        "startDate": start_date.strftime("%Y-%m-%d"),
        "endDate": end_date.strftime("%Y-%m-%d"),
        "timeUnit": "month",
        "keywordGroups": [{"groupName": keyword, "keywords": [keyword]}]
    }

    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
        "Content-Type": "application/json"
    }

    try:
        response = requests.post(url, headers=headers, json=payload, timeout=4)
        if response.status_code != 200:
            return {"success": False, "error": f"DataLab ì˜¤ë¥˜ ({response.status_code})"}

        data = response.json()
        results = data.get("results", [])
        if not results:
            return {"success": False, "error": "íŠ¸ë Œë“œ ë°ì´í„° ì—†ìŒ"}

        series = results[0].get("data", [])
        if not series:
            return {"success": False, "error": "íŠ¸ë Œë“œ ë°ì´í„° ì—†ìŒ"}

        return {"success": True, "data": series}
    except Exception as e:
        logger.error(f"DataLab API ì˜¤ë¥˜: {str(e)}")
        return {"success": False, "error": str(e)}


#############################################
# DataLab ì‡¼í•‘ì¸ì‚¬ì´íŠ¸ API (ì—°ë ¹/ì„±ë³„ ë°ì´í„°)
#############################################
def get_shopping_insight(keyword):
    """ì‡¼í•‘ í‚¤ì›Œë“œ ì—°ë ¹/ì„±ë³„ ë°ì´í„° ì¡°íšŒ"""
    if not NAVER_CLIENT_ID or not NAVER_CLIENT_SECRET:
        return {"success": False, "error": "API í‚¤ ë¯¸ì„¤ì •"}

    url = "https://openapi.naver.com/v1/datalab/shopping/categories"
    end_date = date.today() - timedelta(days=1)
    start_date = end_date - timedelta(days=30)

    # ì‡¼í•‘ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ì¡°íšŒ (í‚¤ì›Œë“œ ì§ì ‘ ì¡°íšŒëŠ” ë¶ˆê°€)
    # ëŒ€ì‹  shopping/category/keywords API ì‚¬ìš© ì‹œë„
    keyword_url = "https://openapi.naver.com/v1/datalab/shopping/category/keywords"

    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
        "Content-Type": "application/json"
    }

    # ì—°ë ¹ë³„ íŠ¸ë Œë“œ
    age_groups = ["10", "20", "30", "40", "50", "60"]
    age_results = {}

    for age in age_groups:
        payload = {
            "startDate": start_date.strftime("%Y-%m-%d"),
            "endDate": end_date.strftime("%Y-%m-%d"),
            "timeUnit": "month",
            "category": "50000000",  # íŒ¨ì…˜ì˜ë¥˜ (ì˜ˆì‹œ)
            "keyword": keyword,
            "ages": [age]
        }

        try:
            response = requests.post(keyword_url, headers=headers, json=payload, timeout=3)
            if response.status_code == 200:
                data = response.json()
                results = data.get("results", [])
                if results and results[0].get("data"):
                    ratio = results[0]["data"][-1].get("ratio", 0)
                    age_results[age] = ratio
        except:
            pass

    if age_results:
        return {"success": True, "data": age_results}
    return {"success": False, "error": "ì‡¼í•‘ ì¸ì‚¬ì´íŠ¸ ë°ì´í„° ì—†ìŒ"}


#############################################
# íŠ¸ë Œë“œ ë¶„ì„ í•¨ìˆ˜ (ê°œì„ )
#############################################
def build_trend_analysis(series, keyword):
    """íŠ¸ë Œë“œ ë°ì´í„° ì‹¬ì¸µ ë¶„ì„"""
    if not series or len(series) < 3:
        return "íŠ¸ë Œë“œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."

    def ym(period):
        return period[:7]

    max_point = max(series, key=lambda x: x.get("ratio", 0))
    min_point = min(series, key=lambda x: x.get("ratio", 0))
    latest = series[-1]
    first = series[0]
    avg_ratio = sum(p.get("ratio", 0) for p in series) / len(series)

    # íŠ¸ë Œë“œ ë³€í™” ê³„ì‚°
    if len(series) >= 6:
        last3_avg = sum(p.get("ratio", 0) for p in series[-3:]) / 3
        prev3_avg = sum(p.get("ratio", 0) for p in series[-6:-3]) / 3
        recent_change = ((last3_avg - prev3_avg) / prev3_avg) * 100 if prev3_avg > 0 else 0
    else:
        recent_change = 0

    # íŠ¸ë Œë“œ ìƒíƒœ íŒë‹¨
    if recent_change >= 20:
        trend_status = "ğŸ”¥ ê¸‰ìƒìŠ¹"
        trend_advice = "ì§€ê¸ˆì´ ì ê¸°! ì ê·¹ ê³µëµ ê¶Œì¥"
    elif recent_change >= 5:
        trend_status = "ğŸ“ˆ ìƒìŠ¹ì„¸"
        trend_advice = "ê´€ì‹¬ ì¦ê°€ ì¤‘, ì„ ì  íš¨ê³¼ ê¸°ëŒ€"
    elif recent_change <= -20:
        trend_status = "ğŸ“‰ ê¸‰í•˜ë½"
        trend_advice = "ì‹œì¦Œ ì¢…ë£Œ ë˜ëŠ” ê´€ì‹¬ ê°ì†Œ"
    elif recent_change <= -5:
        trend_status = "â†˜ï¸ í•˜ë½ì„¸"
        trend_advice = "í‚¤ì›Œë“œ ì¬ê²€í†  ê¶Œì¥"
    else:
        trend_status = "â¡ï¸ ì•ˆì •ì "
        trend_advice = "ê¾¸ì¤€í•œ ìˆ˜ìš”, ì¥ê¸° ìš´ì˜ ì í•©"

    # ê³„ì ˆì„± ë¶„ì„
    seasonality = analyze_seasonality(series)

    # ë³€ë™ì„±
    ratios = [p.get("ratio", 0) for p in series]
    volatility = max(ratios) - min(ratios)
    if volatility >= 50:
        vol_text = "ë†’ìŒ (ê³„ì ˆ/ì´ìŠˆ ì˜í–¥ í¼)"
    elif volatility >= 25:
        vol_text = "ì¤‘ê°„"
    else:
        vol_text = "ë‚®ìŒ (ì•ˆì •ì  ìˆ˜ìš”)"

    text = f"""[í˜„ì¬] {trend_status} ({recent_change:+.1f}%)

[ì§€í‘œ]
â€¢ ìµœê³ : {ym(max_point['period'])} (ì§€ìˆ˜ {max_point['ratio']:.0f})
â€¢ ìµœì €: {ym(min_point['period'])} (ì§€ìˆ˜ {min_point['ratio']:.0f})
â€¢ í˜„ì¬: {ym(latest['period'])} (ì§€ìˆ˜ {latest['ratio']:.0f})
â€¢ í‰ê· : ì§€ìˆ˜ {avg_ratio:.0f}
â€¢ ë³€ë™ì„±: {vol_text}

[ê³„ì ˆì„±] {seasonality}

[ì „ëµ] {trend_advice}"""

    return text


def analyze_seasonality(series):
    """ê³„ì ˆì„± íŒ¨í„´ ë¶„ì„"""
    if len(series) < 12:
        return "1ë…„ ë¯¸ë§Œ ë°ì´í„° (ë¶„ì„ ì œí•œ)"

    monthly_avg = {}
    for point in series:
        month = point['period'][5:7]
        if month not in monthly_avg:
            monthly_avg[month] = []
        monthly_avg[month].append(point.get('ratio', 0))

    for month in monthly_avg:
        monthly_avg[month] = sum(monthly_avg[month]) / len(monthly_avg[month])

    if monthly_avg:
        peak_month = max(monthly_avg, key=monthly_avg.get)
        low_month = min(monthly_avg, key=monthly_avg.get)

        peak_val = monthly_avg[peak_month]
        low_val = monthly_avg[low_month]
        seasonality_ratio = (peak_val - low_val) / low_val * 100 if low_val > 0 else 0

        month_names = {
            '01': '1ì›”', '02': '2ì›”', '03': '3ì›”', '04': '4ì›”',
            '05': '5ì›”', '06': '6ì›”', '07': '7ì›”', '08': '8ì›”',
            '09': '9ì›”', '10': '10ì›”', '11': '11ì›”', '12': '12ì›”'
        }

        if seasonality_ratio >= 30:
            return f"ëšœë ·í•¨ (í”¼í¬: {month_names.get(peak_month)}, ë¹„ìˆ˜ê¸°: {month_names.get(low_month)})"
        else:
            return "ì•½í•¨ (ì—°ì¤‘ ê³ ë¥¸ ê²€ìƒ‰ëŸ‰)"

    return "ë¶„ì„ ë¶ˆê°€"


#############################################
# SERP êµ¬ì¡° ë¶„ì„ (ê°œì„ )
#############################################
def analyze_serp_structure(keyword):
    """SERP êµ¬ì¡° ì‹¬ì¸µ ë¶„ì„"""
    try:
        url = f"https://search.naver.com/search.naver?where=nexearch&query={quote(keyword)}"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            "Accept-Language": "ko-KR,ko;q=0.9"
        }

        response = requests.get(url, headers=headers, timeout=4)
        if response.status_code != 200:
            return f"SERP ë¶„ì„ ì‹¤íŒ¨ (HTTP {response.status_code})"

        html = response.text
        results = []
        strategies = []

        # 1. ê´‘ê³  ë¶„ì„
        ad_patterns = [r'data-adid="', r'class="[^"]*ad_area', r'íŒŒì›Œë§í¬', r'power_link']
        ad_count = sum(len(re.findall(p, html)) for p in ad_patterns)
        ad_count = min(ad_count, 10)

        if ad_count >= 5:
            results.append(f"ê´‘ê³ : ë§ìŒ ({ad_count}ê°œ+)")
            strategies.append("ê´‘ê³  ê²½ìŸ ì¹˜ì—´, SEO ë³‘í–‰ í•„ìˆ˜")
        elif ad_count >= 2:
            results.append(f"ê´‘ê³ : ë³´í†µ ({ad_count}ê°œ)")
            strategies.append("ì ì • ì˜ˆì‚°ìœ¼ë¡œ ê´‘ê³  ë…¸ì¶œ ê°€ëŠ¥")
        elif ad_count >= 1:
            results.append(f"ê´‘ê³ : ì ìŒ ({ad_count}ê°œ)")
        else:
            results.append("ê´‘ê³ : ì—†ìŒ")
            strategies.append("SEOë§Œìœ¼ë¡œ ìƒìœ„ ë…¸ì¶œ ê°€ëŠ¥")

        # 2. í”Œë ˆì´ìŠ¤ ë¶„ì„
        place_patterns = ['data-uisection="place"', 'place_section', 'place_bluelink', '_pl_panel']
        has_place = any(p in html for p in place_patterns)

        if has_place:
            results.append("í”Œë ˆì´ìŠ¤: ìƒë‹¨ ë…¸ì¶œ â­")
            strategies.append("ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ìµœì í™” í•„ìˆ˜!")

        # 3. ë¸”ë¡œê·¸ ë¶„ì„
        blog_patterns = ['blog_area', 'view_wrap', 'data-area="blog"', 'blog.naver.com']
        blog_count = sum(1 for p in blog_patterns if p in html)

        if blog_count >= 2:
            results.append("ë¸”ë¡œê·¸: ì£¼ìš” ë…¸ì¶œ")
            strategies.append("ë¸”ë¡œê·¸ ì½˜í…ì¸  ì œì‘ íš¨ê³¼ì ")
        elif blog_count >= 1:
            results.append("ë¸”ë¡œê·¸: ì¼ë¶€ ë…¸ì¶œ")

        # 4. ê¸°íƒ€ ì˜ì—­
        if 'news_area' in html or 'data-area="news"' in html:
            results.append("ë‰´ìŠ¤: ë…¸ì¶œ")

        if 'cafe.naver.com' in html or 'cafe_area' in html:
            results.append("ì¹´í˜: ë…¸ì¶œ")

        if 'kin.naver.com' in html or 'kin_area' in html:
            results.append("ì§€ì‹ì¸: ë…¸ì¶œ")
            strategies.append("ì§€ì‹ì¸ ë‹µë³€ìœ¼ë¡œ ë…¸ì¶œ ê°€ëŠ¥")

        if 'shopping.naver.com' in html or 'shop_area' in html:
            results.append("ì‡¼í•‘: ë…¸ì¶œ")
            strategies.append("ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ì…ì  ê³ ë ¤")

        if 'video_area' in html or 'youtube.com' in html:
            results.append("ë™ì˜ìƒ: ë…¸ì¶œ")
            strategies.append("ì˜ìƒ ì½˜í…ì¸  ì œì‘ ì¶”ì²œ")

        # ê²°ê³¼ ì¡°í•©
        output = "[ê²€ìƒ‰ê²°ê³¼ êµ¬ì„±]\n"
        output += "\n".join(f"â€¢ {r}" for r in results)

        if strategies:
            output += "\n\n[ë§ˆì¼€íŒ… ì „ëµ]\n"
            output += "\n".join(f"â†’ {s}" for s in strategies[:4])

        return output

    except Exception as e:
        logger.error(f"SERP ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return f"SERP ë¶„ì„ ì˜¤ë¥˜: {str(e)}"


#############################################
# í†µí•© ì¸ì‚¬ì´íŠ¸ (ê°œì„ )
#############################################
def get_keyword_insight(keyword):
    # 1) ê²€ìƒ‰ëŸ‰ & ê²½ìŸë„
    result = get_keyword_data(keyword)
    pc_qc = mobile_qc = total_qc = 0
    comp_idx = ""

    if result["success"]:
        kw = result["data"][0]
        pc_qc = parse_count(kw.get("monthlyPcQcCnt"))
        mobile_qc = parse_count(kw.get("monthlyMobileQcCnt"))
        total_qc = pc_qc + mobile_qc
        mobile_ratio = (mobile_qc * 100 // total_qc) if total_qc > 0 else 0
        pc_ratio = 100 - mobile_ratio if total_qc > 0 else 0
        comp_idx = kw.get("compIdx", "")

        volume_section = f"""ì´ ê²€ìƒ‰ëŸ‰: {format_number(total_qc)}íšŒ/ì›”
â€¢ ëª¨ë°”ì¼: {format_number(mobile_qc)}íšŒ ({mobile_ratio}%)
â€¢ PC: {format_number(pc_qc)}íšŒ ({pc_ratio}%)
â€¢ ê´‘ê³  ê²½ìŸë„: {get_comp_text(comp_idx)}"""
    else:
        mobile_ratio = 0
        volume_section = f"ê²€ìƒ‰ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {result['error']}"

    # 2) íŠ¸ë Œë“œ ë¶„ì„
    trend_res = get_datalab_trend(keyword)
    if trend_res["success"]:
        trend_section = build_trend_analysis(trend_res["data"], keyword)
    else:
        trend_section = trend_res["error"]

    # 3) ì§€ì—­ ë¶„ì„
    region_section = build_region_text(keyword)

    # 4) íƒ€ê²Ÿ ë¶„ì„ (ì—°ë ¹/ì„±ë³„ ì¶”ì • í¬í•¨)
    target_section = build_target_text(total_qc, mobile_ratio, keyword)

    # 5) SERP êµ¬ì¡° ë¶„ì„
    serp_section = analyze_serp_structure(keyword)

    text = f"""[ì¸ì‚¬ì´íŠ¸] {keyword}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š ê²€ìƒ‰ëŸ‰
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{volume_section}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ˆ íŠ¸ë Œë“œ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{trend_section}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ ì§€ì—­
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{region_section}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ íƒ€ê²Ÿ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{target_section}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ” SERP
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{serp_section}
"""
    return text


#############################################
# ê¸°ëŠ¥ 1: ê²€ìƒ‰ëŸ‰ ì¡°íšŒ
#############################################
def get_search_volume(keyword):
    if "," in keyword:
        keywords = [k.strip() for k in keyword.split(",")]
        if len(keywords) > 5:
            return "ìµœëŒ€ 5ê°œ í‚¤ì›Œë“œê¹Œì§€ë§Œ ì¡°íšŒ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        return get_multi_search_volume(keywords[:5])

    result = get_keyword_data(keyword)

    if not result["success"]:
        return f"ì¡°íšŒ ì‹¤íŒ¨: {result['error']}"

    kw = result["data"][0]
    pc = parse_count(kw.get("monthlyPcQcCnt"))
    mobile = parse_count(kw.get("monthlyMobileQcCnt"))
    total = pc + mobile

    return f"""[ê²€ìƒ‰ëŸ‰] {kw.get('relKeyword', keyword)}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì›”ê°„ ê²€ìƒ‰ëŸ‰ (ìµœê·¼ 1ê°œì›”)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ì´ ê²€ìƒ‰ëŸ‰: {format_number(total)}íšŒ
ã„´ ëª¨ë°”ì¼: {format_number(mobile)}íšŒ
ã„´ PC: {format_number(pc)}íšŒ

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€» ë‹¤ë¥¸ ëª…ë ¹ì–´: "ë„ì›€ë§" ì…ë ¥"""


def get_multi_search_volume(keywords):
    response_parts = []

    for keyword in keywords:
        keyword = keyword.replace(" ", "")
        result = get_keyword_data(keyword)

        if result["success"]:
            kw = result["data"][0]
            pc = parse_count(kw.get("monthlyPcQcCnt"))
            mobile = parse_count(kw.get("monthlyMobileQcCnt"))
            total = pc + mobile

            part = f"""[ê²€ìƒ‰ëŸ‰] {kw.get('relKeyword', keyword)}

ì´: {format_number(total)}íšŒ
ã„´ ëª¨ë°”ì¼: {format_number(mobile)}íšŒ
ã„´ PC: {format_number(pc)}íšŒ"""
            response_parts.append(part)
        else:
            response_parts.append(f"[ê²€ìƒ‰ëŸ‰] {keyword}\nì¡°íšŒ ì‹¤íŒ¨")

    return "\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n".join(response_parts)


#############################################
# ê¸°ëŠ¥ 2: ì—°ê´€ í‚¤ì›Œë“œ ì¡°íšŒ
#############################################
def get_related_keywords(keyword):
    try:
        url = f"https://search.naver.com/search.naver?where=nexearch&query={requests.utils.quote(keyword)}"
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Accept-Language": "ko-KR,ko;q=0.9"
        }

        response = requests.get(url, headers=headers, timeout=4)

        if response.status_code == 200:
            html = response.text
            pattern = re.findall(r'<div class="tit">([^<]+)</div>', html)

            seen = set()
            related_keywords = []
            for kw in pattern:
                kw = kw.strip()
                if kw and kw != keyword and kw not in seen and len(kw) > 1:
                    seen.add(kw)
                    related_keywords.append(kw)
                    if len(related_keywords) >= 10:
                        break

            if related_keywords:
                result_text = f"[ì—°ê´€ê²€ìƒ‰ì–´] {keyword}\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                for i, kw in enumerate(related_keywords, 1):
                    result_text += f"{i}. {kw}\n"
                result_text += "\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nâ€» ë„¤ì´ë²„ ì—°ê´€ê²€ìƒ‰ì–´ ê¸°ì¤€"
                return result_text

        return get_related_keywords_api(keyword)

    except Exception as e:
        logger.error(f"ì—°ê´€ê²€ìƒ‰ì–´ ì˜¤ë¥˜: {str(e)}")
        return get_related_keywords_api(keyword)


def get_related_keywords_api(keyword):
    result = get_keyword_data(keyword)

    if not result["success"]:
        return f"ì¡°íšŒ ì‹¤íŒ¨: {result['error']}"

    keyword_list = result["data"][:10]
    response = f"[ì—°ê´€í‚¤ì›Œë“œ] {keyword}\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"

    for i, kw in enumerate(keyword_list, 1):
        name = kw.get("relKeyword", "")
        pc = parse_count(kw.get("monthlyPcQcCnt"))
        mobile = parse_count(kw.get("monthlyMobileQcCnt"))
        total = pc + mobile
        comp = kw.get("compIdx", "")
        comp_text = get_comp_text(comp)

        response += f"{i}. {name} ({format_number(total)}) {comp_text}\n"

    response += "\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nâ€» ê²½ìŸë„: [ë†’ìŒ] [ì¤‘ê°„] [ë‚®ìŒ]"
    return response


#############################################
# ê¸°ëŠ¥ 3: ê´‘ê³  ë‹¨ê°€ ì¡°íšŒ
#############################################
def get_ad_cost(keyword):
    result = get_keyword_data(keyword)

    if not result["success"]:
        return f"ì¡°íšŒ ì‹¤íŒ¨: {result['error']}"

    kw = result["data"][0]
    keyword_name = kw.get('relKeyword', keyword)

    pc_qc = parse_count(kw.get("monthlyPcQcCnt"))
    mobile_qc = parse_count(kw.get("monthlyMobileQcCnt"))
    total_qc = pc_qc + mobile_qc

    mobile_ratio = (mobile_qc * 100 // total_qc) if total_qc > 0 else 0
    pc_ratio = 100 - mobile_ratio

    response = f"""[ê´‘ê³ ë¶„ì„] {keyword_name}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
í‚¤ì›Œë“œ ì •ë³´
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ì›”ê°„ ê²€ìƒ‰ëŸ‰: {format_number(total_qc)}íšŒ
ã„´ ëª¨ë°”ì¼: {format_number(mobile_qc)}íšŒ ({mobile_ratio}%)
ã„´ PC: {format_number(pc_qc)}íšŒ ({pc_ratio}%)

"""

    test_bids = [100, 300, 500, 700, 1000, 1500, 2000, 3000, 5000, 7000, 10000]
    mobile_perf = get_performance_estimate(keyword_name, test_bids, 'MOBILE')
    pc_perf = get_performance_estimate(keyword_name, test_bids, 'PC')

    mobile_success = mobile_perf.get("success", False)
    has_ad_data = False
    analysis = None

    if mobile_success:
        mobile_estimates = mobile_perf["data"].get("estimate", [])
        analysis = get_optimal_bid_analysis(mobile_estimates)

        if analysis:
            has_ad_data = True
            valid_estimates = analysis['all_estimates']

            response += f"""â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ëª¨ë°”ì¼ ê´‘ê³  ë‹¨ê°€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

"""
            prev_clicks = 0
            for est in valid_estimates[:6]:
                bid = est.get("bid", 0)
                clicks = est.get("clicks", 0)
                cost = est.get("cost", 0)
                response += f"{format_number(bid)}ì› > ì›” {clicks}íšŒ | {format_won(cost)}\n"
                if clicks == prev_clicks and prev_clicks > 0:
                    break
                prev_clicks = clicks

            best_eff = analysis.get('best_efficiency')
            if best_eff:
                eff_data = best_eff['data']
                eff_bid = eff_data.get('bid', 0)
                eff_clicks = eff_data.get('clicks', 0)
                eff_cost = eff_data.get('cost', 0)
                eff_cpc = int(eff_cost / eff_clicks) if eff_clicks > 0 else eff_bid

                response += f"""
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì¶”ì²œ ì…ì°°ê°€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

{format_number(eff_bid)}ì›
ã„´ ì˜ˆìƒ í´ë¦­: ì›” {eff_clicks}íšŒ
ã„´ ì˜ˆìƒ ë¹„ìš©: {format_won(eff_cost)}
ã„´ í´ë¦­ë‹¹: {format_number(eff_cpc)}ì›
"""

    if not has_ad_data:
        response += f"""â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ê´‘ê³  ì •ë³´
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ê²€ìƒ‰ëŸ‰ì´ ì ì–´ ì˜ˆìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.

ê°€ì´ë“œ:
- ì…ì°°ê°€: 100~500ì› ì‹œì‘
- ì¼ ì˜ˆì‚°: 5,000~10,000ì›
- 1-2ì£¼ ìš´ì˜ í›„ ì¡°ì •
"""

    return response


#############################################
# ê¸°ëŠ¥ 4: ìš´ì„¸
#############################################
def get_fortune(birthdate=None):
    if not GEMINI_API_KEY:
        return get_fortune_fallback(birthdate)

    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}"
    headers = {"Content-Type": "application/json"}

    if birthdate:
        if len(birthdate) == 6:
            year = birthdate[:2]
            month = birthdate[2:4]
            day = birthdate[4:6]
            year_full = f"19{year}" if int(year) > 30 else f"20{year}"
        elif len(birthdate) == 8:
            year_full = birthdate[:4]
            month = birthdate[4:6]
            day = birthdate[6:8]
        else:
            return get_fortune()

        prompt = f"""ìƒë…„ì›”ì¼ {year_full}ë…„ {month}ì›” {day}ì¼ìƒì˜ ì˜¤ëŠ˜ ìš´ì„¸ë¥¼ ì•Œë ¤ì¤˜.

[ìš´ì„¸] {year_full}ë…„ {month}ì›” {day}ì¼ìƒ

ì´ìš´: (2ì¤„)
ì• ì •ìš´: (1ì¤„)
ê¸ˆì „ìš´: (1ì¤„)
ì§ì¥ìš´: (1ì¤„)

í–‰ìš´ì˜ ìˆ«ì: (1-45 ìˆ«ì 3ê°œ)
í–‰ìš´ì˜ ìƒ‰: (1ê°œ)

ì˜¤ëŠ˜ì˜ ì¡°ì–¸: "(í•œë§ˆë””)"

ì¬ë¯¸ìˆê³  ê¸ì •ì ìœ¼ë¡œ. ì´ëª¨í‹°ì½˜ ì—†ì´."""
    else:
        prompt = """ì˜¤ëŠ˜ì˜ ìš´ì„¸ë¥¼ ì•Œë ¤ì¤˜.

[ì˜¤ëŠ˜ì˜ ìš´ì„¸]

ì´ìš´: (2ì¤„)
ì• ì •ìš´: (1ì¤„)
ê¸ˆì „ìš´: (1ì¤„)
ì§ì¥ìš´: (1ì¤„)

í–‰ìš´ì˜ ìˆ«ì: (1-45 ìˆ«ì 3ê°œ)
í–‰ìš´ì˜ ìƒ‰: (1ê°œ)

ì˜¤ëŠ˜ì˜ í•œë§ˆë””: "(ê²©ì–¸)"

ì¬ë¯¸ìˆê³  ê¸ì •ì ìœ¼ë¡œ. ì´ëª¨í‹°ì½˜ ì—†ì´."""

    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {"temperature": 0.9, "maxOutputTokens": 500}
    }

    try:
        response = requests.post(url, headers=headers, json=data, timeout=4)
        if response.status_code == 200:
            result = response.json()
            return result["candidates"][0]["content"]["parts"][0]["text"]
        return get_fortune_fallback(birthdate)
    except:
        return get_fortune_fallback(birthdate)


def get_fortune_fallback(birthdate=None):
    fortunes = ["ì˜¤ëŠ˜ì€ ìƒˆë¡œìš´ ê¸°íšŒê°€!", "ì¢‹ì€ ì†Œì‹ì´ ì˜ˆì •!", "ì‘ì€ í–‰ìš´ì´ ë”°ë¼ìš”."]
    love = ["ì„¤ë ˆëŠ” ë§Œë‚¨ ê°€ëŠ¥", "ì†Œì¤‘í•œ ëŒ€í™”ë¥¼"]
    money = ["ì‘ì€ íš¡ì¬ìˆ˜", "ì ˆì•½ì´ ë¯¸ë•"]
    work = ["ì§‘ì¤‘ë ¥ UP", "ë„ì „í•´ë³´ì„¸ìš”"]

    lucky_numbers = sorted(random.sample(range(1, 46), 3))
    colors = ["ë¹¨ê°„ìƒ‰", "íŒŒë€ìƒ‰", "ë…¸ë€ìƒ‰", "ì´ˆë¡ìƒ‰", "ë³´ë¼ìƒ‰"]
    quotes = ["í™”ì´íŒ…!", "ì›ƒìœ¼ë©´ ë³µì´ ì™€ìš”", "ë‹¹ì‹ ì€ í•  ìˆ˜ ìˆì–´ìš”!"]

    if birthdate and len(birthdate) in [6, 8]:
        if len(birthdate) == 6:
            year_full = f"19{birthdate[:2]}" if int(birthdate[:2]) > 30 else f"20{birthdate[:2]}"
            month, day = birthdate[2:4], birthdate[4:6]
        else:
            year_full, month, day = birthdate[:4], birthdate[4:6], birthdate[6:8]

        return f"""[ìš´ì„¸] {year_full}ë…„ {month}ì›” {day}ì¼ìƒ

ì´ìš´: {random.choice(fortunes)}
ì• ì •ìš´: {random.choice(love)}
ê¸ˆì „ìš´: {random.choice(money)}
ì§ì¥ìš´: {random.choice(work)}

í–‰ìš´ì˜ ìˆ«ì: {lucky_numbers[0]}, {lucky_numbers[1]}, {lucky_numbers[2]}
í–‰ìš´ì˜ ìƒ‰: {random.choice(colors)}

"{random.choice(quotes)}"
"""

    return f"""[ì˜¤ëŠ˜ì˜ ìš´ì„¸]

ì´ìš´: {random.choice(fortunes)}
ì• ì •ìš´: {random.choice(love)}
ê¸ˆì „ìš´: {random.choice(money)}
ì§ì¥ìš´: {random.choice(work)}

í–‰ìš´ì˜ ìˆ«ì: {lucky_numbers[0]}, {lucky_numbers[1]}, {lucky_numbers[2]}
í–‰ìš´ì˜ ìƒ‰: {random.choice(colors)}

"{random.choice(quotes)}"
"""


#############################################
# ê¸°ëŠ¥ 5: ë¡œë˜
#############################################
def get_lotto():
    if not GEMINI_API_KEY:
        return get_lotto_fallback()

    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}"
    headers = {"Content-Type": "application/json"}

    prompt = """ë¡œë˜ ë²ˆí˜¸ 5ì„¸íŠ¸ ì¶”ì²œ.
1~45 ìˆ«ì, ê° 6ê°œ, ì˜¤ë¦„ì°¨ìˆœ.

[ë¡œë˜ ë²ˆí˜¸ ì¶”ì²œ]

1) 00, 00, 00, 00, 00, 00
2) 00, 00, 00, 00, 00, 00
3) 00, 00, 00, 00, 00, 00
4) 00, 00, 00, 00, 00, 00
5) 00, 00, 00, 00, 00, 00

í–‰ìš´ì„ ë¹•ë‹ˆë‹¤!
â€» ì¬ë¯¸ë¡œë§Œ ì¦ê¸°ì„¸ìš”!

ì´ëª¨í‹°ì½˜ ì—†ì´."""

    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {"temperature": 1.0, "maxOutputTokens": 400}
    }

    try:
        response = requests.post(url, headers=headers, json=data, timeout=4)
        if response.status_code == 200:
            result = response.json()
            return result["candidates"][0]["content"]["parts"][0]["text"]
        return get_lotto_fallback()
    except:
        return get_lotto_fallback()


def get_lotto_fallback():
    result = "[ë¡œë˜ ë²ˆí˜¸ ì¶”ì²œ]\n\n"
    for i in range(1, 6):
        numbers = sorted(random.sample(range(1, 46), 6))
        numbers_str = ", ".join(str(n).zfill(2) for n in numbers)
        result += f"{i}) {numbers_str}\n"
    result += "\ní–‰ìš´ì„ ë¹•ë‹ˆë‹¤!\nâ€» ì¬ë¯¸ë¡œë§Œ ì¦ê¸°ì„¸ìš”!"
    return result


#############################################
# ê¸°ëŠ¥ 6: ëŒ€í‘œí‚¤ì›Œë“œ
#############################################
def extract_place_id_from_url(url_or_id):
    url_or_id = url_or_id.strip()
    if url_or_id.isdigit():
        return url_or_id

    patterns = [
        r'/restaurant/(\d+)', r'/place/(\d+)', r'/cafe/(\d+)',
        r'/hospital/(\d+)', r'/beauty/(\d+)', r'/accommodation/(\d+)',
        r'/leisure/(\d+)', r'/shopping/(\d+)', r'place/(\d+)', r'=(\d{10,})'
    ]

    for pattern in patterns:
        match = re.search(pattern, url_or_id)
        if match:
            place_id = match.group(1)
            if len(place_id) >= 7:
                return place_id

    number_match = re.search(r'\d{7,}', url_or_id)
    if number_match:
        return number_match.group(0)
    return None


def get_place_keywords(place_id):
    headers = {
        "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X)",
        "Accept-Language": "ko-KR,ko;q=0.9"
    }

    categories = ['restaurant', 'place', 'cafe', 'hospital', 'beauty']

    for category in categories:
        try:
            url = f"https://m.place.naver.com/{category}/{place_id}/home"
            response = requests.get(url, headers=headers, timeout=4)

            if response.status_code == 200:
                html = response.content.decode('utf-8', errors='ignore')

                match = re.search(r'"keywordList"\s*:\s*\[((?:"[^"]*",?\s*)*)\]', html)
                if match:
                    keywords_str = "[" + match.group(1) + "]"
                    keywords = json.loads(keywords_str)
                    if keywords:
                        return {"success": True, "place_id": place_id, "keywords": keywords}

                match2 = re.search(r'"keywords"\s*:\s*\[((?:"[^"]*",?\s*)*)\]', html)
                if match2:
                    keywords_str = "[" + match2.group(1) + "]"
                    keywords = json.loads(keywords_str)
                    if keywords:
                        return {"success": True, "place_id": place_id, "keywords": keywords}
        except:
            pass

    return {"success": False, "error": "ëŒ€í‘œí‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}


def format_place_keywords(input_str):
    input_str = input_str.strip().replace('\n', '').replace('\r', '')
    place_id = extract_place_id_from_url(input_str)

    if not place_id:
        return f"""[ëŒ€í‘œí‚¤ì›Œë“œ] ì¡°íšŒ ì‹¤íŒ¨

í”Œë ˆì´ìŠ¤ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ì‚¬ìš©ë²•:
ëŒ€í‘œ 1529801174
ëŒ€í‘œ place.naver.com/restaurant/1529801174"""

    result = get_place_keywords(place_id)

    if not result["success"]:
        return f"""[ëŒ€í‘œí‚¤ì›Œë“œ] ì¡°íšŒ ì‹¤íŒ¨

í”Œë ˆì´ìŠ¤ ID: {place_id}
ì˜¤ë¥˜: {result['error']}"""

    keywords = result["keywords"]
    response = f"""[ëŒ€í‘œí‚¤ì›Œë“œ] {place_id}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ëŒ€í‘œí‚¤ì›Œë“œ ({len(keywords)}ê°œ)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

"""
    for i, kw in enumerate(keywords, 1):
        response += f"{i}. {kw}\n"

    response += f"\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\në³µì‚¬ìš©: {', '.join(keywords)}"
    return response


#############################################
# ê¸°ëŠ¥ 7: ìë™ì™„ì„±
#############################################
def get_autocomplete(keyword):
    try:
        params = {
            "q": keyword, "con": "1", "frm": "nv", "ans": "2",
            "r_format": "json", "r_enc": "UTF-8", "r_unicode": "0",
            "t_koreng": "1", "run": "2", "rev": "4", "q_enc": "UTF-8", "st": "100"
        }
        headers = {
            "User-Agent": "Mozilla/5.0",
            "Referer": "https://www.naver.com/"
        }

        response = requests.get("https://ac.search.naver.com/nx/ac", params=params, headers=headers, timeout=4)

        if response.status_code == 200:
            data = response.json()
            suggestions = []

            for item_group in data.get("items", []):
                if isinstance(item_group, list):
                    for item in item_group:
                        if isinstance(item, list) and len(item) > 0:
                            kw = item[0]
                            if isinstance(kw, list) and len(kw) > 0:
                                suggestions.append(kw[0])
                            elif isinstance(kw, str):
                                suggestions.append(kw)

            seen = set()
            unique = []
            for s in suggestions:
                s = str(s).strip()
                if s and s not in seen and s != keyword:
                    seen.add(s)
                    unique.append(s)
                    if len(unique) >= 10:
                        break

            if unique:
                result = f"[ìë™ì™„ì„±] {keyword}\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                for i, s in enumerate(unique, 1):
                    result += f"{i}. {s}\n"
                result += f"\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nì´ {len(unique)}ê°œ\nâ€» ë„ì–´ì“°ê¸°ì— ë”°ë¼ ê²°ê³¼ ë‹¤ë¦„"
                return result

        return f"[ìë™ì™„ì„±] {keyword}\n\nê²°ê³¼ ì—†ìŒ"

    except Exception as e:
        logger.error(f"ìë™ì™„ì„± ì˜¤ë¥˜: {str(e)}")
        return f"[ìë™ì™„ì„±] {keyword}\n\nì¡°íšŒ ì‹¤íŒ¨"


#############################################
# ë„ì›€ë§
#############################################
def get_help():
    return """[ì‚¬ìš© ê°€ì´ë“œ]

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ê²€ìƒ‰ëŸ‰ (ìµœëŒ€ 5ê°œ)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì˜ˆ) ì¸ì²œë§›ì§‘
ì˜ˆ) ì¸ì²œë§›ì§‘,ê°•ë‚¨ë§›ì§‘

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì¸ì‚¬ì´íŠ¸ (ìƒì„¸ë¶„ì„)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì˜ˆ) ì¸ì‚¬ì´íŠ¸ ë¶€í‰ë§›ì§‘

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
íŠ¸ë Œë“œ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì˜ˆ) íŠ¸ë Œë“œ ì¸ì²œë§›ì§‘

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì—°ê´€ê²€ìƒ‰ì–´
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì˜ˆ) ì—°ê´€ ì¸ì²œë§›ì§‘

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ê´‘ê³ ë‹¨ê°€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì˜ˆ) ê´‘ê³  ì¸ì²œë§›ì§‘

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ìë™ì™„ì„±ì–´
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì˜ˆ) ìë™ ì¸ì²œë§›ì§‘

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ëŒ€í‘œí‚¤ì›Œë“œ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì˜ˆ) ëŒ€í‘œ 12345678

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì¬ë¯¸ ê¸°ëŠ¥
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ìš´ì„¸ > ìš´ì„¸ 870114
ë¡œë˜ > ë¡œë˜"""


#############################################
# ë¼ìš°íŠ¸
#############################################
@app.route('/')
def home():
    return "ì„œë²„ ì •ìƒ ì‘ë™ ì¤‘"


@app.route('/test-place')
def test_place():
    place_id = request.args.get('id', '37838432')
    result = get_place_keywords(place_id)

    html = f"<h2>ID: {place_id}</h2><h3>{'ì„±ê³µ' if result['success'] else 'ì‹¤íŒ¨'}</h3>"
    if result['success']:
        html += "<ul>" + "".join(f"<li>{kw}</li>" for kw in result['keywords']) + "</ul>"
    else:
        html += f"<p>{result.get('error')}</p>"

    return html, 200, {'Content-Type': 'text/html; charset=utf-8'}


#############################################
# ì¹´ì¹´ì˜¤ ìŠ¤í‚¬
#############################################
@app.route('/skill', methods=['POST'])
def kakao_skill():
    try:
        request_data = request.get_json()

        if request_data is None:
            return create_kakao_response("ìš”ì²­ ë°ì´í„° ì—†ìŒ")

        user_utterance = ""
        if "userRequest" in request_data:
            user_utterance = request_data["userRequest"].get("utterance", "").strip()

        if not user_utterance:
            return create_kakao_response("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")

        if is_guide_message(user_utterance):
            return create_kakao_response("ê°€ì´ë“œë¥¼ ì°¸ê³ í•´ì„œ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")

        lower_input = user_utterance.lower()

        # ë„ì›€ë§
        if lower_input in ["ë„ì›€ë§", "ë„ì›€", "ì‚¬ìš©ë²•", "help", "?", "ë©”ë‰´"]:
            return create_kakao_response(get_help())

        # ìš´ì„¸ (ìƒë…„ì›”ì¼)
        if lower_input.startswith("ìš´ì„¸ "):
            birthdate = ''.join(filter(str.isdigit, user_utterance))
            if birthdate and len(birthdate) in [6, 8]:
                return create_kakao_response(get_fortune(birthdate))
            else:
                return create_kakao_response("ìƒë…„ì›”ì¼ì„ 6ìë¦¬ ë˜ëŠ” 8ìë¦¬ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”\nì˜ˆ) ìš´ì„¸ 870114")

        # ìš´ì„¸ (ì¼ë°˜)
        if lower_input in ["ìš´ì„¸", "ì˜¤ëŠ˜ì˜ìš´ì„¸", "ì˜¤ëŠ˜ìš´ì„¸"]:
            return create_kakao_response(get_fortune())

        # ë¡œë˜
        if lower_input in ["ë¡œë˜", "ë¡œë˜ë²ˆí˜¸", "lotto"]:
            return create_kakao_response(get_lotto())

        # ì¸ì‚¬ì´íŠ¸
        if lower_input.startswith("ì¸ì‚¬ì´íŠ¸ "):
            keyword = user_utterance.split(" ", 1)[1].strip() if " " in user_utterance else ""
            keyword = clean_keyword(keyword)
            if keyword:
                return create_kakao_response(get_keyword_insight(keyword))
            return create_kakao_response("ì˜ˆ) ì¸ì‚¬ì´íŠ¸ ë¶€í‰ë§›ì§‘")

        # íŠ¸ë Œë“œ
        if lower_input.startswith("íŠ¸ë Œë“œ "):
            keyword = user_utterance.split(" ", 1)[1].strip() if " " in user_utterance else ""
            keyword = clean_keyword(keyword)
            if keyword:
                return create_kakao_response(get_keyword_insight(keyword))
            return create_kakao_response("ì˜ˆ) íŠ¸ë Œë“œ ì¸ì²œë§›ì§‘")

        # ìë™ì™„ì„±
        if lower_input.startswith("ìë™ ") or lower_input.startswith("ìë™ì™„ì„± "):
            if lower_input.startswith("ìë™ì™„ì„± "):
                keyword = user_utterance[5:].strip()
            else:
                keyword = user_utterance[3:].strip()
            if keyword:
                return create_kakao_response(get_autocomplete(keyword))
            return create_kakao_response("ì˜ˆ) ìë™ ë¶€í‰ë§›ì§‘")

        # ëŒ€í‘œí‚¤ì›Œë“œ
        if lower_input.startswith("ëŒ€í‘œ ") or lower_input.startswith("ëŒ€í‘œí‚¤ì›Œë“œ "):
            if lower_input.startswith("ëŒ€í‘œí‚¤ì›Œë“œ "):
                input_text = user_utterance[6:].strip()
            else:
                input_text = user_utterance[3:].strip()
            if input_text:
                return create_kakao_response(format_place_keywords(input_text))
            return create_kakao_response("ì˜ˆ) ëŒ€í‘œ 37838432")

        # ì—°ê´€í‚¤ì›Œë“œ
        if lower_input.startswith("ì—°ê´€ "):
            keyword = user_utterance.split(" ", 1)[1] if " " in user_utterance else ""
            keyword = clean_keyword(keyword)
            if keyword:
                return create_kakao_response(get_related_keywords(keyword))
            return create_kakao_response("ì˜ˆ) ì—°ê´€ ë§›ì§‘")

        # ê´‘ê³ ë‹¨ê°€
        if lower_input.startswith("ê´‘ê³  "):
            keyword = user_utterance.split(" ", 1)[1] if " " in user_utterance else ""
            keyword = clean_keyword(keyword)
            if keyword:
                return create_kakao_response(get_ad_cost(keyword))
            return create_kakao_response("ì˜ˆ) ê´‘ê³  ë§›ì§‘")

        # ê¸°ë³¸: ê²€ìƒ‰ëŸ‰
        keyword = user_utterance.strip()
        if "," in keyword:
            return create_kakao_response(get_search_volume(keyword))
        else:
            keyword = clean_keyword(keyword)
            return create_kakao_response(get_search_volume(keyword))

    except Exception as e:
        logger.error(f"ìŠ¤í‚¬ ì˜¤ë¥˜: {str(e)}")
        return create_kakao_response(f"ì˜¤ë¥˜: {str(e)}")


def create_kakao_response(text):
    if len(text) > 1000:
        text = text[:997] + "..."

    return jsonify({
        "version": "2.0",
        "template": {
            "outputs": [{"simpleText": {"text": text}}]
        }
    })


#############################################
# ì„œë²„ ì‹¤í–‰
#############################################
if __name__ == '__main__':
    print("=== í™˜ê²½ë³€ìˆ˜ í™•ì¸ ===")
    print(f"ê²€ìƒ‰ê´‘ê³  API: {'âœ…' if NAVER_API_KEY else 'âŒ'}")
    print(f"DataLab API: {'âœ…' if NAVER_CLIENT_ID else 'âŒ'}")
    print(f"Gemini API: {'âœ…' if GEMINI_API_KEY else 'âŒ'}")
    print("====================")

    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)